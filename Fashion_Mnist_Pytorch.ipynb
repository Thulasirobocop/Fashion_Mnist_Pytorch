{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fashion_Mnist_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ceb78c251e4440298b90726db023f027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0d0359d732f047e0ab02e9c88fc67464",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e9b264bd11b14c7fba19ad7431058d41",
              "IPY_MODEL_5f93bb3825874568a73285f34b100b31",
              "IPY_MODEL_66b96b5654014dbf896de3fc20c7af08"
            ]
          }
        },
        "0d0359d732f047e0ab02e9c88fc67464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e9b264bd11b14c7fba19ad7431058d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f07296ffd8174291a4656830e8262de1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a48af25da8894d68affd9c051ac2a2f6"
          }
        },
        "5f93bb3825874568a73285f34b100b31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bcfbbd1337c24e2fbbff88f208b1378f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 26421880,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 26421880,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8dbe1d4d5d194ecda1878ba9ffc4e213"
          }
        },
        "66b96b5654014dbf896de3fc20c7af08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_339257c00abb458dbac4097cf7e9d12c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 26422272/? [00:01&lt;00:00, 24031991.53it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1153382d3a2e4db9b8604d70da0d8965"
          }
        },
        "f07296ffd8174291a4656830e8262de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a48af25da8894d68affd9c051ac2a2f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bcfbbd1337c24e2fbbff88f208b1378f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8dbe1d4d5d194ecda1878ba9ffc4e213": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "339257c00abb458dbac4097cf7e9d12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1153382d3a2e4db9b8604d70da0d8965": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "112451bade7c4179af01278649dfce71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5eb27ff56b394e75891f7398df0e10b5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3c7e56b27c4540008e489fcc36156646",
              "IPY_MODEL_00042b60805d4772888ab7c789908756",
              "IPY_MODEL_f784812e53aa4570a48d9b12b3b4f5af"
            ]
          }
        },
        "5eb27ff56b394e75891f7398df0e10b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c7e56b27c4540008e489fcc36156646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_be34f1120ea846ffbbc3c5335b24167e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_935786e19508487f9d8a1f853b5e2892"
          }
        },
        "00042b60805d4772888ab7c789908756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ffcc5ecc17d417185751c7fd1721e33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 29515,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 29515,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83cfa2081a644701b21fc567a16768ee"
          }
        },
        "f784812e53aa4570a48d9b12b3b4f5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8ee95a2d14f342bc8b313f324c246077",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 29696/? [00:00&lt;00:00, 134446.41it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8789ff9c346543e48c02c12988637a53"
          }
        },
        "be34f1120ea846ffbbc3c5335b24167e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "935786e19508487f9d8a1f853b5e2892": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ffcc5ecc17d417185751c7fd1721e33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83cfa2081a644701b21fc567a16768ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ee95a2d14f342bc8b313f324c246077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8789ff9c346543e48c02c12988637a53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dfd72ee38eda4f08bb7fa598ea78dad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_299853a664444ac398974e08bb649069",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4b6e7fcd27364371ac773abc2108f082",
              "IPY_MODEL_4245013db03a4e80b647c093d2a722d7",
              "IPY_MODEL_d817497fc4a94a3bab0d4dcbb1a9809a"
            ]
          }
        },
        "299853a664444ac398974e08bb649069": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4b6e7fcd27364371ac773abc2108f082": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eb0d54424a674c9abc64452b17ecd165",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7d6e7c6f4cb74f6f92f2d2384fc09fc0"
          }
        },
        "4245013db03a4e80b647c093d2a722d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_69ddd53e4e634ffaa44b574412aaf329",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 4422102,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 4422102,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6304ac71a1864a20afbb1a1c6200fa8a"
          }
        },
        "d817497fc4a94a3bab0d4dcbb1a9809a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_484182f2c21645199b5f8341cfbdd588",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 4422656/? [00:00&lt;00:00, 7914965.69it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c58f9e6691e142d882ae36089cdde884"
          }
        },
        "eb0d54424a674c9abc64452b17ecd165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7d6e7c6f4cb74f6f92f2d2384fc09fc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69ddd53e4e634ffaa44b574412aaf329": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6304ac71a1864a20afbb1a1c6200fa8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "484182f2c21645199b5f8341cfbdd588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c58f9e6691e142d882ae36089cdde884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4dbb1ad8811640b18f79ffb2f15873a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c98d09bf566a45c6b7940d95a84e8117",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_42dd2fd2580c45898dba25866601f62b",
              "IPY_MODEL_ad27b496dfd4476494fd53a22c082805",
              "IPY_MODEL_a54a4cad0332462f968be47ae6df1b7e"
            ]
          }
        },
        "c98d09bf566a45c6b7940d95a84e8117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "42dd2fd2580c45898dba25866601f62b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7debffef95e647f99ebd81a79bed1799",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5d02c67dc47468a8d6e65ac95a51878"
          }
        },
        "ad27b496dfd4476494fd53a22c082805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_30a4fbd0eebd480f81e9f60b8523d212",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5148,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5148,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3d445fa3c1b94e72a24bbf62864c3184"
          }
        },
        "a54a4cad0332462f968be47ae6df1b7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_997dcac838484a32b923a6a673ff5d1a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6144/? [00:00&lt;00:00, 122549.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cc34ffe4cdb34f72a229bbd9d81de4ae"
          }
        },
        "7debffef95e647f99ebd81a79bed1799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5d02c67dc47468a8d6e65ac95a51878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30a4fbd0eebd480f81e9f60b8523d212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3d445fa3c1b94e72a24bbf62864c3184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "997dcac838484a32b923a6a673ff5d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cc34ffe4cdb34f72a229bbd9d81de4ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9PuCgBsFkoM"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdOPbd8_GmMW"
      },
      "source": [
        "Data_root_dir=\"/content/drive/MyDrive/Dataset/FashionMnist/Data\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482,
          "referenced_widgets": [
            "ceb78c251e4440298b90726db023f027",
            "0d0359d732f047e0ab02e9c88fc67464",
            "e9b264bd11b14c7fba19ad7431058d41",
            "5f93bb3825874568a73285f34b100b31",
            "66b96b5654014dbf896de3fc20c7af08",
            "f07296ffd8174291a4656830e8262de1",
            "a48af25da8894d68affd9c051ac2a2f6",
            "bcfbbd1337c24e2fbbff88f208b1378f",
            "8dbe1d4d5d194ecda1878ba9ffc4e213",
            "339257c00abb458dbac4097cf7e9d12c",
            "1153382d3a2e4db9b8604d70da0d8965",
            "112451bade7c4179af01278649dfce71",
            "5eb27ff56b394e75891f7398df0e10b5",
            "3c7e56b27c4540008e489fcc36156646",
            "00042b60805d4772888ab7c789908756",
            "f784812e53aa4570a48d9b12b3b4f5af",
            "be34f1120ea846ffbbc3c5335b24167e",
            "935786e19508487f9d8a1f853b5e2892",
            "9ffcc5ecc17d417185751c7fd1721e33",
            "83cfa2081a644701b21fc567a16768ee",
            "8ee95a2d14f342bc8b313f324c246077",
            "8789ff9c346543e48c02c12988637a53",
            "dfd72ee38eda4f08bb7fa598ea78dad4",
            "299853a664444ac398974e08bb649069",
            "4b6e7fcd27364371ac773abc2108f082",
            "4245013db03a4e80b647c093d2a722d7",
            "d817497fc4a94a3bab0d4dcbb1a9809a",
            "eb0d54424a674c9abc64452b17ecd165",
            "7d6e7c6f4cb74f6f92f2d2384fc09fc0",
            "69ddd53e4e634ffaa44b574412aaf329",
            "6304ac71a1864a20afbb1a1c6200fa8a",
            "484182f2c21645199b5f8341cfbdd588",
            "c58f9e6691e142d882ae36089cdde884",
            "4dbb1ad8811640b18f79ffb2f15873a0",
            "c98d09bf566a45c6b7940d95a84e8117",
            "42dd2fd2580c45898dba25866601f62b",
            "ad27b496dfd4476494fd53a22c082805",
            "a54a4cad0332462f968be47ae6df1b7e",
            "7debffef95e647f99ebd81a79bed1799",
            "a5d02c67dc47468a8d6e65ac95a51878",
            "30a4fbd0eebd480f81e9f60b8523d212",
            "3d445fa3c1b94e72a24bbf62864c3184",
            "997dcac838484a32b923a6a673ff5d1a",
            "cc34ffe4cdb34f72a229bbd9d81de4ae"
          ]
        },
        "id": "HMilEYoUG7Lb",
        "outputId": "a5797854-88e7-4dfe-c866-632e995d53b3"
      },
      "source": [
        "train_data=torchvision.datasets.FashionMNIST(root=Data_root_dir,\n",
        "                                             train=True,\n",
        "                                             download=True,\n",
        "                                             transform=torchvision.transforms.ToTensor())\n",
        "\n",
        "\n",
        "test_data=torchvision.datasets.FashionMNIST(root=Data_root_dir,\n",
        "                                            train=False,\n",
        "                                            download=True,\n",
        "                                            transform=torchvision.transforms.ToTensor())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /content/drive/MyDrive/Dataset/FashionMnist/Data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ceb78c251e4440298b90726db023f027",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/26421880 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/Dataset/FashionMnist/Data/FashionMNIST/raw/train-images-idx3-ubyte.gz to /content/drive/MyDrive/Dataset/FashionMnist/Data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /content/drive/MyDrive/Dataset/FashionMnist/Data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "112451bade7c4179af01278649dfce71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/29515 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/Dataset/FashionMnist/Data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /content/drive/MyDrive/Dataset/FashionMnist/Data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /content/drive/MyDrive/Dataset/FashionMnist/Data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfd72ee38eda4f08bb7fa598ea78dad4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/4422102 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/Dataset/FashionMnist/Data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /content/drive/MyDrive/Dataset/FashionMnist/Data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /content/drive/MyDrive/Dataset/FashionMnist/Data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4dbb1ad8811640b18f79ffb2f15873a0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/5148 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/drive/MyDrive/Dataset/FashionMnist/Data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /content/drive/MyDrive/Dataset/FashionMnist/Data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtdFI83OHpLE"
      },
      "source": [
        "Batch_size=64\n",
        "train_data_loader=torch.utils.data.DataLoader(train_data,batch_size=Batch_size)\n",
        "test_data_loader=torch.utils.data.DataLoader(test_data,batch_size=Batch_size)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npyuz8TuImku",
        "outputId": "e3731589-d152-4825-c2d1-9ad18ac911d5"
      },
      "source": [
        "print(type(train_data_loader))\n",
        "print(type(test_data_loader))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torch.utils.data.dataloader.DataLoader'>\n",
            "<class 'torch.utils.data.dataloader.DataLoader'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1m6jXPnIrZh",
        "outputId": "46cc4642-0e63-4f65-a046-8e3427f9d8c5"
      },
      "source": [
        "for X,y in test_data_loader:\n",
        "  print(X.shape)\n",
        "  print(y.shape,y.dtype,torch.unique(y))\n",
        "  break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64]) torch.int64 tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODQ5Dy-eJB0v",
        "outputId": "4f77084d-6fa9-45e7-d1de-add0cade3b30"
      },
      "source": [
        "device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5p1Vz_4JRlB"
      },
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork,self).__init__()\n",
        "\n",
        "    self.flatten=nn.Flatten()\n",
        "\n",
        "    self.linear_relu_stack=nn.Sequential(\n",
        "        nn.Linear(28*28,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,300),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(300,100),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(100,50),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(50,10),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "  def forward(self,X):\n",
        "    X=self.flatten(X)\n",
        "    logits=self.linear_relu_stack(X)\n",
        "    return logits"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F8dMcwAKYL9"
      },
      "source": [
        "model=NeuralNetwork().to(device)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0VPjufpKcj3",
        "outputId": "1f584fde-d8f9-4fcb-f2fe-f3df64e9c322"
      },
      "source": [
        "print(model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=300, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=300, out_features=100, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=100, out_features=50, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=50, out_features=10, bias=True)\n",
            "    (9): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW91ZWtTKoey"
      },
      "source": [
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=1e-3)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD3dS7b1K3ot"
      },
      "source": [
        "def train(data_loader,model,loss_fn,optimizer):\n",
        "  size=len(data_loader.dataset)\n",
        "\n",
        "  for batch, (X,y) in enumerate(data_loader):\n",
        "    X,y =X.to(device),y.to(device)\n",
        "    \n",
        "    pred=model(X)\n",
        "    loss=loss_fn(pred,y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch%100==0:\n",
        "      #loss=current=loss.item(),batch*len(X)\n",
        "      loss, current = loss.item(), batch * len(X)\n",
        "      print(f\"training loss: {loss} [{current}/{size}]\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKuMJMnAL0bS"
      },
      "source": [
        "def test(data_loader,model):\n",
        "  size=len(data_loader.dataset)\n",
        "  model.eval()\n",
        "\n",
        "  test_loss,correct=0,0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X,y in data_loader:\n",
        "      X,y =X.to(device),y.to(device)\n",
        "      pred=model(X)\n",
        "      test_loss=test_loss+loss_fn(pred,y).item()\n",
        "      correct=correct+(pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "  test_loss=test_loss/size\n",
        "  correct=correct/size\n",
        "\n",
        "  print(f\"Correct Predictions: {100*correct}%, Average Loss: {test_loss*100}%\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk7pujOrMuUZ",
        "outputId": "da36c6ed-a05f-4210-ce35-135fa8623098"
      },
      "source": [
        "Epoch=500\n",
        "\n",
        "for epoch in range(Epoch):\n",
        "  print(f\"\\n\\n\\n\\nEpoch: {epoch+1}\")\n",
        "\n",
        "  train(train_data_loader,model,loss_fn,optimizer)\n",
        "  test(test_data_loader,model)\n",
        "\n",
        "print(\"End of training\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "training loss: 0.715046763420105 [25600/60000]\n",
            "training loss: 1.250493049621582 [32000/60000]\n",
            "training loss: 0.9276719689369202 [38400/60000]\n",
            "training loss: 1.1882702112197876 [44800/60000]\n",
            "training loss: 1.1273798942565918 [51200/60000]\n",
            "training loss: 1.0693398714065552 [57600/60000]\n",
            "Correct Predictions: 57.550000000000004%, Average Loss: 1.692994436621666%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 189\n",
            "training loss: 1.1687965393066406 [0/60000]\n",
            "training loss: 1.0888267755508423 [6400/60000]\n",
            "training loss: 1.1514068841934204 [12800/60000]\n",
            "training loss: 1.0700771808624268 [19200/60000]\n",
            "training loss: 0.7147770524024963 [25600/60000]\n",
            "training loss: 1.2504658699035645 [32000/60000]\n",
            "training loss: 0.9276928305625916 [38400/60000]\n",
            "training loss: 1.1875864267349243 [44800/60000]\n",
            "training loss: 1.1268346309661865 [51200/60000]\n",
            "training loss: 1.0689204931259155 [57600/60000]\n",
            "Correct Predictions: 57.56%, Average Loss: 1.6925915986299513%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 190\n",
            "training loss: 1.1684976816177368 [0/60000]\n",
            "training loss: 1.0882185697555542 [6400/60000]\n",
            "training loss: 1.150711178779602 [12800/60000]\n",
            "training loss: 1.06968355178833 [19200/60000]\n",
            "training loss: 0.7143837213516235 [25600/60000]\n",
            "training loss: 1.250417947769165 [32000/60000]\n",
            "training loss: 0.9275359511375427 [38400/60000]\n",
            "training loss: 1.186943531036377 [44800/60000]\n",
            "training loss: 1.125966191291809 [51200/60000]\n",
            "training loss: 1.068437099456787 [57600/60000]\n",
            "Correct Predictions: 57.56%, Average Loss: 1.6922047418355943%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 191\n",
            "training loss: 1.1680477857589722 [0/60000]\n",
            "training loss: 1.087484359741211 [6400/60000]\n",
            "training loss: 1.1502635478973389 [12800/60000]\n",
            "training loss: 1.0692492723464966 [19200/60000]\n",
            "training loss: 0.7141254544258118 [25600/60000]\n",
            "training loss: 1.2504605054855347 [32000/60000]\n",
            "training loss: 0.9277328848838806 [38400/60000]\n",
            "training loss: 1.186310887336731 [44800/60000]\n",
            "training loss: 1.1255053281784058 [51200/60000]\n",
            "training loss: 1.0679690837860107 [57600/60000]\n",
            "Correct Predictions: 57.56%, Average Loss: 1.6918195432424545%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 192\n",
            "training loss: 1.1678268909454346 [0/60000]\n",
            "training loss: 1.0868816375732422 [6400/60000]\n",
            "training loss: 1.1499207019805908 [12800/60000]\n",
            "training loss: 1.06878662109375 [19200/60000]\n",
            "training loss: 0.7137189507484436 [25600/60000]\n",
            "training loss: 1.2504533529281616 [32000/60000]\n",
            "training loss: 0.9280298352241516 [38400/60000]\n",
            "training loss: 1.185639500617981 [44800/60000]\n",
            "training loss: 1.125043272972107 [51200/60000]\n",
            "training loss: 1.06728994846344 [57600/60000]\n",
            "Correct Predictions: 57.57%, Average Loss: 1.6914253109693527%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 193\n",
            "training loss: 1.1676466464996338 [0/60000]\n",
            "training loss: 1.0861103534698486 [6400/60000]\n",
            "training loss: 1.1494693756103516 [12800/60000]\n",
            "training loss: 1.0683085918426514 [19200/60000]\n",
            "training loss: 0.7135558724403381 [25600/60000]\n",
            "training loss: 1.2504546642303467 [32000/60000]\n",
            "training loss: 0.9280800819396973 [38400/60000]\n",
            "training loss: 1.1851513385772705 [44800/60000]\n",
            "training loss: 1.1245092153549194 [51200/60000]\n",
            "training loss: 1.0668188333511353 [57600/60000]\n",
            "Correct Predictions: 57.56%, Average Loss: 1.691037118434906%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 194\n",
            "training loss: 1.167472004890442 [0/60000]\n",
            "training loss: 1.0854084491729736 [6400/60000]\n",
            "training loss: 1.149044156074524 [12800/60000]\n",
            "training loss: 1.0678662061691284 [19200/60000]\n",
            "training loss: 0.7131742835044861 [25600/60000]\n",
            "training loss: 1.2504042387008667 [32000/60000]\n",
            "training loss: 0.9283196330070496 [38400/60000]\n",
            "training loss: 1.1846230030059814 [44800/60000]\n",
            "training loss: 1.1241041421890259 [51200/60000]\n",
            "training loss: 1.0663542747497559 [57600/60000]\n",
            "Correct Predictions: 57.56%, Average Loss: 1.6906653380393981%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 195\n",
            "training loss: 1.1671463251113892 [0/60000]\n",
            "training loss: 1.0847699642181396 [6400/60000]\n",
            "training loss: 1.1485860347747803 [12800/60000]\n",
            "training loss: 1.06740140914917 [19200/60000]\n",
            "training loss: 0.7128907442092896 [25600/60000]\n",
            "training loss: 1.2503317594528198 [32000/60000]\n",
            "training loss: 0.9284530878067017 [38400/60000]\n",
            "training loss: 1.1839929819107056 [44800/60000]\n",
            "training loss: 1.1236631870269775 [51200/60000]\n",
            "training loss: 1.0657709836959839 [57600/60000]\n",
            "Correct Predictions: 57.57%, Average Loss: 1.6902762258052828%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 196\n",
            "training loss: 1.1668046712875366 [0/60000]\n",
            "training loss: 1.0841145515441895 [6400/60000]\n",
            "training loss: 1.1482079029083252 [12800/60000]\n",
            "training loss: 1.0669854879379272 [19200/60000]\n",
            "training loss: 0.7125476598739624 [25600/60000]\n",
            "training loss: 1.2502201795578003 [32000/60000]\n",
            "training loss: 0.9286508560180664 [38400/60000]\n",
            "training loss: 1.183104395866394 [44800/60000]\n",
            "training loss: 1.123085856437683 [51200/60000]\n",
            "training loss: 1.0652426481246948 [57600/60000]\n",
            "Correct Predictions: 57.589999999999996%, Average Loss: 1.6899095988273622%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 197\n",
            "training loss: 1.1665745973587036 [0/60000]\n",
            "training loss: 1.0834877490997314 [6400/60000]\n",
            "training loss: 1.1478626728057861 [12800/60000]\n",
            "training loss: 1.0665532350540161 [19200/60000]\n",
            "training loss: 0.7123527526855469 [25600/60000]\n",
            "training loss: 1.2501918077468872 [32000/60000]\n",
            "training loss: 0.9284676909446716 [38400/60000]\n",
            "training loss: 1.1826497316360474 [44800/60000]\n",
            "training loss: 1.1226608753204346 [51200/60000]\n",
            "training loss: 1.0646419525146484 [57600/60000]\n",
            "Correct Predictions: 57.599999999999994%, Average Loss: 1.6895345830917359%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 198\n",
            "training loss: 1.1660822629928589 [0/60000]\n",
            "training loss: 1.0828869342803955 [6400/60000]\n",
            "training loss: 1.1475483179092407 [12800/60000]\n",
            "training loss: 1.0661423206329346 [19200/60000]\n",
            "training loss: 0.7120181322097778 [25600/60000]\n",
            "training loss: 1.250071406364441 [32000/60000]\n",
            "training loss: 0.9285909533500671 [38400/60000]\n",
            "training loss: 1.1821117401123047 [44800/60000]\n",
            "training loss: 1.1222374439239502 [51200/60000]\n",
            "training loss: 1.0641560554504395 [57600/60000]\n",
            "Correct Predictions: 57.599999999999994%, Average Loss: 1.6891819614171983%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 199\n",
            "training loss: 1.165771484375 [0/60000]\n",
            "training loss: 1.0822395086288452 [6400/60000]\n",
            "training loss: 1.147233009338379 [12800/60000]\n",
            "training loss: 1.0657036304473877 [19200/60000]\n",
            "training loss: 0.7115830183029175 [25600/60000]\n",
            "training loss: 1.250159740447998 [32000/60000]\n",
            "training loss: 0.9287121295928955 [38400/60000]\n",
            "training loss: 1.1816178560256958 [44800/60000]\n",
            "training loss: 1.1218347549438477 [51200/60000]\n",
            "training loss: 1.0636250972747803 [57600/60000]\n",
            "Correct Predictions: 57.589999999999996%, Average Loss: 1.6888188236951829%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 200\n",
            "training loss: 1.1654502153396606 [0/60000]\n",
            "training loss: 1.0816043615341187 [6400/60000]\n",
            "training loss: 1.146907925605774 [12800/60000]\n",
            "training loss: 1.0652287006378174 [19200/60000]\n",
            "training loss: 0.711376965045929 [25600/60000]\n",
            "training loss: 1.2501024007797241 [32000/60000]\n",
            "training loss: 0.9288164377212524 [38400/60000]\n",
            "training loss: 1.181077480316162 [44800/60000]\n",
            "training loss: 1.1213852167129517 [51200/60000]\n",
            "training loss: 1.0630824565887451 [57600/60000]\n",
            "Correct Predictions: 57.599999999999994%, Average Loss: 1.6884513366222382%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 201\n",
            "training loss: 1.1651902198791504 [0/60000]\n",
            "training loss: 1.0809885263442993 [6400/60000]\n",
            "training loss: 1.1465599536895752 [12800/60000]\n",
            "training loss: 1.0647616386413574 [19200/60000]\n",
            "training loss: 0.7111097574234009 [25600/60000]\n",
            "training loss: 1.2500061988830566 [32000/60000]\n",
            "training loss: 0.9290996193885803 [38400/60000]\n",
            "training loss: 1.180688500404358 [44800/60000]\n",
            "training loss: 1.121026635169983 [51200/60000]\n",
            "training loss: 1.062575101852417 [57600/60000]\n",
            "Correct Predictions: 57.599999999999994%, Average Loss: 1.6881011104583739%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 202\n",
            "training loss: 1.164784550666809 [0/60000]\n",
            "training loss: 1.0804431438446045 [6400/60000]\n",
            "training loss: 1.1461385488510132 [12800/60000]\n",
            "training loss: 1.0643264055252075 [19200/60000]\n",
            "training loss: 0.7107290029525757 [25600/60000]\n",
            "training loss: 1.2500321865081787 [32000/60000]\n",
            "training loss: 0.9297733902931213 [38400/60000]\n",
            "training loss: 1.1801553964614868 [44800/60000]\n",
            "training loss: 1.1205518245697021 [51200/60000]\n",
            "training loss: 1.062036156654358 [57600/60000]\n",
            "Correct Predictions: 57.599999999999994%, Average Loss: 1.6877524656057359%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 203\n",
            "training loss: 1.1645092964172363 [0/60000]\n",
            "training loss: 1.079734206199646 [6400/60000]\n",
            "training loss: 1.1457650661468506 [12800/60000]\n",
            "training loss: 1.0638766288757324 [19200/60000]\n",
            "training loss: 0.7104076743125916 [25600/60000]\n",
            "training loss: 1.2499892711639404 [32000/60000]\n",
            "training loss: 0.9298203587532043 [38400/60000]\n",
            "training loss: 1.1796376705169678 [44800/60000]\n",
            "training loss: 1.1201388835906982 [51200/60000]\n",
            "training loss: 1.0615333318710327 [57600/60000]\n",
            "Correct Predictions: 57.599999999999994%, Average Loss: 1.687434113621712%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 204\n",
            "training loss: 1.1642403602600098 [0/60000]\n",
            "training loss: 1.0791605710983276 [6400/60000]\n",
            "training loss: 1.1453551054000854 [12800/60000]\n",
            "training loss: 1.0634504556655884 [19200/60000]\n",
            "training loss: 0.710090696811676 [25600/60000]\n",
            "training loss: 1.2499268054962158 [32000/60000]\n",
            "training loss: 0.9299474954605103 [38400/60000]\n",
            "training loss: 1.1791718006134033 [44800/60000]\n",
            "training loss: 1.1197752952575684 [51200/60000]\n",
            "training loss: 1.0610674619674683 [57600/60000]\n",
            "Correct Predictions: 57.599999999999994%, Average Loss: 1.687104812860489%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 205\n",
            "training loss: 1.1639435291290283 [0/60000]\n",
            "training loss: 1.0785263776779175 [6400/60000]\n",
            "training loss: 1.1449003219604492 [12800/60000]\n",
            "training loss: 1.063015341758728 [19200/60000]\n",
            "training loss: 0.7098307013511658 [25600/60000]\n",
            "training loss: 1.2499041557312012 [32000/60000]\n",
            "training loss: 0.9299942851066589 [38400/60000]\n",
            "training loss: 1.1786655187606812 [44800/60000]\n",
            "training loss: 1.1193662881851196 [51200/60000]\n",
            "training loss: 1.0602936744689941 [57600/60000]\n",
            "Correct Predictions: 57.599999999999994%, Average Loss: 1.6867634046077729%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 206\n",
            "training loss: 1.1634521484375 [0/60000]\n",
            "training loss: 1.0778298377990723 [6400/60000]\n",
            "training loss: 1.1445045471191406 [12800/60000]\n",
            "training loss: 1.0626120567321777 [19200/60000]\n",
            "training loss: 0.7094702124595642 [25600/60000]\n",
            "training loss: 1.2499138116836548 [32000/60000]\n",
            "training loss: 0.9302342534065247 [38400/60000]\n",
            "training loss: 1.1780861616134644 [44800/60000]\n",
            "training loss: 1.1188786029815674 [51200/60000]\n",
            "training loss: 1.0598089694976807 [57600/60000]\n",
            "Correct Predictions: 57.589999999999996%, Average Loss: 1.6864257514476777%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 207\n",
            "training loss: 1.1631959676742554 [0/60000]\n",
            "training loss: 1.077158808708191 [6400/60000]\n",
            "training loss: 1.1441112756729126 [12800/60000]\n",
            "training loss: 1.062207818031311 [19200/60000]\n",
            "training loss: 0.708349347114563 [25600/60000]\n",
            "training loss: 1.2498944997787476 [32000/60000]\n",
            "training loss: 0.9301213622093201 [38400/60000]\n",
            "training loss: 1.1775754690170288 [44800/60000]\n",
            "training loss: 1.1185133457183838 [51200/60000]\n",
            "training loss: 1.0592432022094727 [57600/60000]\n",
            "Correct Predictions: 57.599999999999994%, Average Loss: 1.6861011272668838%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 208\n",
            "training loss: 1.1628693342208862 [0/60000]\n",
            "training loss: 1.0766361951828003 [6400/60000]\n",
            "training loss: 1.1437253952026367 [12800/60000]\n",
            "training loss: 1.0618354082107544 [19200/60000]\n",
            "training loss: 0.7081329226493835 [25600/60000]\n",
            "training loss: 1.2502154111862183 [32000/60000]\n",
            "training loss: 0.9300815463066101 [38400/60000]\n",
            "training loss: 1.1770918369293213 [44800/60000]\n",
            "training loss: 1.118085265159607 [51200/60000]\n",
            "training loss: 1.0587435960769653 [57600/60000]\n",
            "Correct Predictions: 57.599999999999994%, Average Loss: 1.6857302939891814%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 209\n",
            "training loss: 1.162465214729309 [0/60000]\n",
            "training loss: 1.0760290622711182 [6400/60000]\n",
            "training loss: 1.1433073282241821 [12800/60000]\n",
            "training loss: 1.0613884925842285 [19200/60000]\n",
            "training loss: 0.707636833190918 [25600/60000]\n",
            "training loss: 1.2502342462539673 [32000/60000]\n",
            "training loss: 0.9297405481338501 [38400/60000]\n",
            "training loss: 1.1765697002410889 [44800/60000]\n",
            "training loss: 1.1176844835281372 [51200/60000]\n",
            "training loss: 1.0582311153411865 [57600/60000]\n",
            "Correct Predictions: 57.60999999999999%, Average Loss: 1.685393395423889%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 210\n",
            "training loss: 1.1621989011764526 [0/60000]\n",
            "training loss: 1.0755008459091187 [6400/60000]\n",
            "training loss: 1.1428816318511963 [12800/60000]\n",
            "training loss: 1.0597362518310547 [19200/60000]\n",
            "training loss: 0.7074916958808899 [25600/60000]\n",
            "training loss: 1.250346302986145 [32000/60000]\n",
            "training loss: 0.9292365312576294 [38400/60000]\n",
            "training loss: 1.1759085655212402 [44800/60000]\n",
            "training loss: 1.1173732280731201 [51200/60000]\n",
            "training loss: 1.0576343536376953 [57600/60000]\n",
            "Correct Predictions: 57.64%, Average Loss: 1.6850404006242752%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 211\n",
            "training loss: 1.161994457244873 [0/60000]\n",
            "training loss: 1.0749070644378662 [6400/60000]\n",
            "training loss: 1.1425063610076904 [12800/60000]\n",
            "training loss: 1.059303641319275 [19200/60000]\n",
            "training loss: 0.7075095176696777 [25600/60000]\n",
            "training loss: 1.2503794431686401 [32000/60000]\n",
            "training loss: 0.9283203482627869 [38400/60000]\n",
            "training loss: 1.1745563745498657 [44800/60000]\n",
            "training loss: 1.1171191930770874 [51200/60000]\n",
            "training loss: 1.0569096803665161 [57600/60000]\n",
            "Correct Predictions: 57.65%, Average Loss: 1.6847355002164839%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 212\n",
            "training loss: 1.1617100238800049 [0/60000]\n",
            "training loss: 1.074217677116394 [6400/60000]\n",
            "training loss: 1.1420990228652954 [12800/60000]\n",
            "training loss: 1.0588957071304321 [19200/60000]\n",
            "training loss: 0.7072244882583618 [25600/60000]\n",
            "training loss: 1.2504040002822876 [32000/60000]\n",
            "training loss: 0.9277595281600952 [38400/60000]\n",
            "training loss: 1.1738665103912354 [44800/60000]\n",
            "training loss: 1.1167232990264893 [51200/60000]\n",
            "training loss: 1.0561600923538208 [57600/60000]\n",
            "Correct Predictions: 57.65%, Average Loss: 1.6843909305334093%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 213\n",
            "training loss: 1.1614925861358643 [0/60000]\n",
            "training loss: 1.073642611503601 [6400/60000]\n",
            "training loss: 1.1416407823562622 [12800/60000]\n",
            "training loss: 1.0585615634918213 [19200/60000]\n",
            "training loss: 0.7069788575172424 [25600/60000]\n",
            "training loss: 1.2504308223724365 [32000/60000]\n",
            "training loss: 0.9271848797798157 [38400/60000]\n",
            "training loss: 1.1733036041259766 [44800/60000]\n",
            "training loss: 1.1164554357528687 [51200/60000]\n",
            "training loss: 1.0555676221847534 [57600/60000]\n",
            "Correct Predictions: 57.65%, Average Loss: 1.6841041523218154%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 214\n",
            "training loss: 1.1612025499343872 [0/60000]\n",
            "training loss: 1.0730196237564087 [6400/60000]\n",
            "training loss: 1.14126718044281 [12800/60000]\n",
            "training loss: 1.0582387447357178 [19200/60000]\n",
            "training loss: 0.7060110569000244 [25600/60000]\n",
            "training loss: 1.2503217458724976 [32000/60000]\n",
            "training loss: 0.9265164732933044 [38400/60000]\n",
            "training loss: 1.1726664304733276 [44800/60000]\n",
            "training loss: 1.1160643100738525 [51200/60000]\n",
            "training loss: 1.0549201965332031 [57600/60000]\n",
            "Correct Predictions: 57.66%, Average Loss: 1.6837764394283294%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 215\n",
            "training loss: 1.1609013080596924 [0/60000]\n",
            "training loss: 1.0723532438278198 [6400/60000]\n",
            "training loss: 1.1409823894500732 [12800/60000]\n",
            "training loss: 1.057849645614624 [19200/60000]\n",
            "training loss: 0.7056110501289368 [25600/60000]\n",
            "training loss: 1.2502899169921875 [32000/60000]\n",
            "training loss: 0.9260993003845215 [38400/60000]\n",
            "training loss: 1.171966552734375 [44800/60000]\n",
            "training loss: 1.115675926208496 [51200/60000]\n",
            "training loss: 1.0543371438980103 [57600/60000]\n",
            "Correct Predictions: 57.66%, Average Loss: 1.6834674125909803%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 216\n",
            "training loss: 1.1605298519134521 [0/60000]\n",
            "training loss: 1.0718274116516113 [6400/60000]\n",
            "training loss: 1.1406590938568115 [12800/60000]\n",
            "training loss: 1.0575586557388306 [19200/60000]\n",
            "training loss: 0.7054891586303711 [25600/60000]\n",
            "training loss: 1.2502042055130005 [32000/60000]\n",
            "training loss: 0.9259770512580872 [38400/60000]\n",
            "training loss: 1.1714956760406494 [44800/60000]\n",
            "training loss: 1.1152008771896362 [51200/60000]\n",
            "training loss: 1.0539604425430298 [57600/60000]\n",
            "Correct Predictions: 57.65%, Average Loss: 1.6831458330154419%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 217\n",
            "training loss: 1.1601766347885132 [0/60000]\n",
            "training loss: 1.0713063478469849 [6400/60000]\n",
            "training loss: 1.1402790546417236 [12800/60000]\n",
            "training loss: 1.0571937561035156 [19200/60000]\n",
            "training loss: 0.7053134441375732 [25600/60000]\n",
            "training loss: 1.2502094507217407 [32000/60000]\n",
            "training loss: 0.9255430102348328 [38400/60000]\n",
            "training loss: 1.1708968877792358 [44800/60000]\n",
            "training loss: 1.1148492097854614 [51200/60000]\n",
            "training loss: 1.0534069538116455 [57600/60000]\n",
            "Correct Predictions: 57.65%, Average Loss: 1.682822210788727%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 218\n",
            "training loss: 1.1598087549209595 [0/60000]\n",
            "training loss: 1.070779800415039 [6400/60000]\n",
            "training loss: 1.1400009393692017 [12800/60000]\n",
            "training loss: 1.056931972503662 [19200/60000]\n",
            "training loss: 0.7053003311157227 [25600/60000]\n",
            "training loss: 1.24994957447052 [32000/60000]\n",
            "training loss: 0.9251051545143127 [38400/60000]\n",
            "training loss: 1.1699734926223755 [44800/60000]\n",
            "training loss: 1.1145360469818115 [51200/60000]\n",
            "training loss: 1.052900791168213 [57600/60000]\n",
            "Correct Predictions: 57.66%, Average Loss: 1.6824584740400315%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 219\n",
            "training loss: 1.1598243713378906 [0/60000]\n",
            "training loss: 1.070184350013733 [6400/60000]\n",
            "training loss: 1.139699101448059 [12800/60000]\n",
            "training loss: 1.0565775632858276 [19200/60000]\n",
            "training loss: 0.7051694989204407 [25600/60000]\n",
            "training loss: 1.2496551275253296 [32000/60000]\n",
            "training loss: 0.9246396422386169 [38400/60000]\n",
            "training loss: 1.169411301612854 [44800/60000]\n",
            "training loss: 1.1142385005950928 [51200/60000]\n",
            "training loss: 1.0522527694702148 [57600/60000]\n",
            "Correct Predictions: 57.68%, Average Loss: 1.682205911874771%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 220\n",
            "training loss: 1.159164309501648 [0/60000]\n",
            "training loss: 1.0696852207183838 [6400/60000]\n",
            "training loss: 1.1393890380859375 [12800/60000]\n",
            "training loss: 1.0561742782592773 [19200/60000]\n",
            "training loss: 0.7049954533576965 [25600/60000]\n",
            "training loss: 1.2495651245117188 [32000/60000]\n",
            "training loss: 0.924261212348938 [38400/60000]\n",
            "training loss: 1.168870210647583 [44800/60000]\n",
            "training loss: 1.113864779472351 [51200/60000]\n",
            "training loss: 1.0519086122512817 [57600/60000]\n",
            "Correct Predictions: 57.68%, Average Loss: 1.68183360517025%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 221\n",
            "training loss: 1.1591405868530273 [0/60000]\n",
            "training loss: 1.069069743156433 [6400/60000]\n",
            "training loss: 1.1391558647155762 [12800/60000]\n",
            "training loss: 1.055889368057251 [19200/60000]\n",
            "training loss: 0.7039164304733276 [25600/60000]\n",
            "training loss: 1.2495616674423218 [32000/60000]\n",
            "training loss: 0.9234492182731628 [38400/60000]\n",
            "training loss: 1.168662667274475 [44800/60000]\n",
            "training loss: 1.1134124994277954 [51200/60000]\n",
            "training loss: 1.0512436628341675 [57600/60000]\n",
            "Correct Predictions: 57.68%, Average Loss: 1.68150100171566%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 222\n",
            "training loss: 1.1587505340576172 [0/60000]\n",
            "training loss: 1.0685508251190186 [6400/60000]\n",
            "training loss: 1.1388620138168335 [12800/60000]\n",
            "training loss: 1.0556154251098633 [19200/60000]\n",
            "training loss: 0.7037326097488403 [25600/60000]\n",
            "training loss: 1.2495100498199463 [32000/60000]\n",
            "training loss: 0.9228828549385071 [38400/60000]\n",
            "training loss: 1.16806161403656 [44800/60000]\n",
            "training loss: 1.113011360168457 [51200/60000]\n",
            "training loss: 1.0514857769012451 [57600/60000]\n",
            "Correct Predictions: 57.68%, Average Loss: 1.6811600071191788%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 223\n",
            "training loss: 1.158272624015808 [0/60000]\n",
            "training loss: 1.0679726600646973 [6400/60000]\n",
            "training loss: 1.1381078958511353 [12800/60000]\n",
            "training loss: 1.0552270412445068 [19200/60000]\n",
            "training loss: 0.7036078572273254 [25600/60000]\n",
            "training loss: 1.2495696544647217 [32000/60000]\n",
            "training loss: 0.9223117828369141 [38400/60000]\n",
            "training loss: 1.1677308082580566 [44800/60000]\n",
            "training loss: 1.112414002418518 [51200/60000]\n",
            "training loss: 1.0508028268814087 [57600/60000]\n",
            "Correct Predictions: 57.699999999999996%, Average Loss: 1.6808306062221527%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 224\n",
            "training loss: 1.1578137874603271 [0/60000]\n",
            "training loss: 1.0674855709075928 [6400/60000]\n",
            "training loss: 1.1377989053726196 [12800/60000]\n",
            "training loss: 1.054936170578003 [19200/60000]\n",
            "training loss: 0.703428328037262 [25600/60000]\n",
            "training loss: 1.2494648694992065 [32000/60000]\n",
            "training loss: 0.921763002872467 [38400/60000]\n",
            "training loss: 1.167156457901001 [44800/60000]\n",
            "training loss: 1.1120166778564453 [51200/60000]\n",
            "training loss: 1.0504709482192993 [57600/60000]\n",
            "Correct Predictions: 57.730000000000004%, Average Loss: 1.6805188769102097%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 225\n",
            "training loss: 1.157329797744751 [0/60000]\n",
            "training loss: 1.0669196844100952 [6400/60000]\n",
            "training loss: 1.137534260749817 [12800/60000]\n",
            "training loss: 1.054621696472168 [19200/60000]\n",
            "training loss: 0.7031413316726685 [25600/60000]\n",
            "training loss: 1.2491590976715088 [32000/60000]\n",
            "training loss: 0.921431303024292 [38400/60000]\n",
            "training loss: 1.166718602180481 [44800/60000]\n",
            "training loss: 1.111617922782898 [51200/60000]\n",
            "training loss: 1.0497390031814575 [57600/60000]\n",
            "Correct Predictions: 57.74%, Average Loss: 1.680190806388855%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 226\n",
            "training loss: 1.1569839715957642 [0/60000]\n",
            "training loss: 1.0664422512054443 [6400/60000]\n",
            "training loss: 1.1372103691101074 [12800/60000]\n",
            "training loss: 1.0542824268341064 [19200/60000]\n",
            "training loss: 0.7028340697288513 [25600/60000]\n",
            "training loss: 1.2491072416305542 [32000/60000]\n",
            "training loss: 0.9212900400161743 [38400/60000]\n",
            "training loss: 1.1661388874053955 [44800/60000]\n",
            "training loss: 1.1113032102584839 [51200/60000]\n",
            "training loss: 1.0490710735321045 [57600/60000]\n",
            "Correct Predictions: 57.74%, Average Loss: 1.6798916691541672%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 227\n",
            "training loss: 1.1566529273986816 [0/60000]\n",
            "training loss: 1.0658435821533203 [6400/60000]\n",
            "training loss: 1.13706636428833 [12800/60000]\n",
            "training loss: 1.0539250373840332 [19200/60000]\n",
            "training loss: 0.7026419639587402 [25600/60000]\n",
            "training loss: 1.2489686012268066 [32000/60000]\n",
            "training loss: 0.9209019541740417 [38400/60000]\n",
            "training loss: 1.1655620336532593 [44800/60000]\n",
            "training loss: 1.111010193824768 [51200/60000]\n",
            "training loss: 1.0486721992492676 [57600/60000]\n",
            "Correct Predictions: 57.75%, Average Loss: 1.6795627379417417%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 228\n",
            "training loss: 1.1562961339950562 [0/60000]\n",
            "training loss: 1.0653356313705444 [6400/60000]\n",
            "training loss: 1.136672854423523 [12800/60000]\n",
            "training loss: 1.053688883781433 [19200/60000]\n",
            "training loss: 0.7022178173065186 [25600/60000]\n",
            "training loss: 1.2491612434387207 [32000/60000]\n",
            "training loss: 0.9205541014671326 [38400/60000]\n",
            "training loss: 1.1649824380874634 [44800/60000]\n",
            "training loss: 1.110659122467041 [51200/60000]\n",
            "training loss: 1.0479984283447266 [57600/60000]\n",
            "Correct Predictions: 57.75%, Average Loss: 1.6792616719007492%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 229\n",
            "training loss: 1.1558774709701538 [0/60000]\n",
            "training loss: 1.0648428201675415 [6400/60000]\n",
            "training loss: 1.1364445686340332 [12800/60000]\n",
            "training loss: 1.053452968597412 [19200/60000]\n",
            "training loss: 0.7018834948539734 [25600/60000]\n",
            "training loss: 1.2491182088851929 [32000/60000]\n",
            "training loss: 0.9200331568717957 [38400/60000]\n",
            "training loss: 1.1644227504730225 [44800/60000]\n",
            "training loss: 1.1101397275924683 [51200/60000]\n",
            "training loss: 1.0468859672546387 [57600/60000]\n",
            "Correct Predictions: 57.769999999999996%, Average Loss: 1.67907195687294%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 230\n",
            "training loss: 1.1549166440963745 [0/60000]\n",
            "training loss: 1.0644917488098145 [6400/60000]\n",
            "training loss: 1.1361448764801025 [12800/60000]\n",
            "training loss: 1.0531396865844727 [19200/60000]\n",
            "training loss: 0.7000309228897095 [25600/60000]\n",
            "training loss: 1.2491185665130615 [32000/60000]\n",
            "training loss: 0.9192230105400085 [38400/60000]\n",
            "training loss: 1.1639608144760132 [44800/60000]\n",
            "training loss: 1.1098988056182861 [51200/60000]\n",
            "training loss: 1.046129584312439 [57600/60000]\n",
            "Correct Predictions: 57.76%, Average Loss: 1.678749815225601%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 231\n",
            "training loss: 1.1545354127883911 [0/60000]\n",
            "training loss: 1.064111590385437 [6400/60000]\n",
            "training loss: 1.135907769203186 [12800/60000]\n",
            "training loss: 1.0528193712234497 [19200/60000]\n",
            "training loss: 0.6994887590408325 [25600/60000]\n",
            "training loss: 1.2490100860595703 [32000/60000]\n",
            "training loss: 0.9185647368431091 [38400/60000]\n",
            "training loss: 1.1634458303451538 [44800/60000]\n",
            "training loss: 1.1097111701965332 [51200/60000]\n",
            "training loss: 1.0455436706542969 [57600/60000]\n",
            "Correct Predictions: 57.76%, Average Loss: 1.6784503501653674%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 232\n",
            "training loss: 1.1542489528656006 [0/60000]\n",
            "training loss: 1.0636260509490967 [6400/60000]\n",
            "training loss: 1.1356931924819946 [12800/60000]\n",
            "training loss: 1.0525245666503906 [19200/60000]\n",
            "training loss: 0.6990243792533875 [25600/60000]\n",
            "training loss: 1.2490230798721313 [32000/60000]\n",
            "training loss: 0.9178985357284546 [38400/60000]\n",
            "training loss: 1.1628806591033936 [44800/60000]\n",
            "training loss: 1.109422206878662 [51200/60000]\n",
            "training loss: 1.044804334640503 [57600/60000]\n",
            "Correct Predictions: 57.76%, Average Loss: 1.678156795501709%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 233\n",
            "training loss: 1.1539057493209839 [0/60000]\n",
            "training loss: 1.0632047653198242 [6400/60000]\n",
            "training loss: 1.1353590488433838 [12800/60000]\n",
            "training loss: 1.052250862121582 [19200/60000]\n",
            "training loss: 0.6985222101211548 [25600/60000]\n",
            "training loss: 1.248854160308838 [32000/60000]\n",
            "training loss: 0.9174689650535583 [38400/60000]\n",
            "training loss: 1.162237286567688 [44800/60000]\n",
            "training loss: 1.109061360359192 [51200/60000]\n",
            "training loss: 1.0442620515823364 [57600/60000]\n",
            "Correct Predictions: 57.78%, Average Loss: 1.6778883188962936%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 234\n",
            "training loss: 1.1534963846206665 [0/60000]\n",
            "training loss: 1.0628361701965332 [6400/60000]\n",
            "training loss: 1.13512122631073 [12800/60000]\n",
            "training loss: 1.0518887042999268 [19200/60000]\n",
            "training loss: 0.6981625556945801 [25600/60000]\n",
            "training loss: 1.2487096786499023 [32000/60000]\n",
            "training loss: 0.9169184565544128 [38400/60000]\n",
            "training loss: 1.1617017984390259 [44800/60000]\n",
            "training loss: 1.1087151765823364 [51200/60000]\n",
            "training loss: 1.0437155961990356 [57600/60000]\n",
            "Correct Predictions: 57.78%, Average Loss: 1.6776163113117217%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 235\n",
            "training loss: 1.1529585123062134 [0/60000]\n",
            "training loss: 1.0623902082443237 [6400/60000]\n",
            "training loss: 1.1349554061889648 [12800/60000]\n",
            "training loss: 1.0515483617782593 [19200/60000]\n",
            "training loss: 0.6980437636375427 [25600/60000]\n",
            "training loss: 1.2485110759735107 [32000/60000]\n",
            "training loss: 0.9165993928909302 [38400/60000]\n",
            "training loss: 1.1614277362823486 [44800/60000]\n",
            "training loss: 1.1084643602371216 [51200/60000]\n",
            "training loss: 1.04305100440979 [57600/60000]\n",
            "Correct Predictions: 57.79%, Average Loss: 1.6773628586530684%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 236\n",
            "training loss: 1.1524077653884888 [0/60000]\n",
            "training loss: 1.0619100332260132 [6400/60000]\n",
            "training loss: 1.1347142457962036 [12800/60000]\n",
            "training loss: 1.0512840747833252 [19200/60000]\n",
            "training loss: 0.6976185441017151 [25600/60000]\n",
            "training loss: 1.2483925819396973 [32000/60000]\n",
            "training loss: 0.9160500764846802 [38400/60000]\n",
            "training loss: 1.160878300666809 [44800/60000]\n",
            "training loss: 1.1080135107040405 [51200/60000]\n",
            "training loss: 1.0421812534332275 [57600/60000]\n",
            "Correct Predictions: 57.8%, Average Loss: 1.6770654439926147%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 237\n",
            "training loss: 1.1519713401794434 [0/60000]\n",
            "training loss: 1.0613898038864136 [6400/60000]\n",
            "training loss: 1.1343960762023926 [12800/60000]\n",
            "training loss: 1.0510367155075073 [19200/60000]\n",
            "training loss: 0.6973424553871155 [25600/60000]\n",
            "training loss: 1.2480944395065308 [32000/60000]\n",
            "training loss: 0.9155735373497009 [38400/60000]\n",
            "training loss: 1.1602790355682373 [44800/60000]\n",
            "training loss: 1.107664942741394 [51200/60000]\n",
            "training loss: 1.041473388671875 [57600/60000]\n",
            "Correct Predictions: 57.8%, Average Loss: 1.6767751532793047%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 238\n",
            "training loss: 1.1515915393829346 [0/60000]\n",
            "training loss: 1.060875654220581 [6400/60000]\n",
            "training loss: 1.1341489553451538 [12800/60000]\n",
            "training loss: 1.050767421722412 [19200/60000]\n",
            "training loss: 0.6970449090003967 [25600/60000]\n",
            "training loss: 1.2478433847427368 [32000/60000]\n",
            "training loss: 0.9150586128234863 [38400/60000]\n",
            "training loss: 1.159744143486023 [44800/60000]\n",
            "training loss: 1.1073403358459473 [51200/60000]\n",
            "training loss: 1.041852593421936 [57600/60000]\n",
            "Correct Predictions: 57.82000000000001%, Average Loss: 1.6765112614631654%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 239\n",
            "training loss: 1.1512954235076904 [0/60000]\n",
            "training loss: 1.0603671073913574 [6400/60000]\n",
            "training loss: 1.133989930152893 [12800/60000]\n",
            "training loss: 1.050507664680481 [19200/60000]\n",
            "training loss: 0.6965943574905396 [25600/60000]\n",
            "training loss: 1.2478398084640503 [32000/60000]\n",
            "training loss: 0.9144163131713867 [38400/60000]\n",
            "training loss: 1.1592265367507935 [44800/60000]\n",
            "training loss: 1.1069695949554443 [51200/60000]\n",
            "training loss: 1.0411632061004639 [57600/60000]\n",
            "Correct Predictions: 57.82000000000001%, Average Loss: 1.676242578625679%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 240\n",
            "training loss: 1.1508793830871582 [0/60000]\n",
            "training loss: 1.0599110126495361 [6400/60000]\n",
            "training loss: 1.1336675882339478 [12800/60000]\n",
            "training loss: 1.0501619577407837 [19200/60000]\n",
            "training loss: 0.6963194012641907 [25600/60000]\n",
            "training loss: 1.2477970123291016 [32000/60000]\n",
            "training loss: 0.9141538739204407 [38400/60000]\n",
            "training loss: 1.1587051153182983 [44800/60000]\n",
            "training loss: 1.1067789793014526 [51200/60000]\n",
            "training loss: 1.0410960912704468 [57600/60000]\n",
            "Correct Predictions: 57.82000000000001%, Average Loss: 1.6759491431713105%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 241\n",
            "training loss: 1.150456190109253 [0/60000]\n",
            "training loss: 1.0594478845596313 [6400/60000]\n",
            "training loss: 1.1335127353668213 [12800/60000]\n",
            "training loss: 1.0500003099441528 [19200/60000]\n",
            "training loss: 0.6960650682449341 [25600/60000]\n",
            "training loss: 1.2478678226470947 [32000/60000]\n",
            "training loss: 0.914021372795105 [38400/60000]\n",
            "training loss: 1.1582006216049194 [44800/60000]\n",
            "training loss: 1.106391429901123 [51200/60000]\n",
            "training loss: 1.0397613048553467 [57600/60000]\n",
            "Correct Predictions: 57.830000000000005%, Average Loss: 1.6756487947702408%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 242\n",
            "training loss: 1.1502394676208496 [0/60000]\n",
            "training loss: 1.0590308904647827 [6400/60000]\n",
            "training loss: 1.1331894397735596 [12800/60000]\n",
            "training loss: 1.049796462059021 [19200/60000]\n",
            "training loss: 0.6957257986068726 [25600/60000]\n",
            "training loss: 1.2478148937225342 [32000/60000]\n",
            "training loss: 0.9136490821838379 [38400/60000]\n",
            "training loss: 1.1576385498046875 [44800/60000]\n",
            "training loss: 1.105999231338501 [51200/60000]\n",
            "training loss: 1.038256287574768 [57600/60000]\n",
            "Correct Predictions: 57.830000000000005%, Average Loss: 1.6753732347488404%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 243\n",
            "training loss: 1.1499172449111938 [0/60000]\n",
            "training loss: 1.0586843490600586 [6400/60000]\n",
            "training loss: 1.1327847242355347 [12800/60000]\n",
            "training loss: 1.0495281219482422 [19200/60000]\n",
            "training loss: 0.695265531539917 [25600/60000]\n",
            "training loss: 1.2476849555969238 [32000/60000]\n",
            "training loss: 0.9133556485176086 [38400/60000]\n",
            "training loss: 1.1576101779937744 [44800/60000]\n",
            "training loss: 1.1056408882141113 [51200/60000]\n",
            "training loss: 1.038116693496704 [57600/60000]\n",
            "Correct Predictions: 57.84%, Average Loss: 1.6750861597061157%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 244\n",
            "training loss: 1.1494454145431519 [0/60000]\n",
            "training loss: 1.0583771467208862 [6400/60000]\n",
            "training loss: 1.1323703527450562 [12800/60000]\n",
            "training loss: 1.0491946935653687 [19200/60000]\n",
            "training loss: 0.695186972618103 [25600/60000]\n",
            "training loss: 1.2473963499069214 [32000/60000]\n",
            "training loss: 0.9121740460395813 [38400/60000]\n",
            "training loss: 1.1571502685546875 [44800/60000]\n",
            "training loss: 1.1053061485290527 [51200/60000]\n",
            "training loss: 1.0374497175216675 [57600/60000]\n",
            "Correct Predictions: 57.85%, Average Loss: 1.674798029065132%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 245\n",
            "training loss: 1.1490392684936523 [0/60000]\n",
            "training loss: 1.0580744743347168 [6400/60000]\n",
            "training loss: 1.1319879293441772 [12800/60000]\n",
            "training loss: 1.0488895177841187 [19200/60000]\n",
            "training loss: 0.69480299949646 [25600/60000]\n",
            "training loss: 1.247321367263794 [32000/60000]\n",
            "training loss: 0.9113489389419556 [38400/60000]\n",
            "training loss: 1.1566928625106812 [44800/60000]\n",
            "training loss: 1.1049473285675049 [51200/60000]\n",
            "training loss: 1.0366276502609253 [57600/60000]\n",
            "Correct Predictions: 57.85%, Average Loss: 1.6750128430128095%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 246\n",
            "training loss: 1.148733377456665 [0/60000]\n",
            "training loss: 1.0577173233032227 [6400/60000]\n",
            "training loss: 1.1315627098083496 [12800/60000]\n",
            "training loss: 1.0485390424728394 [19200/60000]\n",
            "training loss: 0.6944509744644165 [25600/60000]\n",
            "training loss: 1.2473104000091553 [32000/60000]\n",
            "training loss: 0.9101715683937073 [38400/60000]\n",
            "training loss: 1.1563098430633545 [44800/60000]\n",
            "training loss: 1.104581594467163 [51200/60000]\n",
            "training loss: 1.0358079671859741 [57600/60000]\n",
            "Correct Predictions: 57.86%, Average Loss: 1.6746244180202485%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 247\n",
            "training loss: 1.1484134197235107 [0/60000]\n",
            "training loss: 1.0573283433914185 [6400/60000]\n",
            "training loss: 1.1312251091003418 [12800/60000]\n",
            "training loss: 1.048274040222168 [19200/60000]\n",
            "training loss: 0.6940213441848755 [25600/60000]\n",
            "training loss: 1.2472035884857178 [32000/60000]\n",
            "training loss: 0.9093716740608215 [38400/60000]\n",
            "training loss: 1.1559151411056519 [44800/60000]\n",
            "training loss: 1.1041615009307861 [51200/60000]\n",
            "training loss: 1.0349609851837158 [57600/60000]\n",
            "Correct Predictions: 57.87%, Average Loss: 1.6743709462881087%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 248\n",
            "training loss: 1.148013710975647 [0/60000]\n",
            "training loss: 1.057036280632019 [6400/60000]\n",
            "training loss: 1.130816102027893 [12800/60000]\n",
            "training loss: 1.047999620437622 [19200/60000]\n",
            "training loss: 0.6937064528465271 [25600/60000]\n",
            "training loss: 1.2470508813858032 [32000/60000]\n",
            "training loss: 0.9086604118347168 [38400/60000]\n",
            "training loss: 1.1554697751998901 [44800/60000]\n",
            "training loss: 1.1038482189178467 [51200/60000]\n",
            "training loss: 1.0343589782714844 [57600/60000]\n",
            "Correct Predictions: 57.87%, Average Loss: 1.6741367959976197%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 249\n",
            "training loss: 1.1476188898086548 [0/60000]\n",
            "training loss: 1.0567107200622559 [6400/60000]\n",
            "training loss: 1.13052499294281 [12800/60000]\n",
            "training loss: 1.047777533531189 [19200/60000]\n",
            "training loss: 0.6933470964431763 [25600/60000]\n",
            "training loss: 1.2471270561218262 [32000/60000]\n",
            "training loss: 0.9082456827163696 [38400/60000]\n",
            "training loss: 1.155066728591919 [44800/60000]\n",
            "training loss: 1.1035364866256714 [51200/60000]\n",
            "training loss: 1.0336377620697021 [57600/60000]\n",
            "Correct Predictions: 57.879999999999995%, Average Loss: 1.6738474434614181%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 250\n",
            "training loss: 1.1471176147460938 [0/60000]\n",
            "training loss: 1.056078553199768 [6400/60000]\n",
            "training loss: 1.129988193511963 [12800/60000]\n",
            "training loss: 1.0475330352783203 [19200/60000]\n",
            "training loss: 0.69286048412323 [25600/60000]\n",
            "training loss: 1.2469749450683594 [32000/60000]\n",
            "training loss: 0.9076570868492126 [38400/60000]\n",
            "training loss: 1.1547610759735107 [44800/60000]\n",
            "training loss: 1.1032578945159912 [51200/60000]\n",
            "training loss: 1.0331491231918335 [57600/60000]\n",
            "Correct Predictions: 57.89%, Average Loss: 1.6735638159513473%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 251\n",
            "training loss: 1.1466466188430786 [0/60000]\n",
            "training loss: 1.0557849407196045 [6400/60000]\n",
            "training loss: 1.1295222043991089 [12800/60000]\n",
            "training loss: 1.0473036766052246 [19200/60000]\n",
            "training loss: 0.6925072073936462 [25600/60000]\n",
            "training loss: 1.2472103834152222 [32000/60000]\n",
            "training loss: 0.9073051810264587 [38400/60000]\n",
            "training loss: 1.1544281244277954 [44800/60000]\n",
            "training loss: 1.1029671430587769 [51200/60000]\n",
            "training loss: 1.0322728157043457 [57600/60000]\n",
            "Correct Predictions: 57.89%, Average Loss: 1.6733413201570508%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 252\n",
            "training loss: 1.1462764739990234 [0/60000]\n",
            "training loss: 1.0554906129837036 [6400/60000]\n",
            "training loss: 1.1292088031768799 [12800/60000]\n",
            "training loss: 1.047075867652893 [19200/60000]\n",
            "training loss: 0.6921602487564087 [25600/60000]\n",
            "training loss: 1.2470961809158325 [32000/60000]\n",
            "training loss: 0.9064903259277344 [38400/60000]\n",
            "training loss: 1.1539326906204224 [44800/60000]\n",
            "training loss: 1.1027207374572754 [51200/60000]\n",
            "training loss: 1.0315370559692383 [57600/60000]\n",
            "Correct Predictions: 57.91%, Average Loss: 1.673071543574333%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 253\n",
            "training loss: 1.1460682153701782 [0/60000]\n",
            "training loss: 1.0554074048995972 [6400/60000]\n",
            "training loss: 1.1287769079208374 [12800/60000]\n",
            "training loss: 1.046900749206543 [19200/60000]\n",
            "training loss: 0.6918904781341553 [25600/60000]\n",
            "training loss: 1.246937870979309 [32000/60000]\n",
            "training loss: 0.9058955907821655 [38400/60000]\n",
            "training loss: 1.1534597873687744 [44800/60000]\n",
            "training loss: 1.1024889945983887 [51200/60000]\n",
            "training loss: 1.0308623313903809 [57600/60000]\n",
            "Correct Predictions: 57.91%, Average Loss: 1.6728209072351456%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 254\n",
            "training loss: 1.1456069946289062 [0/60000]\n",
            "training loss: 1.055161952972412 [6400/60000]\n",
            "training loss: 1.1283930540084839 [12800/60000]\n",
            "training loss: 1.046694278717041 [19200/60000]\n",
            "training loss: 0.6915822625160217 [25600/60000]\n",
            "training loss: 1.2467933893203735 [32000/60000]\n",
            "training loss: 0.9044581651687622 [38400/60000]\n",
            "training loss: 1.1514177322387695 [44800/60000]\n",
            "training loss: 1.1023911237716675 [51200/60000]\n",
            "training loss: 1.0297497510910034 [57600/60000]\n",
            "Correct Predictions: 57.91%, Average Loss: 1.6725127232074737%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 255\n",
            "training loss: 1.145197868347168 [0/60000]\n",
            "training loss: 1.0548462867736816 [6400/60000]\n",
            "training loss: 1.127999186515808 [12800/60000]\n",
            "training loss: 1.0465110540390015 [19200/60000]\n",
            "training loss: 0.6906588077545166 [25600/60000]\n",
            "training loss: 1.2467290163040161 [32000/60000]\n",
            "training loss: 0.9035691618919373 [38400/60000]\n",
            "training loss: 1.151017665863037 [44800/60000]\n",
            "training loss: 1.1021506786346436 [51200/60000]\n",
            "training loss: 1.028963327407837 [57600/60000]\n",
            "Correct Predictions: 57.91%, Average Loss: 1.6722589832544328%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 256\n",
            "training loss: 1.1448715925216675 [0/60000]\n",
            "training loss: 1.0546388626098633 [6400/60000]\n",
            "training loss: 1.1277260780334473 [12800/60000]\n",
            "training loss: 1.0462850332260132 [19200/60000]\n",
            "training loss: 0.6902372241020203 [25600/60000]\n",
            "training loss: 1.2465933561325073 [32000/60000]\n",
            "training loss: 0.9029051065444946 [38400/60000]\n",
            "training loss: 1.150740146636963 [44800/60000]\n",
            "training loss: 1.1020311117172241 [51200/60000]\n",
            "training loss: 1.0282810926437378 [57600/60000]\n",
            "Correct Predictions: 57.93000000000001%, Average Loss: 1.6719946044683458%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 257\n",
            "training loss: 1.1445367336273193 [0/60000]\n",
            "training loss: 1.054423451423645 [6400/60000]\n",
            "training loss: 1.1273086071014404 [12800/60000]\n",
            "training loss: 1.0460853576660156 [19200/60000]\n",
            "training loss: 0.6896126866340637 [25600/60000]\n",
            "training loss: 1.2465611696243286 [32000/60000]\n",
            "training loss: 0.9023388028144836 [38400/60000]\n",
            "training loss: 1.1504701375961304 [44800/60000]\n",
            "training loss: 1.1017863750457764 [51200/60000]\n",
            "training loss: 1.0274864435195923 [57600/60000]\n",
            "Correct Predictions: 57.93000000000001%, Average Loss: 1.6717228722572326%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 258\n",
            "training loss: 1.1441149711608887 [0/60000]\n",
            "training loss: 1.0541633367538452 [6400/60000]\n",
            "training loss: 1.1269625425338745 [12800/60000]\n",
            "training loss: 1.0458921194076538 [19200/60000]\n",
            "training loss: 0.6893416047096252 [25600/60000]\n",
            "training loss: 1.2463829517364502 [32000/60000]\n",
            "training loss: 0.9018040299415588 [38400/60000]\n",
            "training loss: 1.1501468420028687 [44800/60000]\n",
            "training loss: 1.101529598236084 [51200/60000]\n",
            "training loss: 1.026903510093689 [57600/60000]\n",
            "Correct Predictions: 57.93000000000001%, Average Loss: 1.6714650934934616%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 259\n",
            "training loss: 1.1436878442764282 [0/60000]\n",
            "training loss: 1.0539050102233887 [6400/60000]\n",
            "training loss: 1.1266717910766602 [12800/60000]\n",
            "training loss: 1.0458282232284546 [19200/60000]\n",
            "training loss: 0.6888713836669922 [25600/60000]\n",
            "training loss: 1.2460912466049194 [32000/60000]\n",
            "training loss: 0.9014788866043091 [38400/60000]\n",
            "training loss: 1.1498737335205078 [44800/60000]\n",
            "training loss: 1.1013989448547363 [51200/60000]\n",
            "training loss: 1.0261868238449097 [57600/60000]\n",
            "Correct Predictions: 57.92%, Average Loss: 1.671253558397293%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 260\n",
            "training loss: 1.1435304880142212 [0/60000]\n",
            "training loss: 1.0537612438201904 [6400/60000]\n",
            "training loss: 1.1262811422348022 [12800/60000]\n",
            "training loss: 1.0455801486968994 [19200/60000]\n",
            "training loss: 0.6886235475540161 [25600/60000]\n",
            "training loss: 1.245945930480957 [32000/60000]\n",
            "training loss: 0.9008603096008301 [38400/60000]\n",
            "training loss: 1.1495195627212524 [44800/60000]\n",
            "training loss: 1.1011500358581543 [51200/60000]\n",
            "training loss: 1.0255825519561768 [57600/60000]\n",
            "Correct Predictions: 57.92%, Average Loss: 1.6710379201173784%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 261\n",
            "training loss: 1.143163800239563 [0/60000]\n",
            "training loss: 1.0534452199935913 [6400/60000]\n",
            "training loss: 1.1259440183639526 [12800/60000]\n",
            "training loss: 1.0454754829406738 [19200/60000]\n",
            "training loss: 0.688401997089386 [25600/60000]\n",
            "training loss: 1.2457994222640991 [32000/60000]\n",
            "training loss: 0.9002240896224976 [38400/60000]\n",
            "training loss: 1.1491634845733643 [44800/60000]\n",
            "training loss: 1.101008653640747 [51200/60000]\n",
            "training loss: 1.0250197649002075 [57600/60000]\n",
            "Correct Predictions: 57.92%, Average Loss: 1.6708795511722565%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 262\n",
            "training loss: 1.142831563949585 [0/60000]\n",
            "training loss: 1.0533863306045532 [6400/60000]\n",
            "training loss: 1.1255961656570435 [12800/60000]\n",
            "training loss: 1.045333743095398 [19200/60000]\n",
            "training loss: 0.688076913356781 [25600/60000]\n",
            "training loss: 1.2456382513046265 [32000/60000]\n",
            "training loss: 0.8998354077339172 [38400/60000]\n",
            "training loss: 1.1487725973129272 [44800/60000]\n",
            "training loss: 1.1008433103561401 [51200/60000]\n",
            "training loss: 1.0244495868682861 [57600/60000]\n",
            "Correct Predictions: 57.93000000000001%, Average Loss: 1.6706439751386644%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 263\n",
            "training loss: 1.1422721147537231 [0/60000]\n",
            "training loss: 1.0532255172729492 [6400/60000]\n",
            "training loss: 1.1252163648605347 [12800/60000]\n",
            "training loss: 1.045153021812439 [19200/60000]\n",
            "training loss: 0.6879425644874573 [25600/60000]\n",
            "training loss: 1.2452822923660278 [32000/60000]\n",
            "training loss: 0.8991968631744385 [38400/60000]\n",
            "training loss: 1.1484653949737549 [44800/60000]\n",
            "training loss: 1.1005644798278809 [51200/60000]\n",
            "training loss: 1.0237832069396973 [57600/60000]\n",
            "Correct Predictions: 57.93000000000001%, Average Loss: 1.6704189479351044%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 264\n",
            "training loss: 1.1419003009796143 [0/60000]\n",
            "training loss: 1.053000569343567 [6400/60000]\n",
            "training loss: 1.124849796295166 [12800/60000]\n",
            "training loss: 1.044948697090149 [19200/60000]\n",
            "training loss: 0.6877481341362 [25600/60000]\n",
            "training loss: 1.245005488395691 [32000/60000]\n",
            "training loss: 0.8981953859329224 [38400/60000]\n",
            "training loss: 1.148174524307251 [44800/60000]\n",
            "training loss: 1.1003384590148926 [51200/60000]\n",
            "training loss: 1.0231082439422607 [57600/60000]\n",
            "Correct Predictions: 57.93000000000001%, Average Loss: 1.6701574224233628%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 265\n",
            "training loss: 1.1413544416427612 [0/60000]\n",
            "training loss: 1.052775263786316 [6400/60000]\n",
            "training loss: 1.1244244575500488 [12800/60000]\n",
            "training loss: 1.0447673797607422 [19200/60000]\n",
            "training loss: 0.6874147653579712 [25600/60000]\n",
            "training loss: 1.244978666305542 [32000/60000]\n",
            "training loss: 0.8975977301597595 [38400/60000]\n",
            "training loss: 1.1478241682052612 [44800/60000]\n",
            "training loss: 1.1002436876296997 [51200/60000]\n",
            "training loss: 1.0224093198776245 [57600/60000]\n",
            "Correct Predictions: 57.93000000000001%, Average Loss: 1.6699720895290375%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 266\n",
            "training loss: 1.1409599781036377 [0/60000]\n",
            "training loss: 1.0524423122406006 [6400/60000]\n",
            "training loss: 1.1240062713623047 [12800/60000]\n",
            "training loss: 1.0444040298461914 [19200/60000]\n",
            "training loss: 0.6869308352470398 [25600/60000]\n",
            "training loss: 1.2449572086334229 [32000/60000]\n",
            "training loss: 0.8969967365264893 [38400/60000]\n",
            "training loss: 1.1474509239196777 [44800/60000]\n",
            "training loss: 1.1000088453292847 [51200/60000]\n",
            "training loss: 1.021901249885559 [57600/60000]\n",
            "Correct Predictions: 57.940000000000005%, Average Loss: 1.6697352999448776%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 267\n",
            "training loss: 1.140358328819275 [0/60000]\n",
            "training loss: 1.0520923137664795 [6400/60000]\n",
            "training loss: 1.1235517263412476 [12800/60000]\n",
            "training loss: 1.0441703796386719 [19200/60000]\n",
            "training loss: 0.6868218779563904 [25600/60000]\n",
            "training loss: 1.2448316812515259 [32000/60000]\n",
            "training loss: 0.8964989185333252 [38400/60000]\n",
            "training loss: 1.147067666053772 [44800/60000]\n",
            "training loss: 1.0998121500015259 [51200/60000]\n",
            "training loss: 1.021503210067749 [57600/60000]\n",
            "Correct Predictions: 57.92%, Average Loss: 1.6695172733068464%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 268\n",
            "training loss: 1.1399953365325928 [0/60000]\n",
            "training loss: 1.0519638061523438 [6400/60000]\n",
            "training loss: 1.1230907440185547 [12800/60000]\n",
            "training loss: 1.043989658355713 [19200/60000]\n",
            "training loss: 0.6866585612297058 [25600/60000]\n",
            "training loss: 1.244668960571289 [32000/60000]\n",
            "training loss: 0.895844042301178 [38400/60000]\n",
            "training loss: 1.1467664241790771 [44800/60000]\n",
            "training loss: 1.1002748012542725 [51200/60000]\n",
            "training loss: 1.020821452140808 [57600/60000]\n",
            "Correct Predictions: 57.91%, Average Loss: 1.6692531019449235%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 269\n",
            "training loss: 1.1393382549285889 [0/60000]\n",
            "training loss: 1.051552176475525 [6400/60000]\n",
            "training loss: 1.1226423978805542 [12800/60000]\n",
            "training loss: 1.0438258647918701 [19200/60000]\n",
            "training loss: 0.6865301132202148 [25600/60000]\n",
            "training loss: 1.2445275783538818 [32000/60000]\n",
            "training loss: 0.8953533172607422 [38400/60000]\n",
            "training loss: 1.14643394947052 [44800/60000]\n",
            "training loss: 1.0999361276626587 [51200/60000]\n",
            "training loss: 1.0201047658920288 [57600/60000]\n",
            "Correct Predictions: 57.9%, Average Loss: 1.6690098708868026%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 270\n",
            "training loss: 1.138915777206421 [0/60000]\n",
            "training loss: 1.0513825416564941 [6400/60000]\n",
            "training loss: 1.1221874952316284 [12800/60000]\n",
            "training loss: 1.0436365604400635 [19200/60000]\n",
            "training loss: 0.6862494349479675 [25600/60000]\n",
            "training loss: 1.2445545196533203 [32000/60000]\n",
            "training loss: 0.894783079624176 [38400/60000]\n",
            "training loss: 1.1462054252624512 [44800/60000]\n",
            "training loss: 1.0999517440795898 [51200/60000]\n",
            "training loss: 1.0194528102874756 [57600/60000]\n",
            "Correct Predictions: 57.92%, Average Loss: 1.668830674290657%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 271\n",
            "training loss: 1.1383914947509766 [0/60000]\n",
            "training loss: 1.0511831045150757 [6400/60000]\n",
            "training loss: 1.1217563152313232 [12800/60000]\n",
            "training loss: 1.0434255599975586 [19200/60000]\n",
            "training loss: 0.6861255764961243 [25600/60000]\n",
            "training loss: 1.2443945407867432 [32000/60000]\n",
            "training loss: 0.8942281007766724 [38400/60000]\n",
            "training loss: 1.1459028720855713 [44800/60000]\n",
            "training loss: 1.0997004508972168 [51200/60000]\n",
            "training loss: 1.0189809799194336 [57600/60000]\n",
            "Correct Predictions: 57.92%, Average Loss: 1.6686256968975066%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 272\n",
            "training loss: 1.1378523111343384 [0/60000]\n",
            "training loss: 1.0508979558944702 [6400/60000]\n",
            "training loss: 1.121345043182373 [12800/60000]\n",
            "training loss: 1.043279767036438 [19200/60000]\n",
            "training loss: 0.6860260963439941 [25600/60000]\n",
            "training loss: 1.2442034482955933 [32000/60000]\n",
            "training loss: 0.8935940265655518 [38400/60000]\n",
            "training loss: 1.1456725597381592 [44800/60000]\n",
            "training loss: 1.099487066268921 [51200/60000]\n",
            "training loss: 1.0181375741958618 [57600/60000]\n",
            "Correct Predictions: 57.93000000000001%, Average Loss: 1.6684126740694045%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 273\n",
            "training loss: 1.137426733970642 [0/60000]\n",
            "training loss: 1.0508599281311035 [6400/60000]\n",
            "training loss: 1.121009111404419 [12800/60000]\n",
            "training loss: 1.0431866645812988 [19200/60000]\n",
            "training loss: 0.6857826113700867 [25600/60000]\n",
            "training loss: 1.2527098655700684 [32000/60000]\n",
            "training loss: 0.8934550881385803 [38400/60000]\n",
            "training loss: 1.14546799659729 [44800/60000]\n",
            "training loss: 1.09932541847229 [51200/60000]\n",
            "training loss: 1.0173932313919067 [57600/60000]\n",
            "Correct Predictions: 57.940000000000005%, Average Loss: 1.6681969690322878%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 274\n",
            "training loss: 1.1370397806167603 [0/60000]\n",
            "training loss: 1.0506373643875122 [6400/60000]\n",
            "training loss: 1.120544195175171 [12800/60000]\n",
            "training loss: 1.0430479049682617 [19200/60000]\n",
            "training loss: 0.6856521368026733 [25600/60000]\n",
            "training loss: 1.2528996467590332 [32000/60000]\n",
            "training loss: 0.8930165767669678 [38400/60000]\n",
            "training loss: 1.1451361179351807 [44800/60000]\n",
            "training loss: 1.0992026329040527 [51200/60000]\n",
            "training loss: 1.0165671110153198 [57600/60000]\n",
            "Correct Predictions: 57.940000000000005%, Average Loss: 1.6679970997571945%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 275\n",
            "training loss: 1.1366413831710815 [0/60000]\n",
            "training loss: 1.0504190921783447 [6400/60000]\n",
            "training loss: 1.1201107501983643 [12800/60000]\n",
            "training loss: 1.0428812503814697 [19200/60000]\n",
            "training loss: 0.685577929019928 [25600/60000]\n",
            "training loss: 1.2528736591339111 [32000/60000]\n",
            "training loss: 0.89396733045578 [38400/60000]\n",
            "training loss: 1.1449087858200073 [44800/60000]\n",
            "training loss: 1.0989036560058594 [51200/60000]\n",
            "training loss: 1.0160402059555054 [57600/60000]\n",
            "Correct Predictions: 57.940000000000005%, Average Loss: 1.6677424365282059%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 276\n",
            "training loss: 1.1362844705581665 [0/60000]\n",
            "training loss: 1.0503225326538086 [6400/60000]\n",
            "training loss: 1.11981201171875 [12800/60000]\n",
            "training loss: 1.0427473783493042 [19200/60000]\n",
            "training loss: 0.6849862933158875 [25600/60000]\n",
            "training loss: 1.2528319358825684 [32000/60000]\n",
            "training loss: 0.8934417366981506 [38400/60000]\n",
            "training loss: 1.1445581912994385 [44800/60000]\n",
            "training loss: 1.0989429950714111 [51200/60000]\n",
            "training loss: 1.0153236389160156 [57600/60000]\n",
            "Correct Predictions: 57.92%, Average Loss: 1.6675025379657746%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 277\n",
            "training loss: 1.1360151767730713 [0/60000]\n",
            "training loss: 1.050290584564209 [6400/60000]\n",
            "training loss: 1.1193208694458008 [12800/60000]\n",
            "training loss: 1.042708396911621 [19200/60000]\n",
            "training loss: 0.6850649118423462 [25600/60000]\n",
            "training loss: 1.2528258562088013 [32000/60000]\n",
            "training loss: 0.892826497554779 [38400/60000]\n",
            "training loss: 1.1442961692810059 [44800/60000]\n",
            "training loss: 1.0987387895584106 [51200/60000]\n",
            "training loss: 1.0146756172180176 [57600/60000]\n",
            "Correct Predictions: 57.92%, Average Loss: 1.667266362309456%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 278\n",
            "training loss: 1.1357176303863525 [0/60000]\n",
            "training loss: 1.0502668619155884 [6400/60000]\n",
            "training loss: 1.1189064979553223 [12800/60000]\n",
            "training loss: 1.0426162481307983 [19200/60000]\n",
            "training loss: 0.6847710609436035 [25600/60000]\n",
            "training loss: 1.2523967027664185 [32000/60000]\n",
            "training loss: 0.8924320340156555 [38400/60000]\n",
            "training loss: 1.1439307928085327 [44800/60000]\n",
            "training loss: 1.0986809730529785 [51200/60000]\n",
            "training loss: 1.0140806436538696 [57600/60000]\n",
            "Correct Predictions: 57.91%, Average Loss: 1.6669958645105363%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 279\n",
            "training loss: 1.1354553699493408 [0/60000]\n",
            "training loss: 1.0501247644424438 [6400/60000]\n",
            "training loss: 1.118438482284546 [12800/60000]\n",
            "training loss: 1.0424954891204834 [19200/60000]\n",
            "training loss: 0.6844199895858765 [25600/60000]\n",
            "training loss: 1.2525228261947632 [32000/60000]\n",
            "training loss: 0.8920029997825623 [38400/60000]\n",
            "training loss: 1.1437397003173828 [44800/60000]\n",
            "training loss: 1.0984677076339722 [51200/60000]\n",
            "training loss: 1.0135133266448975 [57600/60000]\n",
            "Correct Predictions: 57.92%, Average Loss: 1.6667725348472595%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 280\n",
            "training loss: 1.1350202560424805 [0/60000]\n",
            "training loss: 1.05012845993042 [6400/60000]\n",
            "training loss: 1.118048906326294 [12800/60000]\n",
            "training loss: 1.042458176612854 [19200/60000]\n",
            "training loss: 0.6839505434036255 [25600/60000]\n",
            "training loss: 1.252246379852295 [32000/60000]\n",
            "training loss: 0.8914635181427002 [38400/60000]\n",
            "training loss: 1.1434329748153687 [44800/60000]\n",
            "training loss: 1.0983637571334839 [51200/60000]\n",
            "training loss: 1.012743592262268 [57600/60000]\n",
            "Correct Predictions: 57.92%, Average Loss: 1.6665522968769073%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 281\n",
            "training loss: 1.1348322629928589 [0/60000]\n",
            "training loss: 1.049985408782959 [6400/60000]\n",
            "training loss: 1.1176538467407227 [12800/60000]\n",
            "training loss: 1.0423471927642822 [19200/60000]\n",
            "training loss: 0.684012770652771 [25600/60000]\n",
            "training loss: 1.2522538900375366 [32000/60000]\n",
            "training loss: 0.8893690705299377 [38400/60000]\n",
            "training loss: 1.1432628631591797 [44800/60000]\n",
            "training loss: 1.0981040000915527 [51200/60000]\n",
            "training loss: 1.012001633644104 [57600/60000]\n",
            "Correct Predictions: 57.93000000000001%, Average Loss: 1.6663521146774292%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 282\n",
            "training loss: 1.1345064640045166 [0/60000]\n",
            "training loss: 1.0498260259628296 [6400/60000]\n",
            "training loss: 1.1173131465911865 [12800/60000]\n",
            "training loss: 1.0424214601516724 [19200/60000]\n",
            "training loss: 0.683652937412262 [25600/60000]\n",
            "training loss: 1.2524055242538452 [32000/60000]\n",
            "training loss: 0.8889896869659424 [38400/60000]\n",
            "training loss: 1.1429952383041382 [44800/60000]\n",
            "training loss: 1.0981156826019287 [51200/60000]\n",
            "training loss: 1.0114660263061523 [57600/60000]\n",
            "Correct Predictions: 57.93000000000001%, Average Loss: 1.6661598217487337%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 283\n",
            "training loss: 1.1341320276260376 [0/60000]\n",
            "training loss: 1.0499813556671143 [6400/60000]\n",
            "training loss: 1.116946816444397 [12800/60000]\n",
            "training loss: 1.0423808097839355 [19200/60000]\n",
            "training loss: 0.6834010481834412 [25600/60000]\n",
            "training loss: 1.2522501945495605 [32000/60000]\n",
            "training loss: 0.8884907364845276 [38400/60000]\n",
            "training loss: 1.1427429914474487 [44800/60000]\n",
            "training loss: 1.0978399515151978 [51200/60000]\n",
            "training loss: 1.0108438730239868 [57600/60000]\n",
            "Correct Predictions: 57.95%, Average Loss: 1.665945866703987%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 284\n",
            "training loss: 1.133626103401184 [0/60000]\n",
            "training loss: 1.0499391555786133 [6400/60000]\n",
            "training loss: 1.1165411472320557 [12800/60000]\n",
            "training loss: 1.0423665046691895 [19200/60000]\n",
            "training loss: 0.6830543279647827 [25600/60000]\n",
            "training loss: 1.2523462772369385 [32000/60000]\n",
            "training loss: 0.8877112865447998 [38400/60000]\n",
            "training loss: 1.1425719261169434 [44800/60000]\n",
            "training loss: 1.097382664680481 [51200/60000]\n",
            "training loss: 1.0101256370544434 [57600/60000]\n",
            "Correct Predictions: 57.97%, Average Loss: 1.665731263756752%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 285\n",
            "training loss: 1.1331568956375122 [0/60000]\n",
            "training loss: 1.0498133897781372 [6400/60000]\n",
            "training loss: 1.1160632371902466 [12800/60000]\n",
            "training loss: 1.042171597480774 [19200/60000]\n",
            "training loss: 0.6828296184539795 [25600/60000]\n",
            "training loss: 1.2524114847183228 [32000/60000]\n",
            "training loss: 0.8873090744018555 [38400/60000]\n",
            "training loss: 1.1421538591384888 [44800/60000]\n",
            "training loss: 1.0970982313156128 [51200/60000]\n",
            "training loss: 1.0095692873001099 [57600/60000]\n",
            "Correct Predictions: 57.97%, Average Loss: 1.6655037432909012%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 286\n",
            "training loss: 1.1329342126846313 [0/60000]\n",
            "training loss: 1.049799919128418 [6400/60000]\n",
            "training loss: 1.1156202554702759 [12800/60000]\n",
            "training loss: 1.0421178340911865 [19200/60000]\n",
            "training loss: 0.6825397610664368 [25600/60000]\n",
            "training loss: 1.2521145343780518 [32000/60000]\n",
            "training loss: 0.8868979811668396 [38400/60000]\n",
            "training loss: 1.1419693231582642 [44800/60000]\n",
            "training loss: 1.0971343517303467 [51200/60000]\n",
            "training loss: 1.0095301866531372 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6652958881855011%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 287\n",
            "training loss: 1.132671594619751 [0/60000]\n",
            "training loss: 1.0496973991394043 [6400/60000]\n",
            "training loss: 1.1151877641677856 [12800/60000]\n",
            "training loss: 1.0435757637023926 [19200/60000]\n",
            "training loss: 0.6824078559875488 [25600/60000]\n",
            "training loss: 1.2520586252212524 [32000/60000]\n",
            "training loss: 0.8862640857696533 [38400/60000]\n",
            "training loss: 1.141684651374817 [44800/60000]\n",
            "training loss: 1.096860408782959 [51200/60000]\n",
            "training loss: 1.0088741779327393 [57600/60000]\n",
            "Correct Predictions: 57.95%, Average Loss: 1.6650221538543701%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 288\n",
            "training loss: 1.132171392440796 [0/60000]\n",
            "training loss: 1.0498216152191162 [6400/60000]\n",
            "training loss: 1.1148425340652466 [12800/60000]\n",
            "training loss: 1.0432195663452148 [19200/60000]\n",
            "training loss: 0.6818158626556396 [25600/60000]\n",
            "training loss: 1.2522366046905518 [32000/60000]\n",
            "training loss: 0.8859584331512451 [38400/60000]\n",
            "training loss: 1.1413599252700806 [44800/60000]\n",
            "training loss: 1.0966209173202515 [51200/60000]\n",
            "training loss: 1.008184552192688 [57600/60000]\n",
            "Correct Predictions: 57.95%, Average Loss: 1.6647739243507387%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 289\n",
            "training loss: 1.1320146322250366 [0/60000]\n",
            "training loss: 1.0500413179397583 [6400/60000]\n",
            "training loss: 1.1142760515213013 [12800/60000]\n",
            "training loss: 1.0430583953857422 [19200/60000]\n",
            "training loss: 0.6815846562385559 [25600/60000]\n",
            "training loss: 1.2521394491195679 [32000/60000]\n",
            "training loss: 0.8855768442153931 [38400/60000]\n",
            "training loss: 1.1411346197128296 [44800/60000]\n",
            "training loss: 1.0964442491531372 [51200/60000]\n",
            "training loss: 1.007497787475586 [57600/60000]\n",
            "Correct Predictions: 57.95%, Average Loss: 1.6645510107278823%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 290\n",
            "training loss: 1.1317408084869385 [0/60000]\n",
            "training loss: 1.0501259565353394 [6400/60000]\n",
            "training loss: 1.1138215065002441 [12800/60000]\n",
            "training loss: 1.0429095029830933 [19200/60000]\n",
            "training loss: 0.6813607215881348 [25600/60000]\n",
            "training loss: 1.2520607709884644 [32000/60000]\n",
            "training loss: 0.8850939273834229 [38400/60000]\n",
            "training loss: 1.1407980918884277 [44800/60000]\n",
            "training loss: 1.0962809324264526 [51200/60000]\n",
            "training loss: 1.0068352222442627 [57600/60000]\n",
            "Correct Predictions: 57.95%, Average Loss: 1.6643350380659103%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 291\n",
            "training loss: 1.1313873529434204 [0/60000]\n",
            "training loss: 1.0500028133392334 [6400/60000]\n",
            "training loss: 1.1133569478988647 [12800/60000]\n",
            "training loss: 1.042813777923584 [19200/60000]\n",
            "training loss: 0.681476354598999 [25600/60000]\n",
            "training loss: 1.251894235610962 [32000/60000]\n",
            "training loss: 0.8844925165176392 [38400/60000]\n",
            "training loss: 1.1403603553771973 [44800/60000]\n",
            "training loss: 1.0961463451385498 [51200/60000]\n",
            "training loss: 1.006731390953064 [57600/60000]\n",
            "Correct Predictions: 57.95%, Average Loss: 1.664139876961708%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 292\n",
            "training loss: 1.131090760231018 [0/60000]\n",
            "training loss: 1.0498632192611694 [6400/60000]\n",
            "training loss: 1.112986445426941 [12800/60000]\n",
            "training loss: 1.042851448059082 [19200/60000]\n",
            "training loss: 0.6812673807144165 [25600/60000]\n",
            "training loss: 1.2517355680465698 [32000/60000]\n",
            "training loss: 0.8838819861412048 [38400/60000]\n",
            "training loss: 1.1400688886642456 [44800/60000]\n",
            "training loss: 1.0959601402282715 [51200/60000]\n",
            "training loss: 1.006088376045227 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6639185321331025%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 293\n",
            "training loss: 1.1306926012039185 [0/60000]\n",
            "training loss: 1.0498294830322266 [6400/60000]\n",
            "training loss: 1.1124885082244873 [12800/60000]\n",
            "training loss: 1.0425937175750732 [19200/60000]\n",
            "training loss: 0.6796892881393433 [25600/60000]\n",
            "training loss: 1.2515805959701538 [32000/60000]\n",
            "training loss: 0.8831363320350647 [38400/60000]\n",
            "training loss: 1.1397032737731934 [44800/60000]\n",
            "training loss: 1.0957586765289307 [51200/60000]\n",
            "training loss: 1.0054736137390137 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6637261301279067%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 294\n",
            "training loss: 1.130542516708374 [0/60000]\n",
            "training loss: 1.0500563383102417 [6400/60000]\n",
            "training loss: 1.1124212741851807 [12800/60000]\n",
            "training loss: 1.0425297021865845 [19200/60000]\n",
            "training loss: 0.6795676946640015 [25600/60000]\n",
            "training loss: 1.251762866973877 [32000/60000]\n",
            "training loss: 0.8825893402099609 [38400/60000]\n",
            "training loss: 1.1394160985946655 [44800/60000]\n",
            "training loss: 1.0955023765563965 [51200/60000]\n",
            "training loss: 1.0047277212142944 [57600/60000]\n",
            "Correct Predictions: 57.97%, Average Loss: 1.6635198110342024%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 295\n",
            "training loss: 1.1301296949386597 [0/60000]\n",
            "training loss: 1.0499471426010132 [6400/60000]\n",
            "training loss: 1.1120282411575317 [12800/60000]\n",
            "training loss: 1.0424305200576782 [19200/60000]\n",
            "training loss: 0.679302990436554 [25600/60000]\n",
            "training loss: 1.2520802021026611 [32000/60000]\n",
            "training loss: 0.882023274898529 [38400/60000]\n",
            "training loss: 1.1390525102615356 [44800/60000]\n",
            "training loss: 1.0953422784805298 [51200/60000]\n",
            "training loss: 1.0040162801742554 [57600/60000]\n",
            "Correct Predictions: 57.97%, Average Loss: 1.6633417016267775%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 296\n",
            "training loss: 1.1299774646759033 [0/60000]\n",
            "training loss: 1.049552083015442 [6400/60000]\n",
            "training loss: 1.111568808555603 [12800/60000]\n",
            "training loss: 1.042243480682373 [19200/60000]\n",
            "training loss: 0.6790900230407715 [25600/60000]\n",
            "training loss: 1.2518068552017212 [32000/60000]\n",
            "training loss: 0.8815129995346069 [38400/60000]\n",
            "training loss: 1.1387029886245728 [44800/60000]\n",
            "training loss: 1.0951913595199585 [51200/60000]\n",
            "training loss: 1.0031449794769287 [57600/60000]\n",
            "Correct Predictions: 57.98%, Average Loss: 1.6631533175706863%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 297\n",
            "training loss: 1.1298238039016724 [0/60000]\n",
            "training loss: 1.0495566129684448 [6400/60000]\n",
            "training loss: 1.1113260984420776 [12800/60000]\n",
            "training loss: 1.042006254196167 [19200/60000]\n",
            "training loss: 0.6791403293609619 [25600/60000]\n",
            "training loss: 1.2514220476150513 [32000/60000]\n",
            "training loss: 0.8809117078781128 [38400/60000]\n",
            "training loss: 1.1383768320083618 [44800/60000]\n",
            "training loss: 1.0949692726135254 [51200/60000]\n",
            "training loss: 1.0025032758712769 [57600/60000]\n",
            "Correct Predictions: 57.98%, Average Loss: 1.6629716205596925%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 298\n",
            "training loss: 1.129425287246704 [0/60000]\n",
            "training loss: 1.0495498180389404 [6400/60000]\n",
            "training loss: 1.1108897924423218 [12800/60000]\n",
            "training loss: 1.0418177843093872 [19200/60000]\n",
            "training loss: 0.67864990234375 [25600/60000]\n",
            "training loss: 1.251250147819519 [32000/60000]\n",
            "training loss: 0.8802422881126404 [38400/60000]\n",
            "training loss: 1.1381123065948486 [44800/60000]\n",
            "training loss: 1.094862699508667 [51200/60000]\n",
            "training loss: 1.0019584894180298 [57600/60000]\n",
            "Correct Predictions: 57.98%, Average Loss: 1.6627681463956834%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 299\n",
            "training loss: 1.1290910243988037 [0/60000]\n",
            "training loss: 1.0493059158325195 [6400/60000]\n",
            "training loss: 1.1105303764343262 [12800/60000]\n",
            "training loss: 1.0417132377624512 [19200/60000]\n",
            "training loss: 0.6783058047294617 [25600/60000]\n",
            "training loss: 1.2511186599731445 [32000/60000]\n",
            "training loss: 0.8798332214355469 [38400/60000]\n",
            "training loss: 1.1377836465835571 [44800/60000]\n",
            "training loss: 1.0946545600891113 [51200/60000]\n",
            "training loss: 1.001318097114563 [57600/60000]\n",
            "Correct Predictions: 57.98%, Average Loss: 1.6625705152750014%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 300\n",
            "training loss: 1.1285220384597778 [0/60000]\n",
            "training loss: 1.0492457151412964 [6400/60000]\n",
            "training loss: 1.1102521419525146 [12800/60000]\n",
            "training loss: 1.0418044328689575 [19200/60000]\n",
            "training loss: 0.6780351400375366 [25600/60000]\n",
            "training loss: 1.2511799335479736 [32000/60000]\n",
            "training loss: 0.8791328072547913 [38400/60000]\n",
            "training loss: 1.137473225593567 [44800/60000]\n",
            "training loss: 1.094519019126892 [51200/60000]\n",
            "training loss: 1.0006663799285889 [57600/60000]\n",
            "Correct Predictions: 57.98%, Average Loss: 1.6624633830785753%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 301\n",
            "training loss: 1.127808928489685 [0/60000]\n",
            "training loss: 1.049026370048523 [6400/60000]\n",
            "training loss: 1.1099040508270264 [12800/60000]\n",
            "training loss: 1.041693925857544 [19200/60000]\n",
            "training loss: 0.6778627038002014 [25600/60000]\n",
            "training loss: 1.250530481338501 [32000/60000]\n",
            "training loss: 0.878629207611084 [38400/60000]\n",
            "training loss: 1.1371833086013794 [44800/60000]\n",
            "training loss: 1.0945104360580444 [51200/60000]\n",
            "training loss: 0.99998539686203 [57600/60000]\n",
            "Correct Predictions: 57.98%, Average Loss: 1.6622389996051787%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 302\n",
            "training loss: 1.1274988651275635 [0/60000]\n",
            "training loss: 1.0488711595535278 [6400/60000]\n",
            "training loss: 1.1095386743545532 [12800/60000]\n",
            "training loss: 1.0415228605270386 [19200/60000]\n",
            "training loss: 0.6774837970733643 [25600/60000]\n",
            "training loss: 1.2504398822784424 [32000/60000]\n",
            "training loss: 0.8780465126037598 [38400/60000]\n",
            "training loss: 1.136906623840332 [44800/60000]\n",
            "training loss: 1.0944496393203735 [51200/60000]\n",
            "training loss: 0.9995759725570679 [57600/60000]\n",
            "Correct Predictions: 57.989999999999995%, Average Loss: 1.6620585149526597%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 303\n",
            "training loss: 1.1270477771759033 [0/60000]\n",
            "training loss: 1.0489810705184937 [6400/60000]\n",
            "training loss: 1.1093062162399292 [12800/60000]\n",
            "training loss: 1.0413869619369507 [19200/60000]\n",
            "training loss: 0.6773401498794556 [25600/60000]\n",
            "training loss: 1.2501089572906494 [32000/60000]\n",
            "training loss: 0.8774338960647583 [38400/60000]\n",
            "training loss: 1.1366088390350342 [44800/60000]\n",
            "training loss: 1.0943801403045654 [51200/60000]\n",
            "training loss: 0.9988306760787964 [57600/60000]\n",
            "Correct Predictions: 57.99999999999999%, Average Loss: 1.6618503141403198%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 304\n",
            "training loss: 1.1268364191055298 [0/60000]\n",
            "training loss: 1.0487992763519287 [6400/60000]\n",
            "training loss: 1.1089448928833008 [12800/60000]\n",
            "training loss: 1.041292667388916 [19200/60000]\n",
            "training loss: 0.6775377988815308 [25600/60000]\n",
            "training loss: 1.2498371601104736 [32000/60000]\n",
            "training loss: 0.8761155009269714 [38400/60000]\n",
            "training loss: 1.1364786624908447 [44800/60000]\n",
            "training loss: 1.0944122076034546 [51200/60000]\n",
            "training loss: 0.9981377720832825 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6616213816404342%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 305\n",
            "training loss: 1.1267056465148926 [0/60000]\n",
            "training loss: 1.0487322807312012 [6400/60000]\n",
            "training loss: 1.1083678007125854 [12800/60000]\n",
            "training loss: 1.0409519672393799 [19200/60000]\n",
            "training loss: 0.6771788001060486 [25600/60000]\n",
            "training loss: 1.249624490737915 [32000/60000]\n",
            "training loss: 0.875475287437439 [38400/60000]\n",
            "training loss: 1.136151671409607 [44800/60000]\n",
            "training loss: 1.0948939323425293 [51200/60000]\n",
            "training loss: 0.9974774718284607 [57600/60000]\n",
            "Correct Predictions: 57.99999999999999%, Average Loss: 1.6614261764287948%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 306\n",
            "training loss: 1.1267961263656616 [0/60000]\n",
            "training loss: 1.0483441352844238 [6400/60000]\n",
            "training loss: 1.1080636978149414 [12800/60000]\n",
            "training loss: 1.040905237197876 [19200/60000]\n",
            "training loss: 0.6769119501113892 [25600/60000]\n",
            "training loss: 1.249591588973999 [32000/60000]\n",
            "training loss: 0.8749565482139587 [38400/60000]\n",
            "training loss: 1.1358070373535156 [44800/60000]\n",
            "training loss: 1.0946991443634033 [51200/60000]\n",
            "training loss: 0.9969293475151062 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6612364000082016%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 307\n",
            "training loss: 1.1264647245407104 [0/60000]\n",
            "training loss: 1.048313856124878 [6400/60000]\n",
            "training loss: 1.1077253818511963 [12800/60000]\n",
            "training loss: 1.0408152341842651 [19200/60000]\n",
            "training loss: 0.6766093969345093 [25600/60000]\n",
            "training loss: 1.2490915060043335 [32000/60000]\n",
            "training loss: 0.8743776679039001 [38400/60000]\n",
            "training loss: 1.1355596780776978 [44800/60000]\n",
            "training loss: 1.094728708267212 [51200/60000]\n",
            "training loss: 0.9962312579154968 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6610524129867552%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 308\n",
            "training loss: 1.1259709596633911 [0/60000]\n",
            "training loss: 1.048020362854004 [6400/60000]\n",
            "training loss: 1.1074296236038208 [12800/60000]\n",
            "training loss: 1.0406407117843628 [19200/60000]\n",
            "training loss: 0.6762557625770569 [25600/60000]\n",
            "training loss: 1.2489781379699707 [32000/60000]\n",
            "training loss: 0.873878538608551 [38400/60000]\n",
            "training loss: 1.1353422403335571 [44800/60000]\n",
            "training loss: 1.0946924686431885 [51200/60000]\n",
            "training loss: 0.9958288669586182 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6608678579330443%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 309\n",
            "training loss: 1.1257706880569458 [0/60000]\n",
            "training loss: 1.0477585792541504 [6400/60000]\n",
            "training loss: 1.1071479320526123 [12800/60000]\n",
            "training loss: 1.0406166315078735 [19200/60000]\n",
            "training loss: 0.675960898399353 [25600/60000]\n",
            "training loss: 1.2485837936401367 [32000/60000]\n",
            "training loss: 0.8733305931091309 [38400/60000]\n",
            "training loss: 1.135035753250122 [44800/60000]\n",
            "training loss: 1.0945796966552734 [51200/60000]\n",
            "training loss: 0.9952360987663269 [57600/60000]\n",
            "Correct Predictions: 57.99999999999999%, Average Loss: 1.6606768584251406%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 310\n",
            "training loss: 1.1254441738128662 [0/60000]\n",
            "training loss: 1.0477590560913086 [6400/60000]\n",
            "training loss: 1.1069064140319824 [12800/60000]\n",
            "training loss: 1.0404685735702515 [19200/60000]\n",
            "training loss: 0.6757500767707825 [25600/60000]\n",
            "training loss: 1.2480087280273438 [32000/60000]\n",
            "training loss: 0.8730138540267944 [38400/60000]\n",
            "training loss: 1.1347554922103882 [44800/60000]\n",
            "training loss: 1.0946362018585205 [51200/60000]\n",
            "training loss: 0.9947669506072998 [57600/60000]\n",
            "Correct Predictions: 57.99999999999999%, Average Loss: 1.6604957270622254%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 311\n",
            "training loss: 1.1248897314071655 [0/60000]\n",
            "training loss: 1.0475050210952759 [6400/60000]\n",
            "training loss: 1.1065057516098022 [12800/60000]\n",
            "training loss: 1.0403846502304077 [19200/60000]\n",
            "training loss: 0.6752949357032776 [25600/60000]\n",
            "training loss: 1.247563362121582 [32000/60000]\n",
            "training loss: 0.8722416758537292 [38400/60000]\n",
            "training loss: 1.1345558166503906 [44800/60000]\n",
            "training loss: 1.0945546627044678 [51200/60000]\n",
            "training loss: 0.99400395154953 [57600/60000]\n",
            "Correct Predictions: 57.989999999999995%, Average Loss: 1.660321187376976%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 312\n",
            "training loss: 1.1248596906661987 [0/60000]\n",
            "training loss: 1.0471290349960327 [6400/60000]\n",
            "training loss: 1.1062288284301758 [12800/60000]\n",
            "training loss: 1.040199875831604 [19200/60000]\n",
            "training loss: 0.6746212840080261 [25600/60000]\n",
            "training loss: 1.247405767440796 [32000/60000]\n",
            "training loss: 0.8715827465057373 [38400/60000]\n",
            "training loss: 1.1342777013778687 [44800/60000]\n",
            "training loss: 1.0943876504898071 [51200/60000]\n",
            "training loss: 0.993547260761261 [57600/60000]\n",
            "Correct Predictions: 57.989999999999995%, Average Loss: 1.6601348119974138%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 313\n",
            "training loss: 1.124631404876709 [0/60000]\n",
            "training loss: 1.0469253063201904 [6400/60000]\n",
            "training loss: 1.1059530973434448 [12800/60000]\n",
            "training loss: 1.040106177330017 [19200/60000]\n",
            "training loss: 0.6742443442344666 [25600/60000]\n",
            "training loss: 1.2472916841506958 [32000/60000]\n",
            "training loss: 0.8710178136825562 [38400/60000]\n",
            "training loss: 1.133944034576416 [44800/60000]\n",
            "training loss: 1.0944164991378784 [51200/60000]\n",
            "training loss: 0.9929786920547485 [57600/60000]\n",
            "Correct Predictions: 57.989999999999995%, Average Loss: 1.6599757993221282%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 314\n",
            "training loss: 1.1242647171020508 [0/60000]\n",
            "training loss: 1.0467339754104614 [6400/60000]\n",
            "training loss: 1.1056157350540161 [12800/60000]\n",
            "training loss: 1.0398368835449219 [19200/60000]\n",
            "training loss: 0.6739451885223389 [25600/60000]\n",
            "training loss: 1.2471352815628052 [32000/60000]\n",
            "training loss: 0.8706516027450562 [38400/60000]\n",
            "training loss: 1.1341099739074707 [44800/60000]\n",
            "training loss: 1.0939736366271973 [51200/60000]\n",
            "training loss: 0.9925042390823364 [57600/60000]\n",
            "Correct Predictions: 57.989999999999995%, Average Loss: 1.6598365831375121%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 315\n",
            "training loss: 1.1239327192306519 [0/60000]\n",
            "training loss: 1.0467339754104614 [6400/60000]\n",
            "training loss: 1.105371356010437 [12800/60000]\n",
            "training loss: 1.039566993713379 [19200/60000]\n",
            "training loss: 0.6738941073417664 [25600/60000]\n",
            "training loss: 1.2467511892318726 [32000/60000]\n",
            "training loss: 0.8700876832008362 [38400/60000]\n",
            "training loss: 1.1336876153945923 [44800/60000]\n",
            "training loss: 1.0938361883163452 [51200/60000]\n",
            "training loss: 0.9919072985649109 [57600/60000]\n",
            "Correct Predictions: 57.989999999999995%, Average Loss: 1.659662347435951%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 316\n",
            "training loss: 1.1237261295318604 [0/60000]\n",
            "training loss: 1.046545386314392 [6400/60000]\n",
            "training loss: 1.1051536798477173 [12800/60000]\n",
            "training loss: 1.039494514465332 [19200/60000]\n",
            "training loss: 0.6734235882759094 [25600/60000]\n",
            "training loss: 1.2465229034423828 [32000/60000]\n",
            "training loss: 0.8695040345191956 [38400/60000]\n",
            "training loss: 1.133426308631897 [44800/60000]\n",
            "training loss: 1.093720555305481 [51200/60000]\n",
            "training loss: 0.9915634989738464 [57600/60000]\n",
            "Correct Predictions: 57.989999999999995%, Average Loss: 1.6595025825500487%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 317\n",
            "training loss: 1.1227301359176636 [0/60000]\n",
            "training loss: 1.0463913679122925 [6400/60000]\n",
            "training loss: 1.1048697233200073 [12800/60000]\n",
            "training loss: 1.0392863750457764 [19200/60000]\n",
            "training loss: 0.6734198927879333 [25600/60000]\n",
            "training loss: 1.2462208271026611 [32000/60000]\n",
            "training loss: 0.8689194321632385 [38400/60000]\n",
            "training loss: 1.1331703662872314 [44800/60000]\n",
            "training loss: 1.0935522317886353 [51200/60000]\n",
            "training loss: 0.9908625483512878 [57600/60000]\n",
            "Correct Predictions: 57.99999999999999%, Average Loss: 1.6593656021356582%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 318\n",
            "training loss: 1.1224093437194824 [0/60000]\n",
            "training loss: 1.0461429357528687 [6400/60000]\n",
            "training loss: 1.1046435832977295 [12800/60000]\n",
            "training loss: 1.0390734672546387 [19200/60000]\n",
            "training loss: 0.67284095287323 [25600/60000]\n",
            "training loss: 1.2460285425186157 [32000/60000]\n",
            "training loss: 0.8683077096939087 [38400/60000]\n",
            "training loss: 1.132901668548584 [44800/60000]\n",
            "training loss: 1.0934410095214844 [51200/60000]\n",
            "training loss: 0.9904187917709351 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.659207060933113%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 319\n",
            "training loss: 1.1220935583114624 [0/60000]\n",
            "training loss: 1.046081781387329 [6400/60000]\n",
            "training loss: 1.1043709516525269 [12800/60000]\n",
            "training loss: 1.0388588905334473 [19200/60000]\n",
            "training loss: 0.6711007952690125 [25600/60000]\n",
            "training loss: 1.2456703186035156 [32000/60000]\n",
            "training loss: 0.8676477074623108 [38400/60000]\n",
            "training loss: 1.132663369178772 [44800/60000]\n",
            "training loss: 1.0934510231018066 [51200/60000]\n",
            "training loss: 0.989856481552124 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.659052637219429%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 320\n",
            "training loss: 1.121533989906311 [0/60000]\n",
            "training loss: 1.0458908081054688 [6400/60000]\n",
            "training loss: 1.1041843891143799 [12800/60000]\n",
            "training loss: 1.038670301437378 [19200/60000]\n",
            "training loss: 0.6706194877624512 [25600/60000]\n",
            "training loss: 1.245518684387207 [32000/60000]\n",
            "training loss: 0.8671073317527771 [38400/60000]\n",
            "training loss: 1.1324048042297363 [44800/60000]\n",
            "training loss: 1.0934091806411743 [51200/60000]\n",
            "training loss: 0.9891545176506042 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.658911173939705%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 321\n",
            "training loss: 1.1211880445480347 [0/60000]\n",
            "training loss: 1.0456387996673584 [6400/60000]\n",
            "training loss: 1.1039392948150635 [12800/60000]\n",
            "training loss: 1.0384832620620728 [19200/60000]\n",
            "training loss: 0.6705970168113708 [25600/60000]\n",
            "training loss: 1.245208978652954 [32000/60000]\n",
            "training loss: 0.8664272427558899 [38400/60000]\n",
            "training loss: 1.132171869277954 [44800/60000]\n",
            "training loss: 1.0931915044784546 [51200/60000]\n",
            "training loss: 0.9888614416122437 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6588014364242554%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 322\n",
            "training loss: 1.1206532716751099 [0/60000]\n",
            "training loss: 1.0455870628356934 [6400/60000]\n",
            "training loss: 1.103695034980774 [12800/60000]\n",
            "training loss: 1.0381728410720825 [19200/60000]\n",
            "training loss: 0.6701129078865051 [25600/60000]\n",
            "training loss: 1.244935154914856 [32000/60000]\n",
            "training loss: 0.8658998608589172 [38400/60000]\n",
            "training loss: 1.1318684816360474 [44800/60000]\n",
            "training loss: 1.0930678844451904 [51200/60000]\n",
            "training loss: 0.988416850566864 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.658669244647026%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 323\n",
            "training loss: 1.1203323602676392 [0/60000]\n",
            "training loss: 1.045446753501892 [6400/60000]\n",
            "training loss: 1.1035053730010986 [12800/60000]\n",
            "training loss: 1.0380550622940063 [19200/60000]\n",
            "training loss: 0.6695577502250671 [25600/60000]\n",
            "training loss: 1.2447952032089233 [32000/60000]\n",
            "training loss: 0.8654365539550781 [38400/60000]\n",
            "training loss: 1.1315439939498901 [44800/60000]\n",
            "training loss: 1.0929173231124878 [51200/60000]\n",
            "training loss: 0.9879881739616394 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6585240805149077%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 324\n",
            "training loss: 1.119812250137329 [0/60000]\n",
            "training loss: 1.0452535152435303 [6400/60000]\n",
            "training loss: 1.1031310558319092 [12800/60000]\n",
            "training loss: 1.0378589630126953 [19200/60000]\n",
            "training loss: 0.6692147254943848 [25600/60000]\n",
            "training loss: 1.2446318864822388 [32000/60000]\n",
            "training loss: 0.864749550819397 [38400/60000]\n",
            "training loss: 1.1313426494598389 [44800/60000]\n",
            "training loss: 1.0927176475524902 [51200/60000]\n",
            "training loss: 0.9876431822776794 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6584283381700518%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 325\n",
            "training loss: 1.1195898056030273 [0/60000]\n",
            "training loss: 1.0450499057769775 [6400/60000]\n",
            "training loss: 1.103002667427063 [12800/60000]\n",
            "training loss: 1.0376832485198975 [19200/60000]\n",
            "training loss: 0.6687696576118469 [25600/60000]\n",
            "training loss: 1.244418978691101 [32000/60000]\n",
            "training loss: 0.8642826676368713 [38400/60000]\n",
            "training loss: 1.131022334098816 [44800/60000]\n",
            "training loss: 1.0925453901290894 [51200/60000]\n",
            "training loss: 0.9870165586471558 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.65831693649292%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 326\n",
            "training loss: 1.1191359758377075 [0/60000]\n",
            "training loss: 1.0447975397109985 [6400/60000]\n",
            "training loss: 1.1027904748916626 [12800/60000]\n",
            "training loss: 1.0374804735183716 [19200/60000]\n",
            "training loss: 0.6682527661323547 [25600/60000]\n",
            "training loss: 1.2442805767059326 [32000/60000]\n",
            "training loss: 0.8636187314987183 [38400/60000]\n",
            "training loss: 1.1309579610824585 [44800/60000]\n",
            "training loss: 1.0922638177871704 [51200/60000]\n",
            "training loss: 0.9868260025978088 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.658165292739868%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 327\n",
            "training loss: 1.1187524795532227 [0/60000]\n",
            "training loss: 1.0446381568908691 [6400/60000]\n",
            "training loss: 1.1025534868240356 [12800/60000]\n",
            "training loss: 1.0373588800430298 [19200/60000]\n",
            "training loss: 0.667953372001648 [25600/60000]\n",
            "training loss: 1.2434436082839966 [32000/60000]\n",
            "training loss: 0.8629902601242065 [38400/60000]\n",
            "training loss: 1.1307278871536255 [44800/60000]\n",
            "training loss: 1.0923759937286377 [51200/60000]\n",
            "training loss: 0.9864498972892761 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6580531007051469%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 328\n",
            "training loss: 1.1181488037109375 [0/60000]\n",
            "training loss: 1.044334888458252 [6400/60000]\n",
            "training loss: 1.1022523641586304 [12800/60000]\n",
            "training loss: 1.0371613502502441 [19200/60000]\n",
            "training loss: 0.6671128869056702 [25600/60000]\n",
            "training loss: 1.2434064149856567 [32000/60000]\n",
            "training loss: 0.862446129322052 [38400/60000]\n",
            "training loss: 1.1304949522018433 [44800/60000]\n",
            "training loss: 1.0922414064407349 [51200/60000]\n",
            "training loss: 0.9860343933105469 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.657966364622116%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 329\n",
            "training loss: 1.1176667213439941 [0/60000]\n",
            "training loss: 1.0439590215682983 [6400/60000]\n",
            "training loss: 1.1019978523254395 [12800/60000]\n",
            "training loss: 1.0369892120361328 [19200/60000]\n",
            "training loss: 0.6665800213813782 [25600/60000]\n",
            "training loss: 1.2431925535202026 [32000/60000]\n",
            "training loss: 0.8617795705795288 [38400/60000]\n",
            "training loss: 1.1302731037139893 [44800/60000]\n",
            "training loss: 1.092272162437439 [51200/60000]\n",
            "training loss: 0.9854322075843811 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6578388398885726%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 330\n",
            "training loss: 1.11715829372406 [0/60000]\n",
            "training loss: 1.0435060262680054 [6400/60000]\n",
            "training loss: 1.1017076969146729 [12800/60000]\n",
            "training loss: 1.0367975234985352 [19200/60000]\n",
            "training loss: 0.6661904454231262 [25600/60000]\n",
            "training loss: 1.2431929111480713 [32000/60000]\n",
            "training loss: 0.8611217737197876 [38400/60000]\n",
            "training loss: 1.130104899406433 [44800/60000]\n",
            "training loss: 1.0920249223709106 [51200/60000]\n",
            "training loss: 0.9849855303764343 [57600/60000]\n",
            "Correct Predictions: 58.050000000000004%, Average Loss: 1.657801743745804%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 331\n",
            "training loss: 1.118039846420288 [0/60000]\n",
            "training loss: 1.043566107749939 [6400/60000]\n",
            "training loss: 1.101485013961792 [12800/60000]\n",
            "training loss: 1.0365008115768433 [19200/60000]\n",
            "training loss: 0.6655354499816895 [25600/60000]\n",
            "training loss: 1.243067741394043 [32000/60000]\n",
            "training loss: 0.8607288002967834 [38400/60000]\n",
            "training loss: 1.1299079656600952 [44800/60000]\n",
            "training loss: 1.0919599533081055 [51200/60000]\n",
            "training loss: 0.9847267866134644 [57600/60000]\n",
            "Correct Predictions: 58.050000000000004%, Average Loss: 1.6577251321077346%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 332\n",
            "training loss: 1.1177259683609009 [0/60000]\n",
            "training loss: 1.0432943105697632 [6400/60000]\n",
            "training loss: 1.1012648344039917 [12800/60000]\n",
            "training loss: 1.0362786054611206 [19200/60000]\n",
            "training loss: 0.6649421453475952 [25600/60000]\n",
            "training loss: 1.2429425716400146 [32000/60000]\n",
            "training loss: 0.860255777835846 [38400/60000]\n",
            "training loss: 1.1297619342803955 [44800/60000]\n",
            "training loss: 1.091780424118042 [51200/60000]\n",
            "training loss: 0.984150230884552 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.657665776014328%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 333\n",
            "training loss: 1.11725652217865 [0/60000]\n",
            "training loss: 1.0426945686340332 [6400/60000]\n",
            "training loss: 1.101040244102478 [12800/60000]\n",
            "training loss: 1.0360862016677856 [19200/60000]\n",
            "training loss: 0.6631158590316772 [25600/60000]\n",
            "training loss: 1.2429560422897339 [32000/60000]\n",
            "training loss: 0.8596493601799011 [38400/60000]\n",
            "training loss: 1.129541039466858 [44800/60000]\n",
            "training loss: 1.091672420501709 [51200/60000]\n",
            "training loss: 0.9838694930076599 [57600/60000]\n",
            "Correct Predictions: 58.06%, Average Loss: 1.657547752261162%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 334\n",
            "training loss: 1.11673104763031 [0/60000]\n",
            "training loss: 1.0426758527755737 [6400/60000]\n",
            "training loss: 1.1008309125900269 [12800/60000]\n",
            "training loss: 1.036024570465088 [19200/60000]\n",
            "training loss: 0.662493109703064 [25600/60000]\n",
            "training loss: 1.2425010204315186 [32000/60000]\n",
            "training loss: 0.8591269254684448 [38400/60000]\n",
            "training loss: 1.1294845342636108 [44800/60000]\n",
            "training loss: 1.091550350189209 [51200/60000]\n",
            "training loss: 0.9834087491035461 [57600/60000]\n",
            "Correct Predictions: 58.06%, Average Loss: 1.657477548122406%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 335\n",
            "training loss: 1.1163713932037354 [0/60000]\n",
            "training loss: 1.0423563718795776 [6400/60000]\n",
            "training loss: 1.100644588470459 [12800/60000]\n",
            "training loss: 1.0358033180236816 [19200/60000]\n",
            "training loss: 0.6620872020721436 [25600/60000]\n",
            "training loss: 1.2424952983856201 [32000/60000]\n",
            "training loss: 0.8587589859962463 [38400/60000]\n",
            "training loss: 1.1292572021484375 [44800/60000]\n",
            "training loss: 1.0913329124450684 [51200/60000]\n",
            "training loss: 0.9829821586608887 [57600/60000]\n",
            "Correct Predictions: 58.06%, Average Loss: 1.6574050092697146%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 336\n",
            "training loss: 1.1160268783569336 [0/60000]\n",
            "training loss: 1.0420249700546265 [6400/60000]\n",
            "training loss: 1.1004118919372559 [12800/60000]\n",
            "training loss: 1.0357860326766968 [19200/60000]\n",
            "training loss: 0.6615778207778931 [25600/60000]\n",
            "training loss: 1.242103934288025 [32000/60000]\n",
            "training loss: 0.858268141746521 [38400/60000]\n",
            "training loss: 1.1290996074676514 [44800/60000]\n",
            "training loss: 1.0910180807113647 [51200/60000]\n",
            "training loss: 0.9827067255973816 [57600/60000]\n",
            "Correct Predictions: 58.06%, Average Loss: 1.6572653329372407%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 337\n",
            "training loss: 1.115236759185791 [0/60000]\n",
            "training loss: 1.0419666767120361 [6400/60000]\n",
            "training loss: 1.10014009475708 [12800/60000]\n",
            "training loss: 1.0355706214904785 [19200/60000]\n",
            "training loss: 0.6603814959526062 [25600/60000]\n",
            "training loss: 1.2419854402542114 [32000/60000]\n",
            "training loss: 0.8577343821525574 [38400/60000]\n",
            "training loss: 1.128908395767212 [44800/60000]\n",
            "training loss: 1.0909554958343506 [51200/60000]\n",
            "training loss: 0.982232391834259 [57600/60000]\n",
            "Correct Predictions: 58.07%, Average Loss: 1.6571766328811646%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 338\n",
            "training loss: 1.1147220134735107 [0/60000]\n",
            "training loss: 1.0415544509887695 [6400/60000]\n",
            "training loss: 1.0998588800430298 [12800/60000]\n",
            "training loss: 1.035270094871521 [19200/60000]\n",
            "training loss: 0.6593635678291321 [25600/60000]\n",
            "training loss: 1.2420804500579834 [32000/60000]\n",
            "training loss: 0.8574016690254211 [38400/60000]\n",
            "training loss: 1.1287267208099365 [44800/60000]\n",
            "training loss: 1.0908546447753906 [51200/60000]\n",
            "training loss: 0.9817153811454773 [57600/60000]\n",
            "Correct Predictions: 58.07%, Average Loss: 1.6570694351196287%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 339\n",
            "training loss: 1.1140666007995605 [0/60000]\n",
            "training loss: 1.0413258075714111 [6400/60000]\n",
            "training loss: 1.099639654159546 [12800/60000]\n",
            "training loss: 1.0351516008377075 [19200/60000]\n",
            "training loss: 0.6588699221611023 [25600/60000]\n",
            "training loss: 1.2417525053024292 [32000/60000]\n",
            "training loss: 0.8568562865257263 [38400/60000]\n",
            "training loss: 1.1285597085952759 [44800/60000]\n",
            "training loss: 1.090768814086914 [51200/60000]\n",
            "training loss: 0.9813512563705444 [57600/60000]\n",
            "Correct Predictions: 58.06%, Average Loss: 1.6569766956567766%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 340\n",
            "training loss: 1.1135026216506958 [0/60000]\n",
            "training loss: 1.0409258604049683 [6400/60000]\n",
            "training loss: 1.0994435548782349 [12800/60000]\n",
            "training loss: 1.0347511768341064 [19200/60000]\n",
            "training loss: 0.6582803130149841 [25600/60000]\n",
            "training loss: 1.2419737577438354 [32000/60000]\n",
            "training loss: 0.8562917113304138 [38400/60000]\n",
            "training loss: 1.1283411979675293 [44800/60000]\n",
            "training loss: 1.0902601480484009 [51200/60000]\n",
            "training loss: 0.9809918403625488 [57600/60000]\n",
            "Correct Predictions: 58.06%, Average Loss: 1.6569108140468598%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 341\n",
            "training loss: 1.113279104232788 [0/60000]\n",
            "training loss: 1.0406630039215088 [6400/60000]\n",
            "training loss: 1.0991913080215454 [12800/60000]\n",
            "training loss: 1.0340396165847778 [19200/60000]\n",
            "training loss: 0.6580750346183777 [25600/60000]\n",
            "training loss: 1.241158366203308 [32000/60000]\n",
            "training loss: 0.8557904362678528 [38400/60000]\n",
            "training loss: 1.1282089948654175 [44800/60000]\n",
            "training loss: 1.0891515016555786 [51200/60000]\n",
            "training loss: 0.9802558422088623 [57600/60000]\n",
            "Correct Predictions: 58.06%, Average Loss: 1.656831905245781%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 342\n",
            "training loss: 1.112727403640747 [0/60000]\n",
            "training loss: 1.0407427549362183 [6400/60000]\n",
            "training loss: 1.098948359489441 [12800/60000]\n",
            "training loss: 1.0332671403884888 [19200/60000]\n",
            "training loss: 0.6569656133651733 [25600/60000]\n",
            "training loss: 1.2414381504058838 [32000/60000]\n",
            "training loss: 0.8550378084182739 [38400/60000]\n",
            "training loss: 1.127987265586853 [44800/60000]\n",
            "training loss: 1.0883742570877075 [51200/60000]\n",
            "training loss: 0.9799259901046753 [57600/60000]\n",
            "Correct Predictions: 58.06%, Average Loss: 1.6567441415786743%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 343\n",
            "training loss: 1.1122629642486572 [0/60000]\n",
            "training loss: 1.0401307344436646 [6400/60000]\n",
            "training loss: 1.0987399816513062 [12800/60000]\n",
            "training loss: 1.0325660705566406 [19200/60000]\n",
            "training loss: 0.6565917134284973 [25600/60000]\n",
            "training loss: 1.2411613464355469 [32000/60000]\n",
            "training loss: 0.8545036911964417 [38400/60000]\n",
            "training loss: 1.1278048753738403 [44800/60000]\n",
            "training loss: 1.0877695083618164 [51200/60000]\n",
            "training loss: 0.9793463349342346 [57600/60000]\n",
            "Correct Predictions: 58.050000000000004%, Average Loss: 1.656696982383728%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 344\n",
            "training loss: 1.111997127532959 [0/60000]\n",
            "training loss: 1.0400052070617676 [6400/60000]\n",
            "training loss: 1.0983651876449585 [12800/60000]\n",
            "training loss: 1.031860113143921 [19200/60000]\n",
            "training loss: 0.6560723781585693 [25600/60000]\n",
            "training loss: 1.2409969568252563 [32000/60000]\n",
            "training loss: 0.8540127873420715 [38400/60000]\n",
            "training loss: 1.127639651298523 [44800/60000]\n",
            "training loss: 1.0869133472442627 [51200/60000]\n",
            "training loss: 0.9789024591445923 [57600/60000]\n",
            "Correct Predictions: 58.050000000000004%, Average Loss: 1.6566140657663344%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 345\n",
            "training loss: 1.1112109422683716 [0/60000]\n",
            "training loss: 1.0395758152008057 [6400/60000]\n",
            "training loss: 1.0980998277664185 [12800/60000]\n",
            "training loss: 1.0310403108596802 [19200/60000]\n",
            "training loss: 0.6556856632232666 [25600/60000]\n",
            "training loss: 1.2406989336013794 [32000/60000]\n",
            "training loss: 0.8534722328186035 [38400/60000]\n",
            "training loss: 1.1274281740188599 [44800/60000]\n",
            "training loss: 1.086516261100769 [51200/60000]\n",
            "training loss: 0.978423535823822 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.6565675854682924%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 346\n",
            "training loss: 1.110663652420044 [0/60000]\n",
            "training loss: 1.0397160053253174 [6400/60000]\n",
            "training loss: 1.0977057218551636 [12800/60000]\n",
            "training loss: 1.0304088592529297 [19200/60000]\n",
            "training loss: 0.6550161242485046 [25600/60000]\n",
            "training loss: 1.2405734062194824 [32000/60000]\n",
            "training loss: 0.852584183216095 [38400/60000]\n",
            "training loss: 1.1272345781326294 [44800/60000]\n",
            "training loss: 1.086003303527832 [51200/60000]\n",
            "training loss: 0.9781436324119568 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.6566543459892273%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 347\n",
            "training loss: 1.1110339164733887 [0/60000]\n",
            "training loss: 1.0396007299423218 [6400/60000]\n",
            "training loss: 1.09738028049469 [12800/60000]\n",
            "training loss: 1.0298502445220947 [19200/60000]\n",
            "training loss: 0.6545661687850952 [25600/60000]\n",
            "training loss: 1.240746021270752 [32000/60000]\n",
            "training loss: 0.8513672947883606 [38400/60000]\n",
            "training loss: 1.1271229982376099 [44800/60000]\n",
            "training loss: 1.0858979225158691 [51200/60000]\n",
            "training loss: 0.9774016737937927 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.6563810956478118%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 348\n",
            "training loss: 1.1087586879730225 [0/60000]\n",
            "training loss: 1.0401723384857178 [6400/60000]\n",
            "training loss: 1.0970351696014404 [12800/60000]\n",
            "training loss: 1.02902352809906 [19200/60000]\n",
            "training loss: 0.6541897654533386 [25600/60000]\n",
            "training loss: 1.240652084350586 [32000/60000]\n",
            "training loss: 0.8503600358963013 [38400/60000]\n",
            "training loss: 1.1269762516021729 [44800/60000]\n",
            "training loss: 1.0855398178100586 [51200/60000]\n",
            "training loss: 0.9771886467933655 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.6562924939393997%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 349\n",
            "training loss: 1.1080256700515747 [0/60000]\n",
            "training loss: 1.04007089138031 [6400/60000]\n",
            "training loss: 1.0970869064331055 [12800/60000]\n",
            "training loss: 1.028494954109192 [19200/60000]\n",
            "training loss: 0.65380859375 [25600/60000]\n",
            "training loss: 1.240112543106079 [32000/60000]\n",
            "training loss: 0.8497446775436401 [38400/60000]\n",
            "training loss: 1.1269274950027466 [44800/60000]\n",
            "training loss: 1.0854195356369019 [51200/60000]\n",
            "training loss: 0.9766955971717834 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.6563150620460512%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 350\n",
            "training loss: 1.1092231273651123 [0/60000]\n",
            "training loss: 1.0398706197738647 [6400/60000]\n",
            "training loss: 1.0969115495681763 [12800/60000]\n",
            "training loss: 1.0279921293258667 [19200/60000]\n",
            "training loss: 0.6534197330474854 [25600/60000]\n",
            "training loss: 1.2393693923950195 [32000/60000]\n",
            "training loss: 0.8493530750274658 [38400/60000]\n",
            "training loss: 1.126848816871643 [44800/60000]\n",
            "training loss: 1.0852940082550049 [51200/60000]\n",
            "training loss: 0.9763268828392029 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.6562595540285112%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 351\n",
            "training loss: 1.1088443994522095 [0/60000]\n",
            "training loss: 1.0398309230804443 [6400/60000]\n",
            "training loss: 1.0965962409973145 [12800/60000]\n",
            "training loss: 1.0271122455596924 [19200/60000]\n",
            "training loss: 0.6532888412475586 [25600/60000]\n",
            "training loss: 1.238700270652771 [32000/60000]\n",
            "training loss: 0.8487488627433777 [38400/60000]\n",
            "training loss: 1.1266621351242065 [44800/60000]\n",
            "training loss: 1.0847680568695068 [51200/60000]\n",
            "training loss: 0.9758523106575012 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.6561249685287476%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 352\n",
            "training loss: 1.108339786529541 [0/60000]\n",
            "training loss: 1.0398199558258057 [6400/60000]\n",
            "training loss: 1.0963361263275146 [12800/60000]\n",
            "training loss: 1.026496171951294 [19200/60000]\n",
            "training loss: 0.6528921127319336 [25600/60000]\n",
            "training loss: 1.2384529113769531 [32000/60000]\n",
            "training loss: 0.8484484553337097 [38400/60000]\n",
            "training loss: 1.1264410018920898 [44800/60000]\n",
            "training loss: 1.0842137336730957 [51200/60000]\n",
            "training loss: 0.9756865501403809 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.656117582321167%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 353\n",
            "training loss: 1.10805344581604 [0/60000]\n",
            "training loss: 1.0398155450820923 [6400/60000]\n",
            "training loss: 1.096213698387146 [12800/60000]\n",
            "training loss: 1.0259132385253906 [19200/60000]\n",
            "training loss: 0.6523764133453369 [25600/60000]\n",
            "training loss: 1.2378374338150024 [32000/60000]\n",
            "training loss: 0.8479806780815125 [38400/60000]\n",
            "training loss: 1.1263335943222046 [44800/60000]\n",
            "training loss: 1.0836929082870483 [51200/60000]\n",
            "training loss: 0.9750242233276367 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.6560136848688127%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 354\n",
            "training loss: 1.107489824295044 [0/60000]\n",
            "training loss: 1.039398431777954 [6400/60000]\n",
            "training loss: 1.0958898067474365 [12800/60000]\n",
            "training loss: 1.0252532958984375 [19200/60000]\n",
            "training loss: 0.6518487334251404 [25600/60000]\n",
            "training loss: 1.2376859188079834 [32000/60000]\n",
            "training loss: 0.8473893404006958 [38400/60000]\n",
            "training loss: 1.1261860132217407 [44800/60000]\n",
            "training loss: 1.0832250118255615 [51200/60000]\n",
            "training loss: 0.9747814536094666 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.6559826689958572%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 355\n",
            "training loss: 1.1072720289230347 [0/60000]\n",
            "training loss: 1.0393017530441284 [6400/60000]\n",
            "training loss: 1.0957608222961426 [12800/60000]\n",
            "training loss: 1.0249295234680176 [19200/60000]\n",
            "training loss: 0.6512197852134705 [25600/60000]\n",
            "training loss: 1.2376009225845337 [32000/60000]\n",
            "training loss: 0.8468279838562012 [38400/60000]\n",
            "training loss: 1.126020073890686 [44800/60000]\n",
            "training loss: 1.082741618156433 [51200/60000]\n",
            "training loss: 0.974428117275238 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.655930222272873%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 356\n",
            "training loss: 1.1065971851348877 [0/60000]\n",
            "training loss: 1.0390383005142212 [6400/60000]\n",
            "training loss: 1.095549464225769 [12800/60000]\n",
            "training loss: 1.0244847536087036 [19200/60000]\n",
            "training loss: 0.6508848667144775 [25600/60000]\n",
            "training loss: 1.236810564994812 [32000/60000]\n",
            "training loss: 0.8465064167976379 [38400/60000]\n",
            "training loss: 1.1258864402770996 [44800/60000]\n",
            "training loss: 1.0821691751480103 [51200/60000]\n",
            "training loss: 0.9737227559089661 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.655874784588814%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 357\n",
            "training loss: 1.106227993965149 [0/60000]\n",
            "training loss: 1.038673758506775 [6400/60000]\n",
            "training loss: 1.0953245162963867 [12800/60000]\n",
            "training loss: 1.0237934589385986 [19200/60000]\n",
            "training loss: 0.6506009697914124 [25600/60000]\n",
            "training loss: 1.2367051839828491 [32000/60000]\n",
            "training loss: 0.8460633754730225 [38400/60000]\n",
            "training loss: 1.1257754564285278 [44800/60000]\n",
            "training loss: 1.0819462537765503 [51200/60000]\n",
            "training loss: 0.9733757376670837 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.65583653986454%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 358\n",
            "training loss: 1.1053649187088013 [0/60000]\n",
            "training loss: 1.039014220237732 [6400/60000]\n",
            "training loss: 1.0951282978057861 [12800/60000]\n",
            "training loss: 1.0232878923416138 [19200/60000]\n",
            "training loss: 0.6502793431282043 [25600/60000]\n",
            "training loss: 1.2363049983978271 [32000/60000]\n",
            "training loss: 0.8458715677261353 [38400/60000]\n",
            "training loss: 1.1255587339401245 [44800/60000]\n",
            "training loss: 1.0811985731124878 [51200/60000]\n",
            "training loss: 0.9730387330055237 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.655822011232376%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 359\n",
            "training loss: 1.105358600616455 [0/60000]\n",
            "training loss: 1.0387929677963257 [6400/60000]\n",
            "training loss: 1.0948939323425293 [12800/60000]\n",
            "training loss: 1.0227117538452148 [19200/60000]\n",
            "training loss: 0.6495919227600098 [25600/60000]\n",
            "training loss: 1.2372945547103882 [32000/60000]\n",
            "training loss: 0.8456125855445862 [38400/60000]\n",
            "training loss: 1.125407338142395 [44800/60000]\n",
            "training loss: 1.0806024074554443 [51200/60000]\n",
            "training loss: 0.9728780388832092 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.6558063119649888%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 360\n",
            "training loss: 1.1046276092529297 [0/60000]\n",
            "training loss: 1.0384392738342285 [6400/60000]\n",
            "training loss: 1.0947283506393433 [12800/60000]\n",
            "training loss: 1.0222488641738892 [19200/60000]\n",
            "training loss: 0.649328887462616 [25600/60000]\n",
            "training loss: 1.2356915473937988 [32000/60000]\n",
            "training loss: 0.8448980450630188 [38400/60000]\n",
            "training loss: 1.1252514123916626 [44800/60000]\n",
            "training loss: 1.0801512002944946 [51200/60000]\n",
            "training loss: 0.9725717902183533 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.6557823503017426%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 361\n",
            "training loss: 1.1041808128356934 [0/60000]\n",
            "training loss: 1.038215160369873 [6400/60000]\n",
            "training loss: 1.0944838523864746 [12800/60000]\n",
            "training loss: 1.021486759185791 [19200/60000]\n",
            "training loss: 0.649077832698822 [25600/60000]\n",
            "training loss: 1.2362961769104004 [32000/60000]\n",
            "training loss: 0.8450122475624084 [38400/60000]\n",
            "training loss: 1.125095009803772 [44800/60000]\n",
            "training loss: 1.0795793533325195 [51200/60000]\n",
            "training loss: 0.9721612334251404 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.6557865220308305%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 362\n",
            "training loss: 1.1035728454589844 [0/60000]\n",
            "training loss: 1.0379081964492798 [6400/60000]\n",
            "training loss: 1.0942258834838867 [12800/60000]\n",
            "training loss: 1.0209367275238037 [19200/60000]\n",
            "training loss: 0.6484492421150208 [25600/60000]\n",
            "training loss: 1.2360724210739136 [32000/60000]\n",
            "training loss: 0.8443350195884705 [38400/60000]\n",
            "training loss: 1.1249462366104126 [44800/60000]\n",
            "training loss: 1.0791960954666138 [51200/60000]\n",
            "training loss: 0.9719520807266235 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.6557337623834611%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 363\n",
            "training loss: 1.1030426025390625 [0/60000]\n",
            "training loss: 1.0376921892166138 [6400/60000]\n",
            "training loss: 1.0940110683441162 [12800/60000]\n",
            "training loss: 1.0203543901443481 [19200/60000]\n",
            "training loss: 0.6478753685951233 [25600/60000]\n",
            "training loss: 1.2355766296386719 [32000/60000]\n",
            "training loss: 0.8440670967102051 [38400/60000]\n",
            "training loss: 1.12477445602417 [44800/60000]\n",
            "training loss: 1.078842043876648 [51200/60000]\n",
            "training loss: 0.9715622067451477 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.6556852102279664%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 364\n",
            "training loss: 1.1025629043579102 [0/60000]\n",
            "training loss: 1.0370756387710571 [6400/60000]\n",
            "training loss: 1.093937635421753 [12800/60000]\n",
            "training loss: 1.0198395252227783 [19200/60000]\n",
            "training loss: 0.6472429037094116 [25600/60000]\n",
            "training loss: 1.2349438667297363 [32000/60000]\n",
            "training loss: 0.8436800837516785 [38400/60000]\n",
            "training loss: 1.1246445178985596 [44800/60000]\n",
            "training loss: 1.0780173540115356 [51200/60000]\n",
            "training loss: 0.9712606072425842 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.6556759768724443%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 365\n",
            "training loss: 1.1022262573242188 [0/60000]\n",
            "training loss: 1.0368297100067139 [6400/60000]\n",
            "training loss: 1.093674659729004 [12800/60000]\n",
            "training loss: 1.0193275213241577 [19200/60000]\n",
            "training loss: 0.6464821696281433 [25600/60000]\n",
            "training loss: 1.2350287437438965 [32000/60000]\n",
            "training loss: 0.8432987928390503 [38400/60000]\n",
            "training loss: 1.1244574785232544 [44800/60000]\n",
            "training loss: 1.0778100490570068 [51200/60000]\n",
            "training loss: 0.9708888530731201 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.655710755586624%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 366\n",
            "training loss: 1.1019219160079956 [0/60000]\n",
            "training loss: 1.0361860990524292 [6400/60000]\n",
            "training loss: 1.0935704708099365 [12800/60000]\n",
            "training loss: 1.0186903476715088 [19200/60000]\n",
            "training loss: 0.6462323665618896 [25600/60000]\n",
            "training loss: 1.234553575515747 [32000/60000]\n",
            "training loss: 0.8428899645805359 [38400/60000]\n",
            "training loss: 1.1243082284927368 [44800/60000]\n",
            "training loss: 1.0773037672042847 [51200/60000]\n",
            "training loss: 0.9705663323402405 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.6556851178407668%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 367\n",
            "training loss: 1.1013526916503906 [0/60000]\n",
            "training loss: 1.0361653566360474 [6400/60000]\n",
            "training loss: 1.093328833580017 [12800/60000]\n",
            "training loss: 1.0183186531066895 [19200/60000]\n",
            "training loss: 0.6459548473358154 [25600/60000]\n",
            "training loss: 1.2341943979263306 [32000/60000]\n",
            "training loss: 0.8423523902893066 [38400/60000]\n",
            "training loss: 1.124099612236023 [44800/60000]\n",
            "training loss: 1.0768324136734009 [51200/60000]\n",
            "training loss: 0.9703006744384766 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.655700213313103%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 368\n",
            "training loss: 1.1014372110366821 [0/60000]\n",
            "training loss: 1.0357426404953003 [6400/60000]\n",
            "training loss: 1.0930891036987305 [12800/60000]\n",
            "training loss: 1.0179643630981445 [19200/60000]\n",
            "training loss: 0.6457083821296692 [25600/60000]\n",
            "training loss: 1.2337242364883423 [32000/60000]\n",
            "training loss: 0.8419961333274841 [38400/60000]\n",
            "training loss: 1.1256859302520752 [44800/60000]\n",
            "training loss: 1.0752896070480347 [51200/60000]\n",
            "training loss: 0.9699371457099915 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.655601578950882%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 369\n",
            "training loss: 1.0991233587265015 [0/60000]\n",
            "training loss: 1.0354247093200684 [6400/60000]\n",
            "training loss: 1.0928618907928467 [12800/60000]\n",
            "training loss: 1.0174427032470703 [19200/60000]\n",
            "training loss: 0.6453995108604431 [25600/60000]\n",
            "training loss: 1.233795404434204 [32000/60000]\n",
            "training loss: 0.8416681289672852 [38400/60000]\n",
            "training loss: 1.1254994869232178 [44800/60000]\n",
            "training loss: 1.0750149488449097 [51200/60000]\n",
            "training loss: 0.9696594476699829 [57600/60000]\n",
            "Correct Predictions: 58.050000000000004%, Average Loss: 1.6555968755483628%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 370\n",
            "training loss: 1.0985609292984009 [0/60000]\n",
            "training loss: 1.034954309463501 [6400/60000]\n",
            "training loss: 1.092656135559082 [12800/60000]\n",
            "training loss: 1.0169508457183838 [19200/60000]\n",
            "training loss: 0.6452181935310364 [25600/60000]\n",
            "training loss: 1.2334201335906982 [32000/60000]\n",
            "training loss: 0.8413662314414978 [38400/60000]\n",
            "training loss: 1.1255017518997192 [44800/60000]\n",
            "training loss: 1.074507474899292 [51200/60000]\n",
            "training loss: 0.9693275690078735 [57600/60000]\n",
            "Correct Predictions: 58.050000000000004%, Average Loss: 1.6556542152166367%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 371\n",
            "training loss: 1.0982468128204346 [0/60000]\n",
            "training loss: 1.0347554683685303 [6400/60000]\n",
            "training loss: 1.0926241874694824 [12800/60000]\n",
            "training loss: 1.0162019729614258 [19200/60000]\n",
            "training loss: 0.6448092460632324 [25600/60000]\n",
            "training loss: 1.2336033582687378 [32000/60000]\n",
            "training loss: 0.8409678339958191 [38400/60000]\n",
            "training loss: 1.1253395080566406 [44800/60000]\n",
            "training loss: 1.0740219354629517 [51200/60000]\n",
            "training loss: 0.9691685438156128 [57600/60000]\n",
            "Correct Predictions: 58.050000000000004%, Average Loss: 1.6556997925043104%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 372\n",
            "training loss: 1.0974692106246948 [0/60000]\n",
            "training loss: 1.0342824459075928 [6400/60000]\n",
            "training loss: 1.0923577547073364 [12800/60000]\n",
            "training loss: 1.0157220363616943 [19200/60000]\n",
            "training loss: 0.6440882086753845 [25600/60000]\n",
            "training loss: 1.2333070039749146 [32000/60000]\n",
            "training loss: 0.8406569361686707 [38400/60000]\n",
            "training loss: 1.1251044273376465 [44800/60000]\n",
            "training loss: 1.0736004114151 [51200/60000]\n",
            "training loss: 0.9690167903900146 [57600/60000]\n",
            "Correct Predictions: 58.050000000000004%, Average Loss: 1.655752226114273%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 373\n",
            "training loss: 1.0973337888717651 [0/60000]\n",
            "training loss: 1.0336694717407227 [6400/60000]\n",
            "training loss: 1.0922186374664307 [12800/60000]\n",
            "training loss: 1.0152082443237305 [19200/60000]\n",
            "training loss: 0.6439244747161865 [25600/60000]\n",
            "training loss: 1.232295036315918 [32000/60000]\n",
            "training loss: 0.8402392268180847 [38400/60000]\n",
            "training loss: 1.1249475479125977 [44800/60000]\n",
            "training loss: 1.0729163885116577 [51200/60000]\n",
            "training loss: 0.9686528444290161 [57600/60000]\n",
            "Correct Predictions: 58.050000000000004%, Average Loss: 1.6558049768209455%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 374\n",
            "training loss: 1.0966534614562988 [0/60000]\n",
            "training loss: 1.0333316326141357 [6400/60000]\n",
            "training loss: 1.0919564962387085 [12800/60000]\n",
            "training loss: 1.0145734548568726 [19200/60000]\n",
            "training loss: 0.6428343057632446 [25600/60000]\n",
            "training loss: 1.2320307493209839 [32000/60000]\n",
            "training loss: 0.8399161696434021 [38400/60000]\n",
            "training loss: 1.1248458623886108 [44800/60000]\n",
            "training loss: 1.0723955631256104 [51200/60000]\n",
            "training loss: 0.9684010148048401 [57600/60000]\n",
            "Correct Predictions: 58.06%, Average Loss: 1.6559057873487473%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 375\n",
            "training loss: 1.097937822341919 [0/60000]\n",
            "training loss: 1.0331308841705322 [6400/60000]\n",
            "training loss: 1.0918505191802979 [12800/60000]\n",
            "training loss: 1.0140295028686523 [19200/60000]\n",
            "training loss: 0.6426416039466858 [25600/60000]\n",
            "training loss: 1.2312517166137695 [32000/60000]\n",
            "training loss: 0.8394265174865723 [38400/60000]\n",
            "training loss: 1.124729871749878 [44800/60000]\n",
            "training loss: 1.072134256362915 [51200/60000]\n",
            "training loss: 0.9680392742156982 [57600/60000]\n",
            "Correct Predictions: 58.06%, Average Loss: 1.6559204989671708%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 376\n",
            "training loss: 1.0975791215896606 [0/60000]\n",
            "training loss: 1.0324381589889526 [6400/60000]\n",
            "training loss: 1.0918065309524536 [12800/60000]\n",
            "training loss: 1.0137118101119995 [19200/60000]\n",
            "training loss: 0.64188551902771 [25600/60000]\n",
            "training loss: 1.2310246229171753 [32000/60000]\n",
            "training loss: 0.8392351865768433 [38400/60000]\n",
            "training loss: 1.124610185623169 [44800/60000]\n",
            "training loss: 1.071480631828308 [51200/60000]\n",
            "training loss: 0.9678903818130493 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.6559727025032043%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 377\n",
            "training loss: 1.0951740741729736 [0/60000]\n",
            "training loss: 1.032310128211975 [6400/60000]\n",
            "training loss: 1.091488242149353 [12800/60000]\n",
            "training loss: 1.0133967399597168 [19200/60000]\n",
            "training loss: 0.6416552662849426 [25600/60000]\n",
            "training loss: 1.2301687002182007 [32000/60000]\n",
            "training loss: 0.8389468789100647 [38400/60000]\n",
            "training loss: 1.124334454536438 [44800/60000]\n",
            "training loss: 1.0704247951507568 [51200/60000]\n",
            "training loss: 0.9673116207122803 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.6559923046827316%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 378\n",
            "training loss: 1.0946604013442993 [0/60000]\n",
            "training loss: 1.0321663618087769 [6400/60000]\n",
            "training loss: 1.091303825378418 [12800/60000]\n",
            "training loss: 1.0127854347229004 [19200/60000]\n",
            "training loss: 0.6413687467575073 [25600/60000]\n",
            "training loss: 1.2299433946609497 [32000/60000]\n",
            "training loss: 0.8385655283927917 [38400/60000]\n",
            "training loss: 1.1242351531982422 [44800/60000]\n",
            "training loss: 1.0700191259384155 [51200/60000]\n",
            "training loss: 0.9672157764434814 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.6560624045133592%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 379\n",
            "training loss: 1.0943893194198608 [0/60000]\n",
            "training loss: 1.031785488128662 [6400/60000]\n",
            "training loss: 1.091271162033081 [12800/60000]\n",
            "training loss: 1.0125569105148315 [19200/60000]\n",
            "training loss: 0.6414009928703308 [25600/60000]\n",
            "training loss: 1.2294254302978516 [32000/60000]\n",
            "training loss: 0.8381868600845337 [38400/60000]\n",
            "training loss: 1.1241339445114136 [44800/60000]\n",
            "training loss: 1.0697541236877441 [51200/60000]\n",
            "training loss: 0.9670966863632202 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.6561439365148545%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 380\n",
            "training loss: 1.094078540802002 [0/60000]\n",
            "training loss: 1.0307104587554932 [6400/60000]\n",
            "training loss: 1.090954303741455 [12800/60000]\n",
            "training loss: 1.012073278427124 [19200/60000]\n",
            "training loss: 0.6406263709068298 [25600/60000]\n",
            "training loss: 1.2284317016601562 [32000/60000]\n",
            "training loss: 0.8378817439079285 [38400/60000]\n",
            "training loss: 1.1239136457443237 [44800/60000]\n",
            "training loss: 1.0690363645553589 [51200/60000]\n",
            "training loss: 0.9668659567832947 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.656075617671013%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 381\n",
            "training loss: 1.093306541442871 [0/60000]\n",
            "training loss: 1.030916690826416 [6400/60000]\n",
            "training loss: 1.090855598449707 [12800/60000]\n",
            "training loss: 1.0116318464279175 [19200/60000]\n",
            "training loss: 0.6408726572990417 [25600/60000]\n",
            "training loss: 1.2281925678253174 [32000/60000]\n",
            "training loss: 0.8376390337944031 [38400/60000]\n",
            "training loss: 1.1237337589263916 [44800/60000]\n",
            "training loss: 1.0685068368911743 [51200/60000]\n",
            "training loss: 0.966539204120636 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.6561614364385604%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 382\n",
            "training loss: 1.0930683612823486 [0/60000]\n",
            "training loss: 1.030441403388977 [6400/60000]\n",
            "training loss: 1.090984582901001 [12800/60000]\n",
            "training loss: 1.011070966720581 [19200/60000]\n",
            "training loss: 0.6402254104614258 [25600/60000]\n",
            "training loss: 1.2274926900863647 [32000/60000]\n",
            "training loss: 0.8372359871864319 [38400/60000]\n",
            "training loss: 1.1235511302947998 [44800/60000]\n",
            "training loss: 1.0682297945022583 [51200/60000]\n",
            "training loss: 0.9663424491882324 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.6562280642986298%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 383\n",
            "training loss: 1.092912197113037 [0/60000]\n",
            "training loss: 1.0300238132476807 [6400/60000]\n",
            "training loss: 1.0906096696853638 [12800/60000]\n",
            "training loss: 1.0106847286224365 [19200/60000]\n",
            "training loss: 0.6400651335716248 [25600/60000]\n",
            "training loss: 1.2262705564498901 [32000/60000]\n",
            "training loss: 0.8368675708770752 [38400/60000]\n",
            "training loss: 1.1233837604522705 [44800/60000]\n",
            "training loss: 1.068425178527832 [51200/60000]\n",
            "training loss: 0.9660399556159973 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6562498360872269%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 384\n",
            "training loss: 1.0923402309417725 [0/60000]\n",
            "training loss: 1.0297458171844482 [6400/60000]\n",
            "training loss: 1.090614914894104 [12800/60000]\n",
            "training loss: 1.010241985321045 [19200/60000]\n",
            "training loss: 0.6397883892059326 [25600/60000]\n",
            "training loss: 1.2261186838150024 [32000/60000]\n",
            "training loss: 0.8365736603736877 [38400/60000]\n",
            "training loss: 1.1232019662857056 [44800/60000]\n",
            "training loss: 1.067915916442871 [51200/60000]\n",
            "training loss: 0.9656627774238586 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6563888943195344%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 385\n",
            "training loss: 1.0922319889068604 [0/60000]\n",
            "training loss: 1.0295231342315674 [6400/60000]\n",
            "training loss: 1.0906099081039429 [12800/60000]\n",
            "training loss: 1.0098257064819336 [19200/60000]\n",
            "training loss: 0.6393599510192871 [25600/60000]\n",
            "training loss: 1.2254865169525146 [32000/60000]\n",
            "training loss: 0.8362086415290833 [38400/60000]\n",
            "training loss: 1.1231019496917725 [44800/60000]\n",
            "training loss: 1.0674415826797485 [51200/60000]\n",
            "training loss: 0.9658151268959045 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.6568657660484314%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 386\n",
            "training loss: 1.0900548696517944 [0/60000]\n",
            "training loss: 1.0290064811706543 [6400/60000]\n",
            "training loss: 1.0901790857315063 [12800/60000]\n",
            "training loss: 1.0095205307006836 [19200/60000]\n",
            "training loss: 0.638994574546814 [25600/60000]\n",
            "training loss: 1.2248361110687256 [32000/60000]\n",
            "training loss: 0.8358291387557983 [38400/60000]\n",
            "training loss: 1.1228500604629517 [44800/60000]\n",
            "training loss: 1.0670639276504517 [51200/60000]\n",
            "training loss: 0.9655067920684814 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.6569808202981948%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 387\n",
            "training loss: 1.0897037982940674 [0/60000]\n",
            "training loss: 1.0289692878723145 [6400/60000]\n",
            "training loss: 1.0901908874511719 [12800/60000]\n",
            "training loss: 1.0091750621795654 [19200/60000]\n",
            "training loss: 0.6386235356330872 [25600/60000]\n",
            "training loss: 1.2243516445159912 [32000/60000]\n",
            "training loss: 0.8354941010475159 [38400/60000]\n",
            "training loss: 1.1226885318756104 [44800/60000]\n",
            "training loss: 1.0664548873901367 [51200/60000]\n",
            "training loss: 0.9653338193893433 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6570294046401979%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 388\n",
            "training loss: 1.089005947113037 [0/60000]\n",
            "training loss: 1.0281462669372559 [6400/60000]\n",
            "training loss: 1.0900332927703857 [12800/60000]\n",
            "training loss: 1.0083991289138794 [19200/60000]\n",
            "training loss: 0.6386023163795471 [25600/60000]\n",
            "training loss: 1.2239900827407837 [32000/60000]\n",
            "training loss: 0.8350539207458496 [38400/60000]\n",
            "training loss: 1.1224614381790161 [44800/60000]\n",
            "training loss: 1.0661470890045166 [51200/60000]\n",
            "training loss: 0.9650214910507202 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.657112954258919%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 389\n",
            "training loss: 1.0889686346054077 [0/60000]\n",
            "training loss: 1.02780282497406 [6400/60000]\n",
            "training loss: 1.0896670818328857 [12800/60000]\n",
            "training loss: 1.0078855752944946 [19200/60000]\n",
            "training loss: 0.6380454301834106 [25600/60000]\n",
            "training loss: 1.2227188348770142 [32000/60000]\n",
            "training loss: 0.834614098072052 [38400/60000]\n",
            "training loss: 1.1223502159118652 [44800/60000]\n",
            "training loss: 1.0657013654708862 [51200/60000]\n",
            "training loss: 0.9648451209068298 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6572259426116942%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 390\n",
            "training loss: 1.0886969566345215 [0/60000]\n",
            "training loss: 1.0273268222808838 [6400/60000]\n",
            "training loss: 1.0898455381393433 [12800/60000]\n",
            "training loss: 1.007734775543213 [19200/60000]\n",
            "training loss: 0.6374689340591431 [25600/60000]\n",
            "training loss: 1.2226709127426147 [32000/60000]\n",
            "training loss: 0.8343394994735718 [38400/60000]\n",
            "training loss: 1.1222039461135864 [44800/60000]\n",
            "training loss: 1.0654387474060059 [51200/60000]\n",
            "training loss: 0.964616596698761 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6572237426042555%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 391\n",
            "training loss: 1.0884952545166016 [0/60000]\n",
            "training loss: 1.0269362926483154 [6400/60000]\n",
            "training loss: 1.0896378755569458 [12800/60000]\n",
            "training loss: 1.0069459676742554 [19200/60000]\n",
            "training loss: 0.6368424296379089 [25600/60000]\n",
            "training loss: 1.2223303318023682 [32000/60000]\n",
            "training loss: 0.8337308764457703 [38400/60000]\n",
            "training loss: 1.1222131252288818 [44800/60000]\n",
            "training loss: 1.0649809837341309 [51200/60000]\n",
            "training loss: 0.9644740223884583 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.657407203912735%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 392\n",
            "training loss: 1.088191032409668 [0/60000]\n",
            "training loss: 1.0263100862503052 [6400/60000]\n",
            "training loss: 1.0890482664108276 [12800/60000]\n",
            "training loss: 1.0068529844284058 [19200/60000]\n",
            "training loss: 0.6369571685791016 [25600/60000]\n",
            "training loss: 1.2211132049560547 [32000/60000]\n",
            "training loss: 0.8334991335868835 [38400/60000]\n",
            "training loss: 1.1220266819000244 [44800/60000]\n",
            "training loss: 1.0649125576019287 [51200/60000]\n",
            "training loss: 0.9642091393470764 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6573967421054838%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 393\n",
            "training loss: 1.0878106355667114 [0/60000]\n",
            "training loss: 1.0260587930679321 [6400/60000]\n",
            "training loss: 1.0890233516693115 [12800/60000]\n",
            "training loss: 1.0061299800872803 [19200/60000]\n",
            "training loss: 0.6355429887771606 [25600/60000]\n",
            "training loss: 1.2210911512374878 [32000/60000]\n",
            "training loss: 0.8329852223396301 [38400/60000]\n",
            "training loss: 1.1218652725219727 [44800/60000]\n",
            "training loss: 1.0642616748809814 [51200/60000]\n",
            "training loss: 0.9638182520866394 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6575247859954834%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 394\n",
            "training loss: 1.0874053239822388 [0/60000]\n",
            "training loss: 1.0251113176345825 [6400/60000]\n",
            "training loss: 1.089179515838623 [12800/60000]\n",
            "training loss: 1.0059444904327393 [19200/60000]\n",
            "training loss: 0.6355265378952026 [25600/60000]\n",
            "training loss: 1.220192313194275 [32000/60000]\n",
            "training loss: 0.8324999809265137 [38400/60000]\n",
            "training loss: 1.121763825416565 [44800/60000]\n",
            "training loss: 1.0645288228988647 [51200/60000]\n",
            "training loss: 0.9636067748069763 [57600/60000]\n",
            "Correct Predictions: 57.99999999999999%, Average Loss: 1.6576918458938599%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 395\n",
            "training loss: 1.0871204137802124 [0/60000]\n",
            "training loss: 1.0249221324920654 [6400/60000]\n",
            "training loss: 1.0889978408813477 [12800/60000]\n",
            "training loss: 1.0052454471588135 [19200/60000]\n",
            "training loss: 0.6321740746498108 [25600/60000]\n",
            "training loss: 1.2193019390106201 [32000/60000]\n",
            "training loss: 0.8321563601493835 [38400/60000]\n",
            "training loss: 1.121739149093628 [44800/60000]\n",
            "training loss: 1.0640417337417603 [51200/60000]\n",
            "training loss: 0.9635047316551208 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6578193122148515%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 396\n",
            "training loss: 1.0869550704956055 [0/60000]\n",
            "training loss: 1.0244427919387817 [6400/60000]\n",
            "training loss: 1.0887001752853394 [12800/60000]\n",
            "training loss: 1.0048893690109253 [19200/60000]\n",
            "training loss: 0.6341155767440796 [25600/60000]\n",
            "training loss: 1.2196581363677979 [32000/60000]\n",
            "training loss: 0.8319404721260071 [38400/60000]\n",
            "training loss: 1.1216578483581543 [44800/60000]\n",
            "training loss: 1.06373131275177 [51200/60000]\n",
            "training loss: 0.9676934480667114 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6579225963354112%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 397\n",
            "training loss: 1.0868383646011353 [0/60000]\n",
            "training loss: 1.0239791870117188 [6400/60000]\n",
            "training loss: 1.0888859033584595 [12800/60000]\n",
            "training loss: 1.0043247938156128 [19200/60000]\n",
            "training loss: 0.6331954002380371 [25600/60000]\n",
            "training loss: 1.2196909189224243 [32000/60000]\n",
            "training loss: 0.8314889669418335 [38400/60000]\n",
            "training loss: 1.121572494506836 [44800/60000]\n",
            "training loss: 1.0630521774291992 [51200/60000]\n",
            "training loss: 0.9675737023353577 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.657977831363678%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 398\n",
            "training loss: 1.0865705013275146 [0/60000]\n",
            "training loss: 1.0235486030578613 [6400/60000]\n",
            "training loss: 1.0884631872177124 [12800/60000]\n",
            "training loss: 1.0038971900939941 [19200/60000]\n",
            "training loss: 0.6328009963035583 [25600/60000]\n",
            "training loss: 1.2190228700637817 [32000/60000]\n",
            "training loss: 0.8311821818351746 [38400/60000]\n",
            "training loss: 1.1213825941085815 [44800/60000]\n",
            "training loss: 1.0623160600662231 [51200/60000]\n",
            "training loss: 0.9673733711242676 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.658100237250328%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 399\n",
            "training loss: 1.0862230062484741 [0/60000]\n",
            "training loss: 1.0231505632400513 [6400/60000]\n",
            "training loss: 1.0883349180221558 [12800/60000]\n",
            "training loss: 1.0033477544784546 [19200/60000]\n",
            "training loss: 0.6326637864112854 [25600/60000]\n",
            "training loss: 1.2186793088912964 [32000/60000]\n",
            "training loss: 0.8307754993438721 [38400/60000]\n",
            "training loss: 1.1212788820266724 [44800/60000]\n",
            "training loss: 1.0621551275253296 [51200/60000]\n",
            "training loss: 0.9670004844665527 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.6582427728176117%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 400\n",
            "training loss: 1.0858582258224487 [0/60000]\n",
            "training loss: 1.022925615310669 [6400/60000]\n",
            "training loss: 1.0884450674057007 [12800/60000]\n",
            "training loss: 1.002933382987976 [19200/60000]\n",
            "training loss: 0.6287871599197388 [25600/60000]\n",
            "training loss: 1.2178555727005005 [32000/60000]\n",
            "training loss: 0.830398440361023 [38400/60000]\n",
            "training loss: 1.1211895942687988 [44800/60000]\n",
            "training loss: 1.0616755485534668 [51200/60000]\n",
            "training loss: 0.9666153192520142 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6583328425884245%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 401\n",
            "training loss: 1.085632085800171 [0/60000]\n",
            "training loss: 1.0223740339279175 [6400/60000]\n",
            "training loss: 1.088039755821228 [12800/60000]\n",
            "training loss: 1.0025792121887207 [19200/60000]\n",
            "training loss: 0.6286479830741882 [25600/60000]\n",
            "training loss: 1.217444658279419 [32000/60000]\n",
            "training loss: 0.8298279643058777 [38400/60000]\n",
            "training loss: 1.1210297346115112 [44800/60000]\n",
            "training loss: 1.0613996982574463 [51200/60000]\n",
            "training loss: 0.9666072130203247 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6584566420316698%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 402\n",
            "training loss: 1.0854129791259766 [0/60000]\n",
            "training loss: 1.0219589471817017 [6400/60000]\n",
            "training loss: 1.087908148765564 [12800/60000]\n",
            "training loss: 1.0022999048233032 [19200/60000]\n",
            "training loss: 0.628300666809082 [25600/60000]\n",
            "training loss: 1.2165261507034302 [32000/60000]\n",
            "training loss: 0.8297961354255676 [38400/60000]\n",
            "training loss: 1.120943307876587 [44800/60000]\n",
            "training loss: 1.0607149600982666 [51200/60000]\n",
            "training loss: 0.966170072555542 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6585302710533143%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 403\n",
            "training loss: 1.0847737789154053 [0/60000]\n",
            "training loss: 1.021651268005371 [6400/60000]\n",
            "training loss: 1.087868571281433 [12800/60000]\n",
            "training loss: 1.0018821954727173 [19200/60000]\n",
            "training loss: 0.6277691721916199 [25600/60000]\n",
            "training loss: 1.2162129878997803 [32000/60000]\n",
            "training loss: 0.8291848301887512 [38400/60000]\n",
            "training loss: 1.1208988428115845 [44800/60000]\n",
            "training loss: 1.060393214225769 [51200/60000]\n",
            "training loss: 0.9661561846733093 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6586571615934371%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 404\n",
            "training loss: 1.084795594215393 [0/60000]\n",
            "training loss: 1.0214217901229858 [6400/60000]\n",
            "training loss: 1.087809443473816 [12800/60000]\n",
            "training loss: 1.00153648853302 [19200/60000]\n",
            "training loss: 0.6278979182243347 [25600/60000]\n",
            "training loss: 1.21578848361969 [32000/60000]\n",
            "training loss: 0.8288764953613281 [38400/60000]\n",
            "training loss: 1.1208066940307617 [44800/60000]\n",
            "training loss: 1.0599156618118286 [51200/60000]\n",
            "training loss: 0.9658825397491455 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6587672066688537%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 405\n",
            "training loss: 1.0845985412597656 [0/60000]\n",
            "training loss: 1.021059274673462 [6400/60000]\n",
            "training loss: 1.0879164934158325 [12800/60000]\n",
            "training loss: 1.0013371706008911 [19200/60000]\n",
            "training loss: 0.6284731030464172 [25600/60000]\n",
            "training loss: 1.2150112390518188 [32000/60000]\n",
            "training loss: 0.8284544348716736 [38400/60000]\n",
            "training loss: 1.1207678318023682 [44800/60000]\n",
            "training loss: 1.0593444108963013 [51200/60000]\n",
            "training loss: 0.9656156301498413 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6591050922870636%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 406\n",
            "training loss: 1.0838781595230103 [0/60000]\n",
            "training loss: 1.0207973718643188 [6400/60000]\n",
            "training loss: 1.0878009796142578 [12800/60000]\n",
            "training loss: 1.001094937324524 [19200/60000]\n",
            "training loss: 0.6278433203697205 [25600/60000]\n",
            "training loss: 1.2147656679153442 [32000/60000]\n",
            "training loss: 0.8281092643737793 [38400/60000]\n",
            "training loss: 1.1206459999084473 [44800/60000]\n",
            "training loss: 1.058915138244629 [51200/60000]\n",
            "training loss: 0.9653977155685425 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6591740363836287%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 407\n",
            "training loss: 1.0839729309082031 [0/60000]\n",
            "training loss: 1.0203155279159546 [6400/60000]\n",
            "training loss: 1.087714672088623 [12800/60000]\n",
            "training loss: 1.0005539655685425 [19200/60000]\n",
            "training loss: 0.6270796656608582 [25600/60000]\n",
            "training loss: 1.2142959833145142 [32000/60000]\n",
            "training loss: 0.8277109265327454 [38400/60000]\n",
            "training loss: 1.1205651760101318 [44800/60000]\n",
            "training loss: 1.0585241317749023 [51200/60000]\n",
            "training loss: 0.9653388857841492 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6592976135015487%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 408\n",
            "training loss: 1.083509922027588 [0/60000]\n",
            "training loss: 1.0199260711669922 [6400/60000]\n",
            "training loss: 1.08742356300354 [12800/60000]\n",
            "training loss: 1.0004959106445312 [19200/60000]\n",
            "training loss: 0.6270325183868408 [25600/60000]\n",
            "training loss: 1.2137783765792847 [32000/60000]\n",
            "training loss: 0.8275914788246155 [38400/60000]\n",
            "training loss: 1.120468020439148 [44800/60000]\n",
            "training loss: 1.0576854944229126 [51200/60000]\n",
            "training loss: 0.9650552868843079 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6594541519880295%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 409\n",
            "training loss: 1.0830885171890259 [0/60000]\n",
            "training loss: 1.0196943283081055 [6400/60000]\n",
            "training loss: 1.087446689605713 [12800/60000]\n",
            "training loss: 0.9999504685401917 [19200/60000]\n",
            "training loss: 0.6236492395401001 [25600/60000]\n",
            "training loss: 1.2133339643478394 [32000/60000]\n",
            "training loss: 0.8272206783294678 [38400/60000]\n",
            "training loss: 1.1203656196594238 [44800/60000]\n",
            "training loss: 1.0573970079421997 [51200/60000]\n",
            "training loss: 0.9649157524108887 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.659533775448799%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 410\n",
            "training loss: 1.083178162574768 [0/60000]\n",
            "training loss: 1.0198386907577515 [6400/60000]\n",
            "training loss: 1.0872844457626343 [12800/60000]\n",
            "training loss: 0.9997873306274414 [19200/60000]\n",
            "training loss: 0.6235175728797913 [25600/60000]\n",
            "training loss: 1.2125887870788574 [32000/60000]\n",
            "training loss: 0.8267767429351807 [38400/60000]\n",
            "training loss: 1.1202439069747925 [44800/60000]\n",
            "training loss: 1.0569393634796143 [51200/60000]\n",
            "training loss: 0.9644791483879089 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6596562755107882%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 411\n",
            "training loss: 1.0829154253005981 [0/60000]\n",
            "training loss: 1.0196453332901 [6400/60000]\n",
            "training loss: 1.0871577262878418 [12800/60000]\n",
            "training loss: 0.9992567896842957 [19200/60000]\n",
            "training loss: 0.623555600643158 [25600/60000]\n",
            "training loss: 1.2117007970809937 [32000/60000]\n",
            "training loss: 0.8264345526695251 [38400/60000]\n",
            "training loss: 1.120164155960083 [44800/60000]\n",
            "training loss: 1.056585431098938 [51200/60000]\n",
            "training loss: 0.9641978144645691 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6598636996746063%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 412\n",
            "training loss: 1.0826939344406128 [0/60000]\n",
            "training loss: 1.0190298557281494 [6400/60000]\n",
            "training loss: 1.0871185064315796 [12800/60000]\n",
            "training loss: 0.9992082715034485 [19200/60000]\n",
            "training loss: 0.6229130029678345 [25600/60000]\n",
            "training loss: 1.2114653587341309 [32000/60000]\n",
            "training loss: 0.8260674476623535 [38400/60000]\n",
            "training loss: 1.120054006576538 [44800/60000]\n",
            "training loss: 1.0576107501983643 [51200/60000]\n",
            "training loss: 0.9639719128608704 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6599639821052552%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 413\n",
            "training loss: 1.0825088024139404 [0/60000]\n",
            "training loss: 1.0184022188186646 [6400/60000]\n",
            "training loss: 1.0869337320327759 [12800/60000]\n",
            "training loss: 0.9988183379173279 [19200/60000]\n",
            "training loss: 0.6227359175682068 [25600/60000]\n",
            "training loss: 1.2109626531600952 [32000/60000]\n",
            "training loss: 0.8255996108055115 [38400/60000]\n",
            "training loss: 1.120078444480896 [44800/60000]\n",
            "training loss: 1.055212140083313 [51200/60000]\n",
            "training loss: 0.9638670086860657 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6601494914293289%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 414\n",
            "training loss: 1.0816172361373901 [0/60000]\n",
            "training loss: 1.0180448293685913 [6400/60000]\n",
            "training loss: 1.0868687629699707 [12800/60000]\n",
            "training loss: 0.9986253380775452 [19200/60000]\n",
            "training loss: 0.6227636337280273 [25600/60000]\n",
            "training loss: 1.2106292247772217 [32000/60000]\n",
            "training loss: 0.8251950144767761 [38400/60000]\n",
            "training loss: 1.1199157238006592 [44800/60000]\n",
            "training loss: 1.0568851232528687 [51200/60000]\n",
            "training loss: 0.96329665184021 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6601524209976195%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 415\n",
            "training loss: 1.0820550918579102 [0/60000]\n",
            "training loss: 1.0178544521331787 [6400/60000]\n",
            "training loss: 1.0868258476257324 [12800/60000]\n",
            "training loss: 0.9982046484947205 [19200/60000]\n",
            "training loss: 0.6224647760391235 [25600/60000]\n",
            "training loss: 1.210351586341858 [32000/60000]\n",
            "training loss: 0.8246466517448425 [38400/60000]\n",
            "training loss: 1.1198536157608032 [44800/60000]\n",
            "training loss: 1.0550998449325562 [51200/60000]\n",
            "training loss: 0.9631707072257996 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.66040485560894%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 416\n",
            "training loss: 1.0812909603118896 [0/60000]\n",
            "training loss: 1.017127513885498 [6400/60000]\n",
            "training loss: 1.086737871170044 [12800/60000]\n",
            "training loss: 0.997787356376648 [19200/60000]\n",
            "training loss: 0.6222078204154968 [25600/60000]\n",
            "training loss: 1.2097562551498413 [32000/60000]\n",
            "training loss: 0.8245095610618591 [38400/60000]\n",
            "training loss: 1.1197941303253174 [44800/60000]\n",
            "training loss: 1.0560476779937744 [51200/60000]\n",
            "training loss: 0.962971031665802 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.660568832755089%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 417\n",
            "training loss: 1.0812631845474243 [0/60000]\n",
            "training loss: 1.0166491270065308 [6400/60000]\n",
            "training loss: 1.0865987539291382 [12800/60000]\n",
            "training loss: 0.997552752494812 [19200/60000]\n",
            "training loss: 0.621799111366272 [25600/60000]\n",
            "training loss: 1.2093608379364014 [32000/60000]\n",
            "training loss: 0.8240718245506287 [38400/60000]\n",
            "training loss: 1.1197352409362793 [44800/60000]\n",
            "training loss: 1.055731177330017 [51200/60000]\n",
            "training loss: 0.9629237055778503 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.660789458155632%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 418\n",
            "training loss: 1.0808826684951782 [0/60000]\n",
            "training loss: 1.0162734985351562 [6400/60000]\n",
            "training loss: 1.0865627527236938 [12800/60000]\n",
            "training loss: 0.9971651434898376 [19200/60000]\n",
            "training loss: 0.6219528913497925 [25600/60000]\n",
            "training loss: 1.20890474319458 [32000/60000]\n",
            "training loss: 0.8238441944122314 [38400/60000]\n",
            "training loss: 1.1196234226226807 [44800/60000]\n",
            "training loss: 1.055679202079773 [51200/60000]\n",
            "training loss: 0.9628162980079651 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6609033447504042%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 419\n",
            "training loss: 1.0802568197250366 [0/60000]\n",
            "training loss: 1.0158028602600098 [6400/60000]\n",
            "training loss: 1.086721658706665 [12800/60000]\n",
            "training loss: 0.9969449043273926 [19200/60000]\n",
            "training loss: 0.6216779947280884 [25600/60000]\n",
            "training loss: 1.2086737155914307 [32000/60000]\n",
            "training loss: 0.8235906362533569 [38400/60000]\n",
            "training loss: 1.1195390224456787 [44800/60000]\n",
            "training loss: 1.0556617975234985 [51200/60000]\n",
            "training loss: 0.9624208807945251 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6611158829927444%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 420\n",
            "training loss: 1.0800639390945435 [0/60000]\n",
            "training loss: 1.0156723260879517 [6400/60000]\n",
            "training loss: 1.0865689516067505 [12800/60000]\n",
            "training loss: 0.996833324432373 [19200/60000]\n",
            "training loss: 0.6212376356124878 [25600/60000]\n",
            "training loss: 1.2078415155410767 [32000/60000]\n",
            "training loss: 0.8231456875801086 [38400/60000]\n",
            "training loss: 1.1195478439331055 [44800/60000]\n",
            "training loss: 1.0552637577056885 [51200/60000]\n",
            "training loss: 0.9619171023368835 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6613041979074479%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 421\n",
            "training loss: 1.0794434547424316 [0/60000]\n",
            "training loss: 1.0149354934692383 [6400/60000]\n",
            "training loss: 1.086341142654419 [12800/60000]\n",
            "training loss: 0.996418833732605 [19200/60000]\n",
            "training loss: 0.6208772659301758 [25600/60000]\n",
            "training loss: 1.207916021347046 [32000/60000]\n",
            "training loss: 0.8225646018981934 [38400/60000]\n",
            "training loss: 1.1194065809249878 [44800/60000]\n",
            "training loss: 1.0545485019683838 [51200/60000]\n",
            "training loss: 0.9619153738021851 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6614867717027666%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 422\n",
            "training loss: 1.079226016998291 [0/60000]\n",
            "training loss: 1.014432668685913 [6400/60000]\n",
            "training loss: 1.0864222049713135 [12800/60000]\n",
            "training loss: 0.9959158301353455 [19200/60000]\n",
            "training loss: 0.6202470064163208 [25600/60000]\n",
            "training loss: 1.207848310470581 [32000/60000]\n",
            "training loss: 0.8223740458488464 [38400/60000]\n",
            "training loss: 1.1193430423736572 [44800/60000]\n",
            "training loss: 1.0556271076202393 [51200/60000]\n",
            "training loss: 0.9616830945014954 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6616377884149551%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 423\n",
            "training loss: 1.0788624286651611 [0/60000]\n",
            "training loss: 1.0141873359680176 [6400/60000]\n",
            "training loss: 1.0863295793533325 [12800/60000]\n",
            "training loss: 0.9957137107849121 [19200/60000]\n",
            "training loss: 0.6199480891227722 [25600/60000]\n",
            "training loss: 1.2073490619659424 [32000/60000]\n",
            "training loss: 0.8219100832939148 [38400/60000]\n",
            "training loss: 1.1192998886108398 [44800/60000]\n",
            "training loss: 1.055053949356079 [51200/60000]\n",
            "training loss: 0.9614748954772949 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6618087774515153%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 424\n",
            "training loss: 1.078574299812317 [0/60000]\n",
            "training loss: 1.0139062404632568 [6400/60000]\n",
            "training loss: 1.0862529277801514 [12800/60000]\n",
            "training loss: 0.9953997731208801 [19200/60000]\n",
            "training loss: 0.6195523142814636 [25600/60000]\n",
            "training loss: 1.2068036794662476 [32000/60000]\n",
            "training loss: 0.8215709924697876 [38400/60000]\n",
            "training loss: 1.119246006011963 [44800/60000]\n",
            "training loss: 1.0552719831466675 [51200/60000]\n",
            "training loss: 0.9614382982254028 [57600/60000]\n",
            "Correct Predictions: 57.99999999999999%, Average Loss: 1.6617955416440966%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 425\n",
            "training loss: 1.0785815715789795 [0/60000]\n",
            "training loss: 1.0136957168579102 [6400/60000]\n",
            "training loss: 1.086004614830017 [12800/60000]\n",
            "training loss: 0.9953600168228149 [19200/60000]\n",
            "training loss: 0.6194082498550415 [25600/60000]\n",
            "training loss: 1.2063874006271362 [32000/60000]\n",
            "training loss: 0.8211055994033813 [38400/60000]\n",
            "training loss: 1.1191554069519043 [44800/60000]\n",
            "training loss: 1.0532405376434326 [51200/60000]\n",
            "training loss: 0.96125727891922 [57600/60000]\n",
            "Correct Predictions: 57.989999999999995%, Average Loss: 1.6621298295259477%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 426\n",
            "training loss: 1.0778863430023193 [0/60000]\n",
            "training loss: 1.0131536722183228 [6400/60000]\n",
            "training loss: 1.0859558582305908 [12800/60000]\n",
            "training loss: 0.9947402477264404 [19200/60000]\n",
            "training loss: 0.6186276078224182 [25600/60000]\n",
            "training loss: 1.2057660818099976 [32000/60000]\n",
            "training loss: 0.8206323981285095 [38400/60000]\n",
            "training loss: 1.1190767288208008 [44800/60000]\n",
            "training loss: 1.056003451347351 [51200/60000]\n",
            "training loss: 0.9610006809234619 [57600/60000]\n",
            "Correct Predictions: 57.989999999999995%, Average Loss: 1.6622592425346374%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 427\n",
            "training loss: 1.07767653465271 [0/60000]\n",
            "training loss: 1.0133439302444458 [6400/60000]\n",
            "training loss: 1.086076021194458 [12800/60000]\n",
            "training loss: 0.9945803880691528 [19200/60000]\n",
            "training loss: 0.6172959208488464 [25600/60000]\n",
            "training loss: 1.2046996355056763 [32000/60000]\n",
            "training loss: 0.8206473588943481 [38400/60000]\n",
            "training loss: 1.1190767288208008 [44800/60000]\n",
            "training loss: 1.0552533864974976 [51200/60000]\n",
            "training loss: 0.9605634808540344 [57600/60000]\n",
            "Correct Predictions: 57.989999999999995%, Average Loss: 1.6623184424638746%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 428\n",
            "training loss: 1.0775727033615112 [0/60000]\n",
            "training loss: 1.0125676393508911 [6400/60000]\n",
            "training loss: 1.0858665704727173 [12800/60000]\n",
            "training loss: 0.9945095181465149 [19200/60000]\n",
            "training loss: 0.6164774894714355 [25600/60000]\n",
            "training loss: 1.2046363353729248 [32000/60000]\n",
            "training loss: 0.8200426697731018 [38400/60000]\n",
            "training loss: 1.1190190315246582 [44800/60000]\n",
            "training loss: 1.0558640956878662 [51200/60000]\n",
            "training loss: 0.9604675769805908 [57600/60000]\n",
            "Correct Predictions: 57.99999999999999%, Average Loss: 1.6626071107387543%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 429\n",
            "training loss: 1.0768920183181763 [0/60000]\n",
            "training loss: 1.012241005897522 [6400/60000]\n",
            "training loss: 1.085990309715271 [12800/60000]\n",
            "training loss: 0.9942585825920105 [19200/60000]\n",
            "training loss: 0.6166971325874329 [25600/60000]\n",
            "training loss: 1.2031986713409424 [32000/60000]\n",
            "training loss: 0.819617509841919 [38400/60000]\n",
            "training loss: 1.1189297437667847 [44800/60000]\n",
            "training loss: 1.053992509841919 [51200/60000]\n",
            "training loss: 0.9604005217552185 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6627090579271315%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 430\n",
            "training loss: 1.0764445066452026 [0/60000]\n",
            "training loss: 1.0116604566574097 [6400/60000]\n",
            "training loss: 1.0859462022781372 [12800/60000]\n",
            "training loss: 0.9939525127410889 [19200/60000]\n",
            "training loss: 0.6161960959434509 [25600/60000]\n",
            "training loss: 1.2027969360351562 [32000/60000]\n",
            "training loss: 0.8192770481109619 [38400/60000]\n",
            "training loss: 1.1189055442810059 [44800/60000]\n",
            "training loss: 1.0553690195083618 [51200/60000]\n",
            "training loss: 0.9604032039642334 [57600/60000]\n",
            "Correct Predictions: 57.989999999999995%, Average Loss: 1.6629684084653855%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 431\n",
            "training loss: 1.0761566162109375 [0/60000]\n",
            "training loss: 1.0116713047027588 [6400/60000]\n",
            "training loss: 1.0858614444732666 [12800/60000]\n",
            "training loss: 0.9934042692184448 [19200/60000]\n",
            "training loss: 0.6158351898193359 [25600/60000]\n",
            "training loss: 1.2022877931594849 [32000/60000]\n",
            "training loss: 0.8190664649009705 [38400/60000]\n",
            "training loss: 1.1188298463821411 [44800/60000]\n",
            "training loss: 1.0550743341445923 [51200/60000]\n",
            "training loss: 0.9601253867149353 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.663099506497383%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 432\n",
            "training loss: 1.0760769844055176 [0/60000]\n",
            "training loss: 1.0109106302261353 [6400/60000]\n",
            "training loss: 1.0859432220458984 [12800/60000]\n",
            "training loss: 0.9932182431221008 [19200/60000]\n",
            "training loss: 0.6161602735519409 [25600/60000]\n",
            "training loss: 1.202146291732788 [32000/60000]\n",
            "training loss: 0.8186324834823608 [38400/60000]\n",
            "training loss: 1.1187711954116821 [44800/60000]\n",
            "training loss: 1.0539449453353882 [51200/60000]\n",
            "training loss: 0.9600993990898132 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.663247532248497%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 433\n",
            "training loss: 1.075812816619873 [0/60000]\n",
            "training loss: 1.0105338096618652 [6400/60000]\n",
            "training loss: 1.0857495069503784 [12800/60000]\n",
            "training loss: 0.9929779767990112 [19200/60000]\n",
            "training loss: 0.6156160235404968 [25600/60000]\n",
            "training loss: 1.2020678520202637 [32000/60000]\n",
            "training loss: 0.8182187080383301 [38400/60000]\n",
            "training loss: 1.1186524629592896 [44800/60000]\n",
            "training loss: 1.0520046949386597 [51200/60000]\n",
            "training loss: 0.9606334567070007 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6635099762678147%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 434\n",
            "training loss: 1.0750770568847656 [0/60000]\n",
            "training loss: 1.00998055934906 [6400/60000]\n",
            "training loss: 1.0857579708099365 [12800/60000]\n",
            "training loss: 0.9926459193229675 [19200/60000]\n",
            "training loss: 0.614773154258728 [25600/60000]\n",
            "training loss: 1.2014044523239136 [32000/60000]\n",
            "training loss: 0.8179289698600769 [38400/60000]\n",
            "training loss: 1.1186609268188477 [44800/60000]\n",
            "training loss: 1.053340196609497 [51200/60000]\n",
            "training loss: 0.9600133299827576 [57600/60000]\n",
            "Correct Predictions: 57.989999999999995%, Average Loss: 1.6636438816785812%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 435\n",
            "training loss: 1.0750620365142822 [0/60000]\n",
            "training loss: 1.0098958015441895 [6400/60000]\n",
            "training loss: 1.085500717163086 [12800/60000]\n",
            "training loss: 0.9924598932266235 [19200/60000]\n",
            "training loss: 0.6156186461448669 [25600/60000]\n",
            "training loss: 1.2012535333633423 [32000/60000]\n",
            "training loss: 0.8176203966140747 [38400/60000]\n",
            "training loss: 1.1186634302139282 [44800/60000]\n",
            "training loss: 1.0526742935180664 [51200/60000]\n",
            "training loss: 0.9600421190261841 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.663874506354332%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 436\n",
            "training loss: 1.0745939016342163 [0/60000]\n",
            "training loss: 1.0093598365783691 [6400/60000]\n",
            "training loss: 1.0855042934417725 [12800/60000]\n",
            "training loss: 0.9922837018966675 [19200/60000]\n",
            "training loss: 0.614772617816925 [25600/60000]\n",
            "training loss: 1.2009527683258057 [32000/60000]\n",
            "training loss: 0.8173561096191406 [38400/60000]\n",
            "training loss: 1.1184160709381104 [44800/60000]\n",
            "training loss: 1.0524694919586182 [51200/60000]\n",
            "training loss: 0.9594524502754211 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.664023016691208%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 437\n",
            "training loss: 1.074463963508606 [0/60000]\n",
            "training loss: 1.0090323686599731 [6400/60000]\n",
            "training loss: 1.0854073762893677 [12800/60000]\n",
            "training loss: 0.9919841289520264 [19200/60000]\n",
            "training loss: 0.6145080327987671 [25600/60000]\n",
            "training loss: 1.200280785560608 [32000/60000]\n",
            "training loss: 0.8168942928314209 [38400/60000]\n",
            "training loss: 1.1183841228485107 [44800/60000]\n",
            "training loss: 1.0518062114715576 [51200/60000]\n",
            "training loss: 0.9594160318374634 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.664291751384735%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 438\n",
            "training loss: 1.0737524032592773 [0/60000]\n",
            "training loss: 1.0088809728622437 [6400/60000]\n",
            "training loss: 1.0853468179702759 [12800/60000]\n",
            "training loss: 0.991605818271637 [19200/60000]\n",
            "training loss: 0.6145017743110657 [25600/60000]\n",
            "training loss: 1.1998927593231201 [32000/60000]\n",
            "training loss: 0.8165839910507202 [38400/60000]\n",
            "training loss: 1.1179742813110352 [44800/60000]\n",
            "training loss: 1.0511610507965088 [51200/60000]\n",
            "training loss: 0.9594916105270386 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.6644654762744904%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 439\n",
            "training loss: 1.073593258857727 [0/60000]\n",
            "training loss: 1.0086599588394165 [6400/60000]\n",
            "training loss: 1.0853393077850342 [12800/60000]\n",
            "training loss: 0.991405189037323 [19200/60000]\n",
            "training loss: 0.6141412258148193 [25600/60000]\n",
            "training loss: 1.1999930143356323 [32000/60000]\n",
            "training loss: 0.8165096640586853 [38400/60000]\n",
            "training loss: 1.117919683456421 [44800/60000]\n",
            "training loss: 1.0615545511245728 [51200/60000]\n",
            "training loss: 0.9597743153572083 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6644525092840194%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 440\n",
            "training loss: 1.0740668773651123 [0/60000]\n",
            "training loss: 1.0081802606582642 [6400/60000]\n",
            "training loss: 1.085312843322754 [12800/60000]\n",
            "training loss: 0.990977942943573 [19200/60000]\n",
            "training loss: 0.6140956878662109 [25600/60000]\n",
            "training loss: 1.1981528997421265 [32000/60000]\n",
            "training loss: 0.8162633776664734 [38400/60000]\n",
            "training loss: 1.1178675889968872 [44800/60000]\n",
            "training loss: 1.0691254138946533 [51200/60000]\n",
            "training loss: 0.9599432349205017 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6646744203567505%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 441\n",
            "training loss: 1.073479413986206 [0/60000]\n",
            "training loss: 1.0074923038482666 [6400/60000]\n",
            "training loss: 1.0852750539779663 [12800/60000]\n",
            "training loss: 0.990264356136322 [19200/60000]\n",
            "training loss: 0.6141514182090759 [25600/60000]\n",
            "training loss: 1.1981745958328247 [32000/60000]\n",
            "training loss: 0.8161580562591553 [38400/60000]\n",
            "training loss: 1.1178569793701172 [44800/60000]\n",
            "training loss: 1.0659199953079224 [51200/60000]\n",
            "training loss: 0.9596951603889465 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.664796066880226%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 442\n",
            "training loss: 1.0733258724212646 [0/60000]\n",
            "training loss: 1.006904125213623 [6400/60000]\n",
            "training loss: 1.0850937366485596 [12800/60000]\n",
            "training loss: 0.9903132319450378 [19200/60000]\n",
            "training loss: 0.6132951974868774 [25600/60000]\n",
            "training loss: 1.197678565979004 [32000/60000]\n",
            "training loss: 0.8157903552055359 [38400/60000]\n",
            "training loss: 1.1177778244018555 [44800/60000]\n",
            "training loss: 1.0634092092514038 [51200/60000]\n",
            "training loss: 0.959627091884613 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.6651363551616667%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 443\n",
            "training loss: 1.0725067853927612 [0/60000]\n",
            "training loss: 1.0066890716552734 [6400/60000]\n",
            "training loss: 1.0850400924682617 [12800/60000]\n",
            "training loss: 0.989938497543335 [19200/60000]\n",
            "training loss: 0.6135451197624207 [25600/60000]\n",
            "training loss: 1.1973286867141724 [32000/60000]\n",
            "training loss: 0.8154432773590088 [38400/60000]\n",
            "training loss: 1.1177232265472412 [44800/60000]\n",
            "training loss: 1.0645486116409302 [51200/60000]\n",
            "training loss: 0.9601294994354248 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.665294725894928%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 444\n",
            "training loss: 1.0727958679199219 [0/60000]\n",
            "training loss: 1.0059386491775513 [6400/60000]\n",
            "training loss: 1.0849249362945557 [12800/60000]\n",
            "training loss: 0.9900739789009094 [19200/60000]\n",
            "training loss: 0.6128689050674438 [25600/60000]\n",
            "training loss: 1.1962437629699707 [32000/60000]\n",
            "training loss: 0.815227746963501 [38400/60000]\n",
            "training loss: 1.1176416873931885 [44800/60000]\n",
            "training loss: 1.0639580488204956 [51200/60000]\n",
            "training loss: 0.9602492451667786 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6656937205791473%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 445\n",
            "training loss: 1.0721359252929688 [0/60000]\n",
            "training loss: 1.0052485466003418 [6400/60000]\n",
            "training loss: 1.0849475860595703 [12800/60000]\n",
            "training loss: 0.9896796941757202 [19200/60000]\n",
            "training loss: 0.6129398345947266 [25600/60000]\n",
            "training loss: 1.1963659524917603 [32000/60000]\n",
            "training loss: 0.8150325417518616 [38400/60000]\n",
            "training loss: 1.1176468133926392 [44800/60000]\n",
            "training loss: 1.0624076128005981 [51200/60000]\n",
            "training loss: 0.9597029089927673 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.665924924015999%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 446\n",
            "training loss: 1.0716065168380737 [0/60000]\n",
            "training loss: 1.0052744150161743 [6400/60000]\n",
            "training loss: 1.0847467184066772 [12800/60000]\n",
            "training loss: 0.9895511269569397 [19200/60000]\n",
            "training loss: 0.6124081015586853 [25600/60000]\n",
            "training loss: 1.1958054304122925 [32000/60000]\n",
            "training loss: 0.8148541450500488 [38400/60000]\n",
            "training loss: 1.1176211833953857 [44800/60000]\n",
            "training loss: 1.0598796606063843 [51200/60000]\n",
            "training loss: 0.959771454334259 [57600/60000]\n",
            "Correct Predictions: 58.06%, Average Loss: 1.6661646962165833%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 447\n",
            "training loss: 1.0712003707885742 [0/60000]\n",
            "training loss: 1.0056006908416748 [6400/60000]\n",
            "training loss: 1.0846667289733887 [12800/60000]\n",
            "training loss: 0.9892347455024719 [19200/60000]\n",
            "training loss: 0.6129636764526367 [25600/60000]\n",
            "training loss: 1.1950184106826782 [32000/60000]\n",
            "training loss: 0.8146347999572754 [38400/60000]\n",
            "training loss: 1.1175215244293213 [44800/60000]\n",
            "training loss: 1.0577735900878906 [51200/60000]\n",
            "training loss: 0.9590859413146973 [57600/60000]\n",
            "Correct Predictions: 58.050000000000004%, Average Loss: 1.666311944127083%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 448\n",
            "training loss: 1.071387529373169 [0/60000]\n",
            "training loss: 1.004996657371521 [6400/60000]\n",
            "training loss: 1.0845859050750732 [12800/60000]\n",
            "training loss: 0.9891650080680847 [19200/60000]\n",
            "training loss: 0.6132959723472595 [25600/60000]\n",
            "training loss: 1.194744348526001 [32000/60000]\n",
            "training loss: 0.8144540786743164 [38400/60000]\n",
            "training loss: 1.1174931526184082 [44800/60000]\n",
            "training loss: 1.056923508644104 [51200/60000]\n",
            "training loss: 0.959289014339447 [57600/60000]\n",
            "Correct Predictions: 58.050000000000004%, Average Loss: 1.6666852742433549%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 449\n",
            "training loss: 1.0705513954162598 [0/60000]\n",
            "training loss: 1.0042219161987305 [6400/60000]\n",
            "training loss: 1.0846164226531982 [12800/60000]\n",
            "training loss: 0.9888856410980225 [19200/60000]\n",
            "training loss: 0.6110496520996094 [25600/60000]\n",
            "training loss: 1.1943310499191284 [32000/60000]\n",
            "training loss: 0.8141293525695801 [38400/60000]\n",
            "training loss: 1.1174895763397217 [44800/60000]\n",
            "training loss: 1.0561676025390625 [51200/60000]\n",
            "training loss: 0.959200382232666 [57600/60000]\n",
            "Correct Predictions: 58.06%, Average Loss: 1.6667617386579514%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 450\n",
            "training loss: 1.070595383644104 [0/60000]\n",
            "training loss: 1.0044987201690674 [6400/60000]\n",
            "training loss: 1.0845268964767456 [12800/60000]\n",
            "training loss: 0.9885932207107544 [19200/60000]\n",
            "training loss: 0.6122042536735535 [25600/60000]\n",
            "training loss: 1.1935800313949585 [32000/60000]\n",
            "training loss: 0.8139290809631348 [38400/60000]\n",
            "training loss: 1.117410659790039 [44800/60000]\n",
            "training loss: 1.0545122623443604 [51200/60000]\n",
            "training loss: 0.9588372111320496 [57600/60000]\n",
            "Correct Predictions: 58.02%, Average Loss: 1.6700107580423353%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 451\n",
            "training loss: 1.067635178565979 [0/60000]\n",
            "training loss: 1.0038604736328125 [6400/60000]\n",
            "training loss: 1.0843075513839722 [12800/60000]\n",
            "training loss: 0.9885353446006775 [19200/60000]\n",
            "training loss: 0.6114177107810974 [25600/60000]\n",
            "training loss: 1.1931548118591309 [32000/60000]\n",
            "training loss: 0.8138908743858337 [38400/60000]\n",
            "training loss: 1.1174052953720093 [44800/60000]\n",
            "training loss: 1.0532617568969727 [51200/60000]\n",
            "training loss: 0.9587869644165039 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.670311611890793%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 452\n",
            "training loss: 1.067463755607605 [0/60000]\n",
            "training loss: 1.0035849809646606 [6400/60000]\n",
            "training loss: 1.0843538045883179 [12800/60000]\n",
            "training loss: 0.9880353808403015 [19200/60000]\n",
            "training loss: 0.6096703410148621 [25600/60000]\n",
            "training loss: 1.192480444908142 [32000/60000]\n",
            "training loss: 0.8135329484939575 [38400/60000]\n",
            "training loss: 1.1172728538513184 [44800/60000]\n",
            "training loss: 1.0520565509796143 [51200/60000]\n",
            "training loss: 0.9582147598266602 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6705936884880066%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 453\n",
            "training loss: 1.0669515132904053 [0/60000]\n",
            "training loss: 1.0030450820922852 [6400/60000]\n",
            "training loss: 1.0844334363937378 [12800/60000]\n",
            "training loss: 0.9882397055625916 [19200/60000]\n",
            "training loss: 0.609279215335846 [25600/60000]\n",
            "training loss: 1.192425012588501 [32000/60000]\n",
            "training loss: 0.8133894801139832 [38400/60000]\n",
            "training loss: 1.1172997951507568 [44800/60000]\n",
            "training loss: 1.0513273477554321 [51200/60000]\n",
            "training loss: 0.9586399793624878 [57600/60000]\n",
            "Correct Predictions: 58.06%, Average Loss: 1.6676690846681594%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 454\n",
            "training loss: 1.069650650024414 [0/60000]\n",
            "training loss: 1.0026804208755493 [6400/60000]\n",
            "training loss: 1.0842005014419556 [12800/60000]\n",
            "training loss: 0.9881647229194641 [19200/60000]\n",
            "training loss: 0.6084699630737305 [25600/60000]\n",
            "training loss: 1.1914331912994385 [32000/60000]\n",
            "training loss: 0.8132058382034302 [38400/60000]\n",
            "training loss: 1.1172512769699097 [44800/60000]\n",
            "training loss: 1.0536150932312012 [51200/60000]\n",
            "training loss: 0.9579246640205383 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6708843928575516%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 455\n",
            "training loss: 1.0663201808929443 [0/60000]\n",
            "training loss: 1.002701997756958 [6400/60000]\n",
            "training loss: 1.0841777324676514 [12800/60000]\n",
            "training loss: 0.9878301620483398 [19200/60000]\n",
            "training loss: 0.6088545322418213 [25600/60000]\n",
            "training loss: 1.1911656856536865 [32000/60000]\n",
            "training loss: 0.812870442867279 [38400/60000]\n",
            "training loss: 1.1172548532485962 [44800/60000]\n",
            "training loss: 1.0493319034576416 [51200/60000]\n",
            "training loss: 0.9581370949745178 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6711244434118269%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 456\n",
            "training loss: 1.0661929845809937 [0/60000]\n",
            "training loss: 1.0021328926086426 [6400/60000]\n",
            "training loss: 1.0841413736343384 [12800/60000]\n",
            "training loss: 0.9877434372901917 [19200/60000]\n",
            "training loss: 0.6042051315307617 [25600/60000]\n",
            "training loss: 1.1904302835464478 [32000/60000]\n",
            "training loss: 0.8129015564918518 [38400/60000]\n",
            "training loss: 1.117215633392334 [44800/60000]\n",
            "training loss: 1.0464677810668945 [51200/60000]\n",
            "training loss: 0.9587464332580566 [57600/60000]\n",
            "Correct Predictions: 58.06%, Average Loss: 1.668024924993515%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 457\n",
            "training loss: 1.069385051727295 [0/60000]\n",
            "training loss: 1.0018671751022339 [6400/60000]\n",
            "training loss: 1.0840435028076172 [12800/60000]\n",
            "training loss: 0.9875608086585999 [19200/60000]\n",
            "training loss: 0.6079339981079102 [25600/60000]\n",
            "training loss: 1.1895947456359863 [32000/60000]\n",
            "training loss: 0.8126534223556519 [38400/60000]\n",
            "training loss: 1.1172198057174683 [44800/60000]\n",
            "training loss: 1.0528693199157715 [51200/60000]\n",
            "training loss: 0.9579899907112122 [57600/60000]\n",
            "Correct Predictions: 58.03%, Average Loss: 1.668254777789116%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 458\n",
            "training loss: 1.0690271854400635 [0/60000]\n",
            "training loss: 1.001520037651062 [6400/60000]\n",
            "training loss: 1.0839731693267822 [12800/60000]\n",
            "training loss: 0.9875605702400208 [19200/60000]\n",
            "training loss: 0.6033778786659241 [25600/60000]\n",
            "training loss: 1.1899138689041138 [32000/60000]\n",
            "training loss: 0.8124672770500183 [38400/60000]\n",
            "training loss: 1.1171703338623047 [44800/60000]\n",
            "training loss: 1.04917573928833 [51200/60000]\n",
            "training loss: 0.9575809836387634 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.67161101937294%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 459\n",
            "training loss: 1.0656694173812866 [0/60000]\n",
            "training loss: 1.0005786418914795 [6400/60000]\n",
            "training loss: 1.0839747190475464 [12800/60000]\n",
            "training loss: 0.9870154857635498 [19200/60000]\n",
            "training loss: 0.6025301814079285 [25600/60000]\n",
            "training loss: 1.1890283823013306 [32000/60000]\n",
            "training loss: 0.8122857213020325 [38400/60000]\n",
            "training loss: 1.1171826124191284 [44800/60000]\n",
            "training loss: 1.0500283241271973 [51200/60000]\n",
            "training loss: 0.9572255611419678 [57600/60000]\n",
            "Correct Predictions: 58.01%, Average Loss: 1.6719455456733705%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 460\n",
            "training loss: 1.065289855003357 [0/60000]\n",
            "training loss: 1.000503420829773 [6400/60000]\n",
            "training loss: 1.0838149785995483 [12800/60000]\n",
            "training loss: 0.9869191646575928 [19200/60000]\n",
            "training loss: 0.6022875308990479 [25600/60000]\n",
            "training loss: 1.1886104345321655 [32000/60000]\n",
            "training loss: 0.8121249079704285 [38400/60000]\n",
            "training loss: 1.1171703338623047 [44800/60000]\n",
            "training loss: 1.050273060798645 [51200/60000]\n",
            "training loss: 0.9577811360359192 [57600/60000]\n",
            "Correct Predictions: 58.040000000000006%, Average Loss: 1.668934376835823%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 461\n",
            "training loss: 1.0683425664901733 [0/60000]\n",
            "training loss: 1.0004217624664307 [6400/60000]\n",
            "training loss: 1.0838968753814697 [12800/60000]\n",
            "training loss: 0.9867770671844482 [19200/60000]\n",
            "training loss: 0.6018038988113403 [25600/60000]\n",
            "training loss: 1.1877202987670898 [32000/60000]\n",
            "training loss: 0.8119667172431946 [38400/60000]\n",
            "training loss: 1.1172125339508057 [44800/60000]\n",
            "training loss: 1.049810767173767 [51200/60000]\n",
            "training loss: 0.9570309519767761 [57600/60000]\n",
            "Correct Predictions: 57.99999999999999%, Average Loss: 1.6724765563011168%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 462\n",
            "training loss: 1.0647478103637695 [0/60000]\n",
            "training loss: 0.9988025426864624 [6400/60000]\n",
            "training loss: 1.0838731527328491 [12800/60000]\n",
            "training loss: 0.9865371584892273 [19200/60000]\n",
            "training loss: 0.6013797521591187 [25600/60000]\n",
            "training loss: 1.1875889301300049 [32000/60000]\n",
            "training loss: 0.8119505643844604 [38400/60000]\n",
            "training loss: 1.1171542406082153 [44800/60000]\n",
            "training loss: 1.0483506917953491 [51200/60000]\n",
            "training loss: 0.9568783044815063 [57600/60000]\n",
            "Correct Predictions: 57.989999999999995%, Average Loss: 1.6726309847831726%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 463\n",
            "training loss: 1.0650644302368164 [0/60000]\n",
            "training loss: 0.9987883567810059 [6400/60000]\n",
            "training loss: 1.0840544700622559 [12800/60000]\n",
            "training loss: 0.9862871170043945 [19200/60000]\n",
            "training loss: 0.6013115048408508 [25600/60000]\n",
            "training loss: 1.1870959997177124 [32000/60000]\n",
            "training loss: 0.8116661310195923 [38400/60000]\n",
            "training loss: 1.117126226425171 [44800/60000]\n",
            "training loss: 1.0476117134094238 [51200/60000]\n",
            "training loss: 0.956807553768158 [57600/60000]\n",
            "Correct Predictions: 57.989999999999995%, Average Loss: 1.6728104776144028%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 464\n",
            "training loss: 1.0649610757827759 [0/60000]\n",
            "training loss: 0.9981477856636047 [6400/60000]\n",
            "training loss: 1.0839433670043945 [12800/60000]\n",
            "training loss: 0.9863232374191284 [19200/60000]\n",
            "training loss: 0.6014921069145203 [25600/60000]\n",
            "training loss: 1.1873869895935059 [32000/60000]\n",
            "training loss: 0.8113164901733398 [38400/60000]\n",
            "training loss: 1.1171451807022095 [44800/60000]\n",
            "training loss: 1.0469459295272827 [51200/60000]\n",
            "training loss: 0.9568325281143188 [57600/60000]\n",
            "Correct Predictions: 57.99999999999999%, Average Loss: 1.6732799285650253%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 465\n",
            "training loss: 1.0645033121109009 [0/60000]\n",
            "training loss: 0.9982982873916626 [6400/60000]\n",
            "training loss: 1.0839064121246338 [12800/60000]\n",
            "training loss: 0.9862293601036072 [19200/60000]\n",
            "training loss: 0.6009364128112793 [25600/60000]\n",
            "training loss: 1.1867737770080566 [32000/60000]\n",
            "training loss: 0.8111248016357422 [38400/60000]\n",
            "training loss: 1.1171164512634277 [44800/60000]\n",
            "training loss: 1.0460078716278076 [51200/60000]\n",
            "training loss: 0.9561565518379211 [57600/60000]\n",
            "Correct Predictions: 57.98%, Average Loss: 1.6733276957273484%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 466\n",
            "training loss: 1.0641443729400635 [0/60000]\n",
            "training loss: 0.9975717663764954 [6400/60000]\n",
            "training loss: 1.083877444267273 [12800/60000]\n",
            "training loss: 0.9861143231391907 [19200/60000]\n",
            "training loss: 0.6008894443511963 [25600/60000]\n",
            "training loss: 1.1869308948516846 [32000/60000]\n",
            "training loss: 0.8110442161560059 [38400/60000]\n",
            "training loss: 1.1171151399612427 [44800/60000]\n",
            "training loss: 1.044539451599121 [51200/60000]\n",
            "training loss: 0.9556379318237305 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6733586436510086%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 467\n",
            "training loss: 1.0642638206481934 [0/60000]\n",
            "training loss: 0.9974754452705383 [6400/60000]\n",
            "training loss: 1.0840908288955688 [12800/60000]\n",
            "training loss: 0.9856505990028381 [19200/60000]\n",
            "training loss: 0.6007372736930847 [25600/60000]\n",
            "training loss: 1.1858007907867432 [32000/60000]\n",
            "training loss: 0.8109089136123657 [38400/60000]\n",
            "training loss: 1.1171059608459473 [44800/60000]\n",
            "training loss: 1.043968915939331 [51200/60000]\n",
            "training loss: 0.9558912515640259 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6736048460006714%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 468\n",
            "training loss: 1.0636299848556519 [0/60000]\n",
            "training loss: 0.9970296621322632 [6400/60000]\n",
            "training loss: 1.083796739578247 [12800/60000]\n",
            "training loss: 0.9856036901473999 [19200/60000]\n",
            "training loss: 0.6002914309501648 [25600/60000]\n",
            "training loss: 1.1859058141708374 [32000/60000]\n",
            "training loss: 0.8106215000152588 [38400/60000]\n",
            "training loss: 1.1171002388000488 [44800/60000]\n",
            "training loss: 1.0431253910064697 [51200/60000]\n",
            "training loss: 0.955540120601654 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6737394356727602%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 469\n",
            "training loss: 1.063666820526123 [0/60000]\n",
            "training loss: 0.996766209602356 [6400/60000]\n",
            "training loss: 1.0837407112121582 [12800/60000]\n",
            "training loss: 0.9857326745986938 [19200/60000]\n",
            "training loss: 0.6005314588546753 [25600/60000]\n",
            "training loss: 1.1848444938659668 [32000/60000]\n",
            "training loss: 0.8104748129844666 [38400/60000]\n",
            "training loss: 1.1170294284820557 [44800/60000]\n",
            "training loss: 1.04221773147583 [51200/60000]\n",
            "training loss: 0.9556493759155273 [57600/60000]\n",
            "Correct Predictions: 57.95%, Average Loss: 1.6741527998447419%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 470\n",
            "training loss: 1.0634114742279053 [0/60000]\n",
            "training loss: 0.9965839385986328 [6400/60000]\n",
            "training loss: 1.083634614944458 [12800/60000]\n",
            "training loss: 0.9853336215019226 [19200/60000]\n",
            "training loss: 0.5997572541236877 [25600/60000]\n",
            "training loss: 1.1850149631500244 [32000/60000]\n",
            "training loss: 0.8103681802749634 [38400/60000]\n",
            "training loss: 1.1170601844787598 [44800/60000]\n",
            "training loss: 1.041900873184204 [51200/60000]\n",
            "training loss: 0.9548726081848145 [57600/60000]\n",
            "Correct Predictions: 57.940000000000005%, Average Loss: 1.6745426487922668%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 471\n",
            "training loss: 1.0633515119552612 [0/60000]\n",
            "training loss: 0.9963299036026001 [6400/60000]\n",
            "training loss: 1.0837677717208862 [12800/60000]\n",
            "training loss: 0.9849769473075867 [19200/60000]\n",
            "training loss: 0.5995742082595825 [25600/60000]\n",
            "training loss: 1.1849466562271118 [32000/60000]\n",
            "training loss: 0.8100852370262146 [38400/60000]\n",
            "training loss: 1.1170345544815063 [44800/60000]\n",
            "training loss: 1.0406954288482666 [51200/60000]\n",
            "training loss: 0.9550185203552246 [57600/60000]\n",
            "Correct Predictions: 57.940000000000005%, Average Loss: 1.6745140808820724%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 472\n",
            "training loss: 1.0631253719329834 [0/60000]\n",
            "training loss: 0.9956409335136414 [6400/60000]\n",
            "training loss: 1.0837324857711792 [12800/60000]\n",
            "training loss: 0.984896183013916 [19200/60000]\n",
            "training loss: 0.5992961525917053 [25600/60000]\n",
            "training loss: 1.184563159942627 [32000/60000]\n",
            "training loss: 0.8098959922790527 [38400/60000]\n",
            "training loss: 1.117043375968933 [44800/60000]\n",
            "training loss: 1.0399625301361084 [51200/60000]\n",
            "training loss: 0.9547210335731506 [57600/60000]\n",
            "Correct Predictions: 57.93000000000001%, Average Loss: 1.674681755900383%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 473\n",
            "training loss: 1.0632691383361816 [0/60000]\n",
            "training loss: 0.9955428242683411 [6400/60000]\n",
            "training loss: 1.0838528871536255 [12800/60000]\n",
            "training loss: 0.9849883317947388 [19200/60000]\n",
            "training loss: 0.5990554690361023 [25600/60000]\n",
            "training loss: 1.1847357749938965 [32000/60000]\n",
            "training loss: 0.8098142147064209 [38400/60000]\n",
            "training loss: 1.1170397996902466 [44800/60000]\n",
            "training loss: 1.0387810468673706 [51200/60000]\n",
            "training loss: 0.954704761505127 [57600/60000]\n",
            "Correct Predictions: 57.940000000000005%, Average Loss: 1.6750561815500258%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 474\n",
            "training loss: 1.0628923177719116 [0/60000]\n",
            "training loss: 0.9954586029052734 [6400/60000]\n",
            "training loss: 1.0841542482376099 [12800/60000]\n",
            "training loss: 0.985202968120575 [19200/60000]\n",
            "training loss: 0.5982799530029297 [25600/60000]\n",
            "training loss: 1.1850508451461792 [32000/60000]\n",
            "training loss: 0.8094667196273804 [38400/60000]\n",
            "training loss: 1.1169971227645874 [44800/60000]\n",
            "training loss: 1.03751540184021 [51200/60000]\n",
            "training loss: 0.9540161490440369 [57600/60000]\n",
            "Correct Predictions: 57.95%, Average Loss: 1.675309624671936%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 475\n",
            "training loss: 1.062414526939392 [0/60000]\n",
            "training loss: 0.995177686214447 [6400/60000]\n",
            "training loss: 1.0838221311569214 [12800/60000]\n",
            "training loss: 0.9848703145980835 [19200/60000]\n",
            "training loss: 0.5989863276481628 [25600/60000]\n",
            "training loss: 1.18467378616333 [32000/60000]\n",
            "training loss: 0.8094344735145569 [38400/60000]\n",
            "training loss: 1.1169954538345337 [44800/60000]\n",
            "training loss: 1.037182331085205 [51200/60000]\n",
            "training loss: 0.9547926187515259 [57600/60000]\n",
            "Correct Predictions: 57.940000000000005%, Average Loss: 1.6756315743923187%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 476\n",
            "training loss: 1.062552571296692 [0/60000]\n",
            "training loss: 0.9951173067092896 [6400/60000]\n",
            "training loss: 1.0839587450027466 [12800/60000]\n",
            "training loss: 0.9853569865226746 [19200/60000]\n",
            "training loss: 0.5988113284111023 [25600/60000]\n",
            "training loss: 1.1836867332458496 [32000/60000]\n",
            "training loss: 0.8091742396354675 [38400/60000]\n",
            "training loss: 1.1169817447662354 [44800/60000]\n",
            "training loss: 1.0367789268493652 [51200/60000]\n",
            "training loss: 0.9544263482093811 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6758172065019605%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 477\n",
            "training loss: 1.0625039339065552 [0/60000]\n",
            "training loss: 0.9947518110275269 [6400/60000]\n",
            "training loss: 1.083906888961792 [12800/60000]\n",
            "training loss: 0.9849774241447449 [19200/60000]\n",
            "training loss: 0.5974829196929932 [25600/60000]\n",
            "training loss: 1.183241367340088 [32000/60000]\n",
            "training loss: 0.8089389204978943 [38400/60000]\n",
            "training loss: 1.1169695854187012 [44800/60000]\n",
            "training loss: 1.036500096321106 [51200/60000]\n",
            "training loss: 0.9543395638465881 [57600/60000]\n",
            "Correct Predictions: 57.95%, Average Loss: 1.6761207902431488%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 478\n",
            "training loss: 1.062334418296814 [0/60000]\n",
            "training loss: 0.9943378567695618 [6400/60000]\n",
            "training loss: 1.0836304426193237 [12800/60000]\n",
            "training loss: 0.9845109581947327 [19200/60000]\n",
            "training loss: 0.5970052480697632 [25600/60000]\n",
            "training loss: 1.1840057373046875 [32000/60000]\n",
            "training loss: 0.8087242841720581 [38400/60000]\n",
            "training loss: 1.1169861555099487 [44800/60000]\n",
            "training loss: 1.0361700057983398 [51200/60000]\n",
            "training loss: 0.9538390040397644 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6763051033020018%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 479\n",
            "training loss: 1.0622462034225464 [0/60000]\n",
            "training loss: 0.9940146803855896 [6400/60000]\n",
            "training loss: 1.083809494972229 [12800/60000]\n",
            "training loss: 0.9847337603569031 [19200/60000]\n",
            "training loss: 0.5970544219017029 [25600/60000]\n",
            "training loss: 1.1841329336166382 [32000/60000]\n",
            "training loss: 0.8083574175834656 [38400/60000]\n",
            "training loss: 1.1169513463974 [44800/60000]\n",
            "training loss: 1.034857988357544 [51200/60000]\n",
            "training loss: 0.9537593126296997 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6767953968048095%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 480\n",
            "training loss: 1.0618163347244263 [0/60000]\n",
            "training loss: 0.9938101768493652 [6400/60000]\n",
            "training loss: 1.0836710929870605 [12800/60000]\n",
            "training loss: 0.9847149848937988 [19200/60000]\n",
            "training loss: 0.5972605347633362 [25600/60000]\n",
            "training loss: 1.1841247081756592 [32000/60000]\n",
            "training loss: 0.8084537982940674 [38400/60000]\n",
            "training loss: 1.1169341802597046 [44800/60000]\n",
            "training loss: 1.0344682931900024 [51200/60000]\n",
            "training loss: 0.9534845948219299 [57600/60000]\n",
            "Correct Predictions: 57.95%, Average Loss: 1.6768273311853408%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 481\n",
            "training loss: 1.0618505477905273 [0/60000]\n",
            "training loss: 0.9936680793762207 [6400/60000]\n",
            "training loss: 1.084225058555603 [12800/60000]\n",
            "training loss: 0.9842063784599304 [19200/60000]\n",
            "training loss: 0.5958942770957947 [25600/60000]\n",
            "training loss: 1.1845061779022217 [32000/60000]\n",
            "training loss: 0.8084150552749634 [38400/60000]\n",
            "training loss: 1.11693274974823 [44800/60000]\n",
            "training loss: 1.0347328186035156 [51200/60000]\n",
            "training loss: 0.953498899936676 [57600/60000]\n",
            "Correct Predictions: 57.98%, Average Loss: 1.6772786343097688%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 482\n",
            "training loss: 1.0616602897644043 [0/60000]\n",
            "training loss: 0.9933788180351257 [6400/60000]\n",
            "training loss: 1.0840266942977905 [12800/60000]\n",
            "training loss: 0.9841487407684326 [19200/60000]\n",
            "training loss: 0.5963321328163147 [25600/60000]\n",
            "training loss: 1.1835732460021973 [32000/60000]\n",
            "training loss: 0.8079547882080078 [38400/60000]\n",
            "training loss: 1.1169514656066895 [44800/60000]\n",
            "training loss: 1.0330095291137695 [51200/60000]\n",
            "training loss: 0.9541143178939819 [57600/60000]\n",
            "Correct Predictions: 57.97%, Average Loss: 1.6773036307096483%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 483\n",
            "training loss: 1.0615835189819336 [0/60000]\n",
            "training loss: 0.9928686618804932 [6400/60000]\n",
            "training loss: 1.0840100049972534 [12800/60000]\n",
            "training loss: 0.98370760679245 [19200/60000]\n",
            "training loss: 0.5955436825752258 [25600/60000]\n",
            "training loss: 1.18271803855896 [32000/60000]\n",
            "training loss: 0.8076914548873901 [38400/60000]\n",
            "training loss: 1.116890788078308 [44800/60000]\n",
            "training loss: 1.032795786857605 [51200/60000]\n",
            "training loss: 0.9531474113464355 [57600/60000]\n",
            "Correct Predictions: 57.98%, Average Loss: 1.6773580157756804%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 484\n",
            "training loss: 1.061830997467041 [0/60000]\n",
            "training loss: 0.9928292632102966 [6400/60000]\n",
            "training loss: 1.0840423107147217 [12800/60000]\n",
            "training loss: 0.9835088849067688 [19200/60000]\n",
            "training loss: 0.595517098903656 [25600/60000]\n",
            "training loss: 1.1816537380218506 [32000/60000]\n",
            "training loss: 0.8077950477600098 [38400/60000]\n",
            "training loss: 1.116894245147705 [44800/60000]\n",
            "training loss: 1.031772255897522 [51200/60000]\n",
            "training loss: 0.9530238509178162 [57600/60000]\n",
            "Correct Predictions: 57.98%, Average Loss: 1.6774446231126787%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 485\n",
            "training loss: 1.0616014003753662 [0/60000]\n",
            "training loss: 0.99281245470047 [6400/60000]\n",
            "training loss: 1.0839608907699585 [12800/60000]\n",
            "training loss: 0.9836382269859314 [19200/60000]\n",
            "training loss: 0.5953847169876099 [25600/60000]\n",
            "training loss: 1.1803396940231323 [32000/60000]\n",
            "training loss: 0.8074876666069031 [38400/60000]\n",
            "training loss: 1.1169356107711792 [44800/60000]\n",
            "training loss: 1.0314992666244507 [51200/60000]\n",
            "training loss: 0.953416109085083 [57600/60000]\n",
            "Correct Predictions: 57.97%, Average Loss: 1.6776411503553392%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 486\n",
            "training loss: 1.0617151260375977 [0/60000]\n",
            "training loss: 0.9921835660934448 [6400/60000]\n",
            "training loss: 1.0835950374603271 [12800/60000]\n",
            "training loss: 0.98342365026474 [19200/60000]\n",
            "training loss: 0.5948659181594849 [25600/60000]\n",
            "training loss: 1.1813973188400269 [32000/60000]\n",
            "training loss: 0.8071572184562683 [38400/60000]\n",
            "training loss: 1.1168581247329712 [44800/60000]\n",
            "training loss: 1.0312919616699219 [51200/60000]\n",
            "training loss: 0.953933835029602 [57600/60000]\n",
            "Correct Predictions: 57.97%, Average Loss: 1.6781704515218734%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 487\n",
            "training loss: 1.0613571405410767 [0/60000]\n",
            "training loss: 0.9920052289962769 [6400/60000]\n",
            "training loss: 1.0837897062301636 [12800/60000]\n",
            "training loss: 0.9832050204277039 [19200/60000]\n",
            "training loss: 0.5945402979850769 [25600/60000]\n",
            "training loss: 1.1801321506500244 [32000/60000]\n",
            "training loss: 0.8075929284095764 [38400/60000]\n",
            "training loss: 1.116851568222046 [44800/60000]\n",
            "training loss: 1.0299047231674194 [51200/60000]\n",
            "training loss: 0.9532298445701599 [57600/60000]\n",
            "Correct Predictions: 57.98%, Average Loss: 1.6786186134815215%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 488\n",
            "training loss: 1.0610270500183105 [0/60000]\n",
            "training loss: 0.9916238188743591 [6400/60000]\n",
            "training loss: 1.0840272903442383 [12800/60000]\n",
            "training loss: 0.9831173419952393 [19200/60000]\n",
            "training loss: 0.5946231484413147 [25600/60000]\n",
            "training loss: 1.180757761001587 [32000/60000]\n",
            "training loss: 0.80690997838974 [38400/60000]\n",
            "training loss: 1.1168731451034546 [44800/60000]\n",
            "training loss: 1.0297203063964844 [51200/60000]\n",
            "training loss: 0.952663004398346 [57600/60000]\n",
            "Correct Predictions: 57.97%, Average Loss: 1.678387949466705%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 489\n",
            "training loss: 1.0613043308258057 [0/60000]\n",
            "training loss: 0.9912192821502686 [6400/60000]\n",
            "training loss: 1.0836635828018188 [12800/60000]\n",
            "training loss: 0.9826598763465881 [19200/60000]\n",
            "training loss: 0.5944556593894958 [25600/60000]\n",
            "training loss: 1.1797716617584229 [32000/60000]\n",
            "training loss: 0.8073679208755493 [38400/60000]\n",
            "training loss: 1.1168807744979858 [44800/60000]\n",
            "training loss: 1.0295246839523315 [51200/60000]\n",
            "training loss: 0.952620804309845 [57600/60000]\n",
            "Correct Predictions: 57.97%, Average Loss: 1.678906232714653%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 490\n",
            "training loss: 1.0610744953155518 [0/60000]\n",
            "training loss: 0.9911423921585083 [6400/60000]\n",
            "training loss: 1.0836844444274902 [12800/60000]\n",
            "training loss: 0.9821776151657104 [19200/60000]\n",
            "training loss: 0.5934898257255554 [25600/60000]\n",
            "training loss: 1.1874725818634033 [32000/60000]\n",
            "training loss: 0.8069661259651184 [38400/60000]\n",
            "training loss: 1.1168292760849 [44800/60000]\n",
            "training loss: 1.0284924507141113 [51200/60000]\n",
            "training loss: 0.9522941708564758 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6791578888893128%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 491\n",
            "training loss: 1.0609896183013916 [0/60000]\n",
            "training loss: 0.9909363389015198 [6400/60000]\n",
            "training loss: 1.0834848880767822 [12800/60000]\n",
            "training loss: 0.9824327230453491 [19200/60000]\n",
            "training loss: 0.5940679311752319 [25600/60000]\n",
            "training loss: 1.1810579299926758 [32000/60000]\n",
            "training loss: 0.8068023920059204 [38400/60000]\n",
            "training loss: 1.116826057434082 [44800/60000]\n",
            "training loss: 1.0279159545898438 [51200/60000]\n",
            "training loss: 0.9519606828689575 [57600/60000]\n",
            "Correct Predictions: 57.97%, Average Loss: 1.6793254339694978%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 492\n",
            "training loss: 1.0609102249145508 [0/60000]\n",
            "training loss: 0.9905582070350647 [6400/60000]\n",
            "training loss: 1.0839896202087402 [12800/60000]\n",
            "training loss: 0.9820462465286255 [19200/60000]\n",
            "training loss: 0.592557430267334 [25600/60000]\n",
            "training loss: 1.1867661476135254 [32000/60000]\n",
            "training loss: 0.8064426183700562 [38400/60000]\n",
            "training loss: 1.1168133020401 [44800/60000]\n",
            "training loss: 1.0278874635696411 [51200/60000]\n",
            "training loss: 0.9530481696128845 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6795584475994112%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 493\n",
            "training loss: 1.0608965158462524 [0/60000]\n",
            "training loss: 0.9904248714447021 [6400/60000]\n",
            "training loss: 1.0838898420333862 [12800/60000]\n",
            "training loss: 0.9815881848335266 [19200/60000]\n",
            "training loss: 0.5939873456954956 [25600/60000]\n",
            "training loss: 1.1860055923461914 [32000/60000]\n",
            "training loss: 0.8064272403717041 [38400/60000]\n",
            "training loss: 1.1167885065078735 [44800/60000]\n",
            "training loss: 1.0274261236190796 [51200/60000]\n",
            "training loss: 0.9514907002449036 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6798623776435853%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 494\n",
            "training loss: 1.0604876279830933 [0/60000]\n",
            "training loss: 0.9899580478668213 [6400/60000]\n",
            "training loss: 1.0835881233215332 [12800/60000]\n",
            "training loss: 0.9815927743911743 [19200/60000]\n",
            "training loss: 0.5937538743019104 [25600/60000]\n",
            "training loss: 1.1858206987380981 [32000/60000]\n",
            "training loss: 0.8062574863433838 [38400/60000]\n",
            "training loss: 1.1168217658996582 [44800/60000]\n",
            "training loss: 1.0267730951309204 [51200/60000]\n",
            "training loss: 0.9520718455314636 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6804064816236495%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 495\n",
            "training loss: 1.060219168663025 [0/60000]\n",
            "training loss: 0.9900414943695068 [6400/60000]\n",
            "training loss: 1.0834424495697021 [12800/60000]\n",
            "training loss: 0.9818986058235168 [19200/60000]\n",
            "training loss: 0.5940219759941101 [25600/60000]\n",
            "training loss: 1.1864588260650635 [32000/60000]\n",
            "training loss: 0.8063793182373047 [38400/60000]\n",
            "training loss: 1.1167675256729126 [44800/60000]\n",
            "training loss: 1.0266342163085938 [51200/60000]\n",
            "training loss: 0.9523608684539795 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6809291625022889%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 496\n",
            "training loss: 1.0599206686019897 [0/60000]\n",
            "training loss: 0.9898740649223328 [6400/60000]\n",
            "training loss: 1.083665370941162 [12800/60000]\n",
            "training loss: 0.9812949299812317 [19200/60000]\n",
            "training loss: 0.5928763747215271 [25600/60000]\n",
            "training loss: 1.1842565536499023 [32000/60000]\n",
            "training loss: 0.8059152364730835 [38400/60000]\n",
            "training loss: 1.1167731285095215 [44800/60000]\n",
            "training loss: 1.02787446975708 [51200/60000]\n",
            "training loss: 0.9523114562034607 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6808323109149932%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 497\n",
            "training loss: 1.060261845588684 [0/60000]\n",
            "training loss: 0.9891125559806824 [6400/60000]\n",
            "training loss: 1.0833021402359009 [12800/60000]\n",
            "training loss: 0.9812244176864624 [19200/60000]\n",
            "training loss: 0.5928845405578613 [25600/60000]\n",
            "training loss: 1.184138298034668 [32000/60000]\n",
            "training loss: 0.8058142066001892 [38400/60000]\n",
            "training loss: 1.1167913675308228 [44800/60000]\n",
            "training loss: 1.0271016359329224 [51200/60000]\n",
            "training loss: 0.9521154761314392 [57600/60000]\n",
            "Correct Predictions: 57.95%, Average Loss: 1.6814490419626233%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 498\n",
            "training loss: 1.0597032308578491 [0/60000]\n",
            "training loss: 0.9888936877250671 [6400/60000]\n",
            "training loss: 1.083298683166504 [12800/60000]\n",
            "training loss: 0.9809824824333191 [19200/60000]\n",
            "training loss: 0.5931698083877563 [25600/60000]\n",
            "training loss: 1.1876060962677002 [32000/60000]\n",
            "training loss: 0.8058776259422302 [38400/60000]\n",
            "training loss: 1.1167715787887573 [44800/60000]\n",
            "training loss: 1.0259414911270142 [51200/60000]\n",
            "training loss: 0.9520858526229858 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.6819835293293%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 499\n",
            "training loss: 1.0594017505645752 [0/60000]\n",
            "training loss: 0.9893537759780884 [6400/60000]\n",
            "training loss: 1.0836665630340576 [12800/60000]\n",
            "training loss: 0.9808443784713745 [19200/60000]\n",
            "training loss: 0.5923023223876953 [25600/60000]\n",
            "training loss: 1.189099907875061 [32000/60000]\n",
            "training loss: 0.8054969906806946 [38400/60000]\n",
            "training loss: 1.1167373657226562 [44800/60000]\n",
            "training loss: 1.02607262134552 [51200/60000]\n",
            "training loss: 0.9508415460586548 [57600/60000]\n",
            "Correct Predictions: 57.95%, Average Loss: 1.6819639569520952%\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch: 500\n",
            "training loss: 1.059518814086914 [0/60000]\n",
            "training loss: 0.9891218543052673 [6400/60000]\n",
            "training loss: 1.0833855867385864 [12800/60000]\n",
            "training loss: 0.9809208512306213 [19200/60000]\n",
            "training loss: 0.5934416651725769 [25600/60000]\n",
            "training loss: 1.1870044469833374 [32000/60000]\n",
            "training loss: 0.8057056665420532 [38400/60000]\n",
            "training loss: 1.116744041442871 [44800/60000]\n",
            "training loss: 1.026159405708313 [51200/60000]\n",
            "training loss: 0.9512845277786255 [57600/60000]\n",
            "Correct Predictions: 57.96%, Average Loss: 1.682413836121559%\n",
            "End of training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHdRfbh0NYBq"
      },
      "source": [
        "#torch.save(model, \"model.pth\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1xJmnY4kCTr"
      },
      "source": [
        "torch.save(model, \"/content/drive/MyDrive/Dataset/FashionMnist/Fashion_Mnist_Pytorch_model.pth\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imP6qfmOkWif",
        "outputId": "6b144690-967f-4047-883a-da2deeeb93af"
      },
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "device1=\"cpu\"\n",
        "model.to(device1)\n",
        "model.eval()\n",
        "test_data[0][0]\n",
        "X, y = torch.tensor(test_data[0][0]).to(device1), torch.tensor(test_data[0][1]).to(device1)\n",
        "\n",
        "with torch.no_grad():\n",
        "  pred = model(X)\n",
        "  predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "  print(predicted, actual)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ankle boot Ankle boot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        }
      ]
    }
  ]
}